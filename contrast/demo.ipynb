{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdUjdV2F047ZPcPTKk+9Tw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/contrast/demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YawvW_SWXaZf",
        "outputId": "534470aa-03de-49da-fc49-e2a25348959a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.1/322.1 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install gradio requests pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install fastapi uvicorn gradio pymongo pandas elasticsearch -q\n",
        "\n",
        "from fastapi import FastAPI, Request\n",
        "from pydantic import BaseModel\n",
        "from pymongo import MongoClient\n",
        "from typing import List\n",
        "from datetime import datetime\n",
        "from itertools import product\n",
        "from elasticsearch import Elasticsearch\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "# 🔹 Initialize FastAPI App\n",
        "app = FastAPI()\n",
        "\n",
        "# 🔹 Connect to MongoDB\n",
        "MONGO_URI = \"mongodb://admin:admin%40inet!@203.151.199.181:27017/?authSource=admin\"\n",
        "client = MongoClient(MONGO_URI)\n",
        "db = client[\"drug_interact\"]\n",
        "collection = db[\"drug_interact_col\"]\n",
        "\n",
        "# 🔹 Connect to Elasticsearch\n",
        "es = Elasticsearch(\n",
        "    hosts=[{\n",
        "        'host': 'elk.manageai.co.th',\n",
        "        'port': 443,\n",
        "        'scheme': 'https'\n",
        "    }],\n",
        "    basic_auth=(\"natthaphol.po\", \"cnEM5CeFrG\"),\n",
        "    request_timeout=120\n",
        ")\n",
        "\n",
        "# ✅ Define Input Model\n",
        "class SearchRequest(BaseModel):\n",
        "    input_text: List[str]  # List of input texts\n",
        "    tpu_id: List[int]  # List of TPUIDs\n",
        "\n",
        "# 🔹 API Endpoint: Get Drug Interactions & Log Input\n",
        "@app.post(\"/interactions/\")\n",
        "async def get_drug_interactions(request: Request, request_data: SearchRequest):\n",
        "    \"\"\"\n",
        "    Fetch unique drug interactions based on input_text and tpu_id.\n",
        "    Logs the full request into Elasticsearch.\n",
        "    \"\"\"\n",
        "    input_text_list = request_data.input_text\n",
        "    tpu_id_list = request_data.tpu_id\n",
        "    results = []\n",
        "\n",
        "    # ✅ Log API request into Elasticsearch\n",
        "    log_entry = {\n",
        "        \"timestamp\": datetime.utcnow().isoformat(),\n",
        "        \"ip\": request.client.host,\n",
        "        \"endpoint\": \"/interactions/\",\n",
        "        \"input_text\": input_text_list,\n",
        "        \"tpu_id\": tpu_id_list\n",
        "    }\n",
        "    es.index(index=\"internal-manageai-interaction_logs\", document=log_entry)\n",
        "\n",
        "    # 🔍 Query MongoDB for interactions (excluding duplicate tpuid1-tpuid2 and tpuid2-tpuid1)\n",
        "    seen_pairs = set()\n",
        "    unique_results = []\n",
        "\n",
        "    for tpuid1, tpuid2 in product(tpu_id_list, repeat=2):\n",
        "        # Ensure the order is always (smaller_tpuid, larger_tpuid)\n",
        "        pair = tuple(sorted([tpuid1, tpuid2]))\n",
        "\n",
        "        if pair in seen_pairs:\n",
        "            continue  # Skip if we've already processed this pair\n",
        "        seen_pairs.add(pair)\n",
        "\n",
        "        query = {\n",
        "            \"$or\": [\n",
        "                {\"tpuid\": pair[0], \"tpuid_contrast\": pair[1]}\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        for doc in collection.find(query, {\"tpuid\": 1, \"tpuid_contrast\": 1, \"name1\": 1, \"name2\": 1, \"detail\": 1, \"_id\": 0}):\n",
        "            interaction = {\n",
        "                \"tpuid1\": doc[\"tpuid\"],\n",
        "                \"tpuid2\": doc[\"tpuid_contrast\"],\n",
        "                \"drug_name1\": doc[\"name1\"],\n",
        "                \"drug_name2\": doc[\"name2\"],\n",
        "                \"interaction_detail\": doc[\"detail\"]\n",
        "            }\n",
        "\n",
        "            unique_results.append(interaction)\n",
        "\n",
        "    return {\"interactions\": unique_results} if unique_results else {\"message\": \"No interactions found\"}\n",
        "\n",
        "# Function to start FastAPI inside Colab\n",
        "def start_fastapi():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=7777)\n",
        "\n",
        "# Run FastAPI in a separate thread (so Gradio UI can run)\n",
        "threading.Thread(target=start_fastapi, daemon=True).start()\n",
        "\n",
        "# Gradio Interface\n",
        "def gradio_interactions(input_text, tpu_id):\n",
        "    \"\"\"\n",
        "    Calls the FastAPI backend with GP Name (input_text) and TPUID (tpu_id).\n",
        "    Returns a formatted DataFrame with interaction details.\n",
        "    \"\"\"\n",
        "    # Convert input_text to a list\n",
        "    input_text_list = [x.strip() for x in input_text.split(\",\") if x.strip()]\n",
        "\n",
        "    # Convert tpu_id to list of integers\n",
        "    try:\n",
        "        tpu_id_list = [int(x.strip()) for x in tpu_id.split(\",\") if x.strip().isdigit()]\n",
        "    except ValueError:\n",
        "        return \"⚠️ Invalid TPUID format. Please enter numbers separated by commas.\"\n",
        "\n",
        "    # Prepare the request payload\n",
        "    payload = {\"input_text\": input_text_list, \"tpu_id\": tpu_id_list}\n",
        "\n",
        "    # Send request to FastAPI backend\n",
        "    response = requests.post(\"http://0.0.0.0:7777/interactions/\", json=payload)\n",
        "    data = response.json()\n",
        "\n",
        "    # Handle empty response\n",
        "    if \"interactions\" not in data or not data[\"interactions\"]:\n",
        "        return \"❌ No interactions found.\"\n",
        "\n",
        "    # Convert response to DataFrame for better formatting\n",
        "    df = pd.DataFrame(data[\"interactions\"])\n",
        "    return df  # Gradio will automatically render it as a table\n",
        "\n",
        "# Create Gradio UI\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interactions,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"🧪 GP Name (comma-separated)\"),\n",
        "        gr.Textbox(label=\"🆔 TPUID (comma-separated, numbers only)\")\n",
        "    ],\n",
        "    outputs=gr.Dataframe(label=\"📋 Drug Interactions\"),\n",
        "    title=\"💊 Drug Interaction Checker\",\n",
        "    description=\"Enter GP Name and TPUID to check for drug interactions. Data will be retrieved from MongoDB and formatted in a table.\",\n",
        ")\n",
        "\n",
        "# Run Gradio app in Google Colab\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "ouQFrQpZZm-d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}