{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ovaDlxWb84jVuUIbdltLO41B6C6UTSb8",
      "authorship_tag": "ABX9TyPtF12Wjx7qnpSsKuQpYxG+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/BertModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers pandas torch"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mx61Ot83FQpf",
        "outputId": "745b1156-cda7-4587-d2ea-5ac97e13d872"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install transformers accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eqii6YnZI363",
        "outputId": "230faa38-3425-4e49-bd25-6d699db99cc8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElCeT5pmEJB5",
        "outputId": "4cd0b2b5-e080-4e45-a385-948fbff21d27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "XQQBB-kKD94p",
        "outputId": "e59a0502-7913-4c80-e929-8a707a015d85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             subject  \\\n",
              "0  Interlink : MA วันที่ 15 กรกฎาคม 2565 เวลา 00....   \n",
              "1  [Closed]Promessy Corporation : แจ้งตรวจสอบเครื...   \n",
              "2  BAAC : รบกวนเข้าไปเก็บตัวกล่องสัญญาณที่สาขาสาร...   \n",
              "3  Transform You : แจ้งขอข้อมูล Lun ดังนี้ Offsit...   \n",
              "4  GSB[SD] : แบบคำขอเปลี่ยนแปลงทรัพยากรบน GSB Clo...   \n",
              "\n",
              "                                         description ticket_type  \\\n",
              "0  From: \"NQM Interlink Telecom\" <nqm@interlinkte...     Request   \n",
              "1  From: Werachat Nawaroongruang <werachat.nawaro...     Request   \n",
              "2  รับสายลูกค้าคุณสุริยา เบอร์ 0818863505 แจ้งมีต...     Request   \n",
              "3  From: \"Teerayut Saowamok\" <teerayut.sa@transfo...     Request   \n",
              "4  From: Servicedesk <servicedesk@inetms.co.th>\\n...     Request   \n",
              "\n",
              "                                       clean_subject  \\\n",
              "0  ma     น      น   cid  inextbaac   สาขา หน่วยบ...   \n",
              "1  promessy corporation   ตรวจสอบเครื่อง ip     r...   \n",
              "2  รบกวนเข้าไปเก็บตัวกล่องสัญญาณที่สาขาสารภี เนื่...   \n",
              "3  ขอข้อมูล lun ดังนี้ offsite อยู่ที่ idc ไหนและ...   \n",
              "4  แบบคำขอเปลี่ยนแปลงทรัพยากรบน gsb cloud based s...   \n",
              "\n",
              "                                   clean_description  \\\n",
              "0  เรื่อง ขอกำหนดการปรับปรุงการให้บริการ บริษัท ไ...   \n",
              "1  inet team เครื่อง private ip     ได้มีการ rest...   \n",
              "2  รับสายลูกค้าคุณสุริยา เบอร์  มีตัวกล่องอุปกรณ์...   \n",
              "3  noc รบกวนเปิดเคสประสานงานทีม op cloud ทางทีม t...   \n",
              "4  noc ครับ subject    internal  gsb  sr   รับ  ร...   \n",
              "\n",
              "                                   tokenized_subject  \\\n",
              "0  ['ma', 'น', 'น', 'cid', 'inextbaac', 'สาขา', '...   \n",
              "1  ['promessy', 'corporation', 'ตรวจสอบ', 'เครื่อ...   \n",
              "2  ['รบกวน', 'เข้าไป', 'เก็บตัว', 'กล่อง', 'สัญญา...   \n",
              "3  ['ขอ', 'ข้อมูล', 'lun', 'ดังนี้', 'offsite', '...   \n",
              "4  ['แบบ', 'คำขอ', 'เปลี่ยนแปลง', 'ทรัพยากร', 'บน...   \n",
              "\n",
              "                               tokenized_description  \\\n",
              "0  ['เรื่อง', 'ขอ', 'กำหนด', 'การปรับปรุง', 'การ'...   \n",
              "1  ['inet', 'team', 'เครื่อง', 'private', 'ip', '...   \n",
              "2  ['รับสาย', 'ลูกค้า', 'คุณ', 'สุริยา', 'เบอร์',...   \n",
              "3  ['noc', 'รบกวน', 'เปิด', 'เคส', 'ประสานงาน', '...   \n",
              "4  ['noc', 'ครับ', 'subject', 'internal', 'gsb', ...   \n",
              "\n",
              "                                     meaning_subject  \\\n",
              "0  ['inextbaac', 'cid', 'สาขา', 'หน่วยบุรีรัมย์',...   \n",
              "1  ['ip', 'restart', 'ตรวจสอบเครื่อง', 'โดยไม่ทรา...   \n",
              "2  ['เข้าไป', 'สารภี', 'เนื่องจากมีการย้ายอาคารไป...   \n",
              "3  ['ดังนี้', 'full', 'อยู่ที่', 'ไหนและ', 'offsi...   \n",
              "4  ['แบบคำขอเปลี่ยนแปลงทรัพยากรบน', 'กรมการปกครอง...   \n",
              "\n",
              "                                 meaning_description  \n",
              "0  ['ท่าน', 'สิ้นสุดดำเนินการ', 'ปรับปรุง', 'ขอจั...  \n",
              "1  ['team', 'ได้มีการ', 'รบกวนเช็คให้หน่อยครับ', ...  \n",
              "2  ['เข้าไป', 'เดิม', 'โทร', 'เพชร', 'ตัว', 'สุภา...  \n",
              "3  ['full', 'aci', 'เคส', 'sas', 'op', 'offsite',...  \n",
              "4  ['อายุการใช้งาน', 'ทรัพยากร', 'gsb', 'gateway'...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9849f8e6-dec1-4942-b1bb-bacb085c137f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subject</th>\n",
              "      <th>description</th>\n",
              "      <th>ticket_type</th>\n",
              "      <th>clean_subject</th>\n",
              "      <th>clean_description</th>\n",
              "      <th>tokenized_subject</th>\n",
              "      <th>tokenized_description</th>\n",
              "      <th>meaning_subject</th>\n",
              "      <th>meaning_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interlink : MA วันที่ 15 กรกฎาคม 2565 เวลา 00....</td>\n",
              "      <td>From: \"NQM Interlink Telecom\" &lt;nqm@interlinkte...</td>\n",
              "      <td>Request</td>\n",
              "      <td>ma     น      น   cid  inextbaac   สาขา หน่วยบ...</td>\n",
              "      <td>เรื่อง ขอกำหนดการปรับปรุงการให้บริการ บริษัท ไ...</td>\n",
              "      <td>['ma', 'น', 'น', 'cid', 'inextbaac', 'สาขา', '...</td>\n",
              "      <td>['เรื่อง', 'ขอ', 'กำหนด', 'การปรับปรุง', 'การ'...</td>\n",
              "      <td>['inextbaac', 'cid', 'สาขา', 'หน่วยบุรีรัมย์',...</td>\n",
              "      <td>['ท่าน', 'สิ้นสุดดำเนินการ', 'ปรับปรุง', 'ขอจั...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Closed]Promessy Corporation : แจ้งตรวจสอบเครื...</td>\n",
              "      <td>From: Werachat Nawaroongruang &lt;werachat.nawaro...</td>\n",
              "      <td>Request</td>\n",
              "      <td>promessy corporation   ตรวจสอบเครื่อง ip     r...</td>\n",
              "      <td>inet team เครื่อง private ip     ได้มีการ rest...</td>\n",
              "      <td>['promessy', 'corporation', 'ตรวจสอบ', 'เครื่อ...</td>\n",
              "      <td>['inet', 'team', 'เครื่อง', 'private', 'ip', '...</td>\n",
              "      <td>['ip', 'restart', 'ตรวจสอบเครื่อง', 'โดยไม่ทรา...</td>\n",
              "      <td>['team', 'ได้มีการ', 'รบกวนเช็คให้หน่อยครับ', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BAAC : รบกวนเข้าไปเก็บตัวกล่องสัญญาณที่สาขาสาร...</td>\n",
              "      <td>รับสายลูกค้าคุณสุริยา เบอร์ 0818863505 แจ้งมีต...</td>\n",
              "      <td>Request</td>\n",
              "      <td>รบกวนเข้าไปเก็บตัวกล่องสัญญาณที่สาขาสารภี เนื่...</td>\n",
              "      <td>รับสายลูกค้าคุณสุริยา เบอร์  มีตัวกล่องอุปกรณ์...</td>\n",
              "      <td>['รบกวน', 'เข้าไป', 'เก็บตัว', 'กล่อง', 'สัญญา...</td>\n",
              "      <td>['รับสาย', 'ลูกค้า', 'คุณ', 'สุริยา', 'เบอร์',...</td>\n",
              "      <td>['เข้าไป', 'สารภี', 'เนื่องจากมีการย้ายอาคารไป...</td>\n",
              "      <td>['เข้าไป', 'เดิม', 'โทร', 'เพชร', 'ตัว', 'สุภา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Transform You : แจ้งขอข้อมูล Lun ดังนี้ Offsit...</td>\n",
              "      <td>From: \"Teerayut Saowamok\" &lt;teerayut.sa@transfo...</td>\n",
              "      <td>Request</td>\n",
              "      <td>ขอข้อมูล lun ดังนี้ offsite อยู่ที่ idc ไหนและ...</td>\n",
              "      <td>noc รบกวนเปิดเคสประสานงานทีม op cloud ทางทีม t...</td>\n",
              "      <td>['ขอ', 'ข้อมูล', 'lun', 'ดังนี้', 'offsite', '...</td>\n",
              "      <td>['noc', 'รบกวน', 'เปิด', 'เคส', 'ประสานงาน', '...</td>\n",
              "      <td>['ดังนี้', 'full', 'อยู่ที่', 'ไหนและ', 'offsi...</td>\n",
              "      <td>['full', 'aci', 'เคส', 'sas', 'op', 'offsite',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GSB[SD] : แบบคำขอเปลี่ยนแปลงทรัพยากรบน GSB Clo...</td>\n",
              "      <td>From: Servicedesk &lt;servicedesk@inetms.co.th&gt;\\n...</td>\n",
              "      <td>Request</td>\n",
              "      <td>แบบคำขอเปลี่ยนแปลงทรัพยากรบน gsb cloud based s...</td>\n",
              "      <td>noc ครับ subject    internal  gsb  sr   รับ  ร...</td>\n",
              "      <td>['แบบ', 'คำขอ', 'เปลี่ยนแปลง', 'ทรัพยากร', 'บน...</td>\n",
              "      <td>['noc', 'ครับ', 'subject', 'internal', 'gsb', ...</td>\n",
              "      <td>['แบบคำขอเปลี่ยนแปลงทรัพยากรบน', 'กรมการปกครอง...</td>\n",
              "      <td>['อายุการใช้งาน', 'ทรัพยากร', 'gsb', 'gateway'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9849f8e6-dec1-4942-b1bb-bacb085c137f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9849f8e6-dec1-4942-b1bb-bacb085c137f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9849f8e6-dec1-4942-b1bb-bacb085c137f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3d4c2307-1215-4921-bb44-6dfe82b28989\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3d4c2307-1215-4921-bb44-6dfe82b28989')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3d4c2307-1215-4921-bb44-6dfe82b28989 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/AIEngineer/data.csv\")\n",
        "df = df.drop(columns=['Unnamed: 0'])\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "dWAimyKVFphQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "yMqN8cBVmoml"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sentence'] = df['clean_subject'] + ' ' + df['clean_description']\n",
        "df['sentence'].loc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "_-5pVSn3mu-g",
        "outputId": "ddd3365e-9a9b-45b5-8005-25a15f1c5284"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ma     น      น   cid  inextbaac   สาขา หน่วยบุรีรัมย์ เรื่อง ขอกำหนดการปรับปรุงการให้บริการ บริษัท ไอเน็กซ์ บรอดแบนด์ จำกัด ขอจัดส่งจดหมายปรับปรุงการบริการวงจร จำนวน  วงจร วัตถุประ์การดำเนินการ   ปรับปรุงบริการโครงข่าย เนื่องจากจะดำเนินการ replace อุปกรณ์ภายใน node พื้นที่ดำเนินการ   node บุรีรัมย์ site interlink วัน เริ่มดำเนินการ       น  วัน สิ้นสุดดำเนินการ       น  ระยะกระทบ   กระทบบริการไม่เกิน   ชั่วโมง รายละเอียดทั้งหมดตาม เอกสารแนบมา จึงมาโปรดทราบความจำเป็นดังกล่าว และบริษัทฯ ขออภัยในความไม่สะดวกในครั้งนี้ หากท่านมีข้อสงสัยหรือต้องการข้อมูลเพิ่มเติม โปรดติดต่อตามหมายเลขด้านล่าง หรือ reply mail กลับมาที่'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['ticket_type','sentence']]\n",
        "data.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UBdCnR6VnDpK",
        "outputId": "0ddc06c6-350f-4d5d-f560-494530e12364"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  ticket_type                                           sentence\n",
              "0     Request  ma     น      น   cid  inextbaac   สาขา หน่วยบ...\n",
              "1     Request  promessy corporation   ตรวจสอบเครื่อง ip     r...\n",
              "2     Request  รบกวนเข้าไปเก็บตัวกล่องสัญญาณที่สาขาสารภี เนื่...\n",
              "3     Request  ขอข้อมูล lun ดังนี้ offsite อยู่ที่ idc ไหนและ...\n",
              "4     Request  แบบคำขอเปลี่ยนแปลงทรัพยากรบน gsb cloud based s..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ef3ec8e-cf43-46dd-9696-153b45ca9644\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticket_type</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Request</td>\n",
              "      <td>ma     น      น   cid  inextbaac   สาขา หน่วยบ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Request</td>\n",
              "      <td>promessy corporation   ตรวจสอบเครื่อง ip     r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Request</td>\n",
              "      <td>รบกวนเข้าไปเก็บตัวกล่องสัญญาณที่สาขาสารภี เนื่...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Request</td>\n",
              "      <td>ขอข้อมูล lun ดังนี้ offsite อยู่ที่ idc ไหนและ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Request</td>\n",
              "      <td>แบบคำขอเปลี่ยนแปลงทรัพยากรบน gsb cloud based s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ef3ec8e-cf43-46dd-9696-153b45ca9644')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ef3ec8e-cf43-46dd-9696-153b45ca9644 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ef3ec8e-cf43-46dd-9696-153b45ca9644');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fce6cb18-8d91-489d-9305-206c054a02f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fce6cb18-8d91-489d-9305-206c054a02f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fce6cb18-8d91-489d-9305-206c054a02f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(subset=['sentence'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZRIJoLPo_JY",
        "outputId": "92b64a4b-3040-4efd-e4eb-0970239d266f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-ca873a3b1d33>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data.dropna(subset=['sentence'], inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class distribution\n",
        "data['ticket_type'].value_counts(normalize = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rtbez6tmt0P",
        "outputId": "7bdd545f-9b40-44f5-8c5f-f9103d3fa832"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ticket_type\n",
              "Request     0.580555\n",
              "Incident    0.412498\n",
              "Problem     0.006947\n",
              "Name: proportion, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue_qHDK2pYyK",
        "outputId": "1b4f4601-4683-462e-86de-c1143ea40904"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ticket_type    0\n",
              "sentence       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(data['sentence'], data['ticket_type'],\n",
        "                                                                    random_state=2018,\n",
        "                                                                    test_size=0.3,\n",
        "                                                                    stratify=data['ticket_type'])\n",
        "\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
        "                                                                random_state=2018,\n",
        "                                                                test_size=0.3,\n",
        "                                                                stratify=temp_labels)"
      ],
      "metadata": {
        "id": "lUIT4OWwFxIm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiTFNFQWEeeK",
        "outputId": "44772bf0-de41-4c70-bc86-fac8c9030d9e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "Nay3Eiq4ngf9",
        "outputId": "4a807660-3556-4d7b-852e-bb342d78a4b2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = 25,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xKHXwz7pkt4",
        "outputId": "2ef364ac-69ac-4e31-80a4-74aeeb7bfb42"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit and transform the labels\n",
        "train_labels = le.fit_transform(train_labels)\n",
        "val_labels = le.transform(val_labels)\n",
        "test_labels = le.transform(test_labels)"
      ],
      "metadata": {
        "id": "xT-y6GyVqq8l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert lists to tensors\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels)\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels)\n",
        "\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels)"
      ],
      "metadata": {
        "id": "ZEu1kUcspmEM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Batch size\n",
        "batch_size = 16\n",
        "\n",
        "# Create TensorDataset for training data\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "# Create a RandomSampler for training data\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Create DataLoader for training data\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "# (Optional) Create TensorDataset and DataLoader for test data if needed\n",
        "# test_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "# test_sampler = SequentialSampler(test_data)\n",
        "# test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "mghlEXMqp850"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "6DWKfEffqanu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "\n",
        "        self.bert = bert\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        # relu activation function\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        # dense layer 1\n",
        "        self.fc1 = nn.Linear(768,512)\n",
        "\n",
        "        # dense layer 2 (Output layer)\n",
        "        self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "        #softmax activation function\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "        #pass the inputs to the model\n",
        "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "\n",
        "        x = self.fc1(cls_hs)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # output layer\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        # apply softmax activation\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "OzcNm8GyrRqd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "U8vqNxgprSpy",
        "outputId": "22be9b44-750b-486d-d68b-3a78980c0e7e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-5d499bb53163>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# push the model to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m                     )\n\u001b[0;32m-> 1159\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1160\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),lr = 1e-5)\n",
        "\n",
        "#compute the class weights\n",
        "class_weights = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print('Class Weights:',class_weights)"
      ],
      "metadata": {
        "id": "9lRgS3UlrU8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting list of class weights to a tensor\n",
        "weights= torch.tensor(class_weights,dtype=torch.float)\n",
        "\n",
        "# push to GPU\n",
        "weights = weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights)\n",
        "\n",
        "# number of training epochs\n",
        "epochs = 5"
      ],
      "metadata": {
        "id": "RFoGO5zSrm4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "\n",
        "    model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save model predictions\n",
        "    total_preds=[]\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(train_dataloader):\n",
        "\n",
        "        # progress update after every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [r.to(device) for r in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # clear previously calculated gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # get model predictions for the current batch\n",
        "        preds = model(sent_id, mask)\n",
        "\n",
        "        # compute the loss between actual and predicted values\n",
        "        loss = cross_entropy(preds, labels)\n",
        "\n",
        "        # add on to the total loss\n",
        "        total_loss = total_loss + loss.item()\n",
        "\n",
        "        # backward pass to calculate the gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # model predictions are stored on GPU. So, push it to CPU\n",
        "        preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "    # compute the training loss of the epoch\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "      # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    #returns the loss and predictions\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "NR8fKUUkrsxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "\n",
        "    print(\"\\nEvaluating...\")\n",
        "\n",
        "    # deactivate dropout layers\n",
        "    model.eval()\n",
        "\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    # empty list to save the model predictions\n",
        "    total_preds = []\n",
        "\n",
        "    # iterate over batches\n",
        "    for step,batch in enumerate(val_dataloader):\n",
        "\n",
        "        # Progress update every 50 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "        # push the batch to gpu\n",
        "        batch = [t.to(device) for t in batch]\n",
        "\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        # deactivate autograd\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # model predictions\n",
        "            preds = model(sent_id, mask)\n",
        "\n",
        "            # compute the validation loss between actual and predicted values\n",
        "            loss = cross_entropy(preds,labels)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "\n",
        "            total_preds.append(preds)\n",
        "\n",
        "    # compute the validation loss of the epoch\n",
        "    avg_loss = total_loss / len(val_dataloader)\n",
        "\n",
        "    # reshape the predictions in form of (number of samples, no. of classes)\n",
        "    total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "    return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "dlEWW2MVrwiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "#defining epochs\n",
        "epochs = 1\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "\n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "\n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "\n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "metadata": {
        "id": "lwIWEWqNr2IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights of best modelpath = 'saved_weights.pt'model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "J7xfXJZrr6KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "    preds = model(test_seq.to(device), test_mask.to(device))\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))\n"
      ],
      "metadata": {
        "id": "WYHNazk6r_IF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}