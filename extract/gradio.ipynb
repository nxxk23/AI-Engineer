{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP1hdkS8T+6xIXzebBuMTSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/extract/gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65_MjRQXYJZM"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr pdf2image gradio pythainlp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install easyocr gradio pythainlp pdf2image\n",
        "!apt-get install -y poppler-utils  # Install poppler for PDF processing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oftS-S49ZZ8j",
        "outputId": "f891b084-585d-40d0-b481-fc8975eb97f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.5 [186 kB]\n",
            "Fetched 186 kB in 0s (408 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.5_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y poppler-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRI_e6fCaKFl",
        "outputId": "3e75235a-570c-43a2-e3f5-0750ec09e17f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded_files = files.upload()"
      ],
      "metadata": {
        "id": "RKqDbuImYhHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54QS_8wCYXw3",
        "outputId": "d38f81e7-5f68-48a6-b132-295b729f7a23"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "resume_directory = '/content/drive/MyDrive/AIEngineer/resume/resume_LLM'\n",
        "pdf_files = [os.path.join(resume_directory, f) for f in os.listdir(resume_directory) if f.endswith('.pdf')]\n",
        "\n",
        "# Print the list of PDF files to verify\n",
        "print(pdf_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5BgVkOdY9sw",
        "outputId": "85b0ea29-f2ce-4fe6-b14c-eeae716d7ab5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/AIEngineer/resume/resume_LLM/Resume BA 2.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/Resume BA 3.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/Resume ba 5.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/Resume ba2.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/Resume baa.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 6.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 7.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 2.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 3.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 4.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 5.pdf', '/content/drive/MyDrive/AIEngineer/resume/resume_LLM/resume 1.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "from pdf2image import convert_from_path\n",
        "from pythainlp.phayathaibert.core import NamedEntityTagger\n",
        "import gradio as gr\n",
        "\n",
        "def extract_text_from_image(image):\n",
        "    try:\n",
        "        reader = easyocr.Reader(['th', 'en'], gpu=True)  # Enable GPU if available\n",
        "        image_np = np.array(image)\n",
        "        result = reader.readtext(image_np)\n",
        "        sorted_data = sorted(result, key=lambda x: x[0][0][1])\n",
        "        plain_text = \"\\n\".join([text for _, text, _ in sorted_data])\n",
        "        return plain_text\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from image: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def process_single_pdf(pdf_file):\n",
        "    tagger = NamedEntityTagger()\n",
        "    unwanted_terms = [\n",
        "        'ที่อยู่', 'โทรศัพท์', 'อีเมล', 'linkedin', ':', ',', '-', '|',\n",
        "        'ประวัติส่วนตัว', 'เกี่ยวกับฉัน', 'about me', 'ชื่อ', 'สกุล', 'tell', 'โทร', 'โทรงาน',\n",
        "        'ชื่อเล่น', 'อายุ', 'วันเกิด', 'พุทธ', 'ศาสนา', 'สัญชาติ', 'phone',\n",
        "        'ช่องทางการติดต่อ', '_', 're sume', 'resume', 'resu me'\n",
        "    ]\n",
        "    unwanted_pattern = '|'.join(map(re.escape, unwanted_terms))\n",
        "\n",
        "    def tag_and_clean_text(text):\n",
        "        try:\n",
        "            ner = tagger.get_ner(text, tag=True)\n",
        "            pattern = r'<(?!ORGANIZATION|PERCENT|TIME)[^>]+>[^<]+</[^>]+>'\n",
        "            cleaned_ner = re.sub(pattern, '', ner)\n",
        "            cleaned_ner = re.sub(r'</?(ORGANIZATION|PERCENT|TIME)>', '', cleaned_ner)\n",
        "            cleaned_ner = re.sub(unwanted_pattern, '', cleaned_ner)\n",
        "            cleaned_ner = re.sub(r'\\bal\\b', 'ai', cleaned_ner, flags=re.IGNORECASE)\n",
        "            return ner.strip(), cleaned_ner.strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Error in tag_and_clean_text: {e}\")\n",
        "            return \"\", text\n",
        "\n",
        "    results = []\n",
        "    try:\n",
        "        images = convert_from_path(pdf_file.name, dpi=300)\n",
        "        raw_text = \"\"\n",
        "        for image in images:\n",
        "            raw_text += extract_text_from_image(image) + \"\\n\"\n",
        "        tagged_text, cleaned_text = tag_and_clean_text(raw_text)\n",
        "        results.append({\n",
        "            \"PDF File\": os.path.basename(pdf_file.name),\n",
        "            \"Raw_Text\": raw_text,\n",
        "            \"Cleaned_Text\": cleaned_text\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in process_single_pdf: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    return df\n",
        "\n",
        "def process_multiple_pdfs(pdf_files):\n",
        "    all_results = pd.DataFrame()\n",
        "    for pdf_file in pdf_files:\n",
        "        df = process_single_pdf(pdf_file)\n",
        "        all_results = pd.concat([all_results, df], ignore_index=True)\n",
        "    return all_results\n",
        "\n",
        "def gradio_interface(pdf_files):\n",
        "    try:\n",
        "        df = process_multiple_pdfs(pdf_files)\n",
        "        csv_path = save_dataframe(df)\n",
        "        return df, csv_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in gradio_interface: {e}\")\n",
        "        return pd.DataFrame(), \"\"\n",
        "\n",
        "\n",
        "def save_dataframe(df):\n",
        "    try:\n",
        "        csv_path = '/content/output.csv'\n",
        "        df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
        "        return csv_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving DataFrame: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def save_button_action(df):\n",
        "    csv_path = save_dataframe(df)\n",
        "    return csv_path\n"
      ],
      "metadata": {
        "id": "xh3H_8cCYkBD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=[gr.Files(label=\"Upload PDF Files\")],  # Allow multiple files\n",
        "    outputs=[\n",
        "        gr.Dataframe(label=\"Extracted and Cleaned Data\", height=500, min_width=800),\n",
        "        gr.File(label=\"Download CSV\")  # Add a file download button\n",
        "    ],\n",
        "    title=\"PDF to Text and Data Cleaner\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "nTbGNnawY1np",
        "outputId": "471528bd-6dd6-433f-d505-1d734bb980ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://5f01a29b36f400adbc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f01a29b36f400adbc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ]
    }
  ]
}