{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/extract/gradioprompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eCrTQcC53f5"
      },
      "outputs": [],
      "source": [
        "!pip -q install easyocr gradio pythainlp langchain langchain_huggingface langchain_community pytesseract transformers\n",
        "!sudo apt-get install ghostscript"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> [resume drive link](https://drive.google.com/drive/folders/1aoFrz_k9ngVXesYZGIrTaiPQJTOBQFEr?usp=sharing) but if u already have your own resume, it will be unneccessary"
      ],
      "metadata": {
        "id": "mSSTsQAY3aTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "import subprocess\n",
        "from pythainlp.phayathaibert.core import NamedEntityTagger\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import requests\n",
        "from threading import Semaphore\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from huggingface_hub import InferenceClient\n",
        "import pytesseract\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import os\n",
        "import subprocess\n",
        "import uuid"
      ],
      "metadata": {
        "id": "90WztN4zV52X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eExOBevq53gJ"
      },
      "outputs": [],
      "source": [
        "resume_prompt = \"\"\"\n",
        "# Resume Evaluation Prompt\n",
        "\n",
        "**You are a career coach and resume evaluator**, tasked with thoughtfully assessing a candidate's resume based on a specific job description. Your goal is to strike a balance between the candidate’s qualifications and their potential for growth. Keep in mind that real-world hiring involves not only meeting immediate requirements but also identifying long-term potential and adaptability.\n",
        "\n",
        "## Instructions:\n",
        "- **Focus primarily on the job description**, but also consider any unique skills and experience that the candidate offers.\n",
        "- Your evaluation should prioritize candidates who align well with the role but remain open to those who might provide unexpected strengths.\n",
        "- **Don’t rely solely on a perfect match**—instead, take a holistic view of the candidate to assess their overall fit, potential, and growth trajectory.\n",
        "\n",
        "### Evaluation Criteria:\n",
        "\n",
        "1. **Strong Fit (PASS)**:\n",
        "   - The candidate aligns well with the job requirements and demonstrates strong potential to excel, even if some qualifications are missing.\n",
        "   - Consider their **unique strengths**, **relevant experience**, and **transferable skills**.\n",
        "   - If they show adaptability and a strong overall fit, classify them as \"Strong Fit.\"\n",
        "\n",
        "2. **Promising (RECONSIDER)**:\n",
        "   - The candidate aligns with some aspects of the job but has notable gaps.\n",
        "   - However, their experience suggests they could grow into the role.\n",
        "   - Consider them as a candidate with potential, particularly if their overall background suggests they would be worth interviewing or reviewing further.\n",
        "\n",
        "3. **Not a Fit (UNRELATED)**:\n",
        "   - The candidate’s background does not align with the job description and there is no significant potential for the role.\n",
        "   - Their experience, while potentially strong in other areas, is unrelated to the requirements for this position.\n",
        "\n",
        "## Evaluation Process:\n",
        "\n",
        "1. **Step 1**: Carefully review the **job description** and extract the core requirements and preferred qualifications.\n",
        "2. **Step 2**: Compare the **resume** to the job description:\n",
        "   - Identify relevant qualifications and skills.\n",
        "   - Note any **transferable skills** or **unique strengths** that the candidate brings.\n",
        "3. **Step 3**: Consider the candidate's **overall potential**, adaptability, and long-term growth.\n",
        "4. **Step 4**: Classify the resume and provide feedback.\n",
        "\n",
        "## Output Instructions:\n",
        "- The output must **only** contain the following sections in the exact order and format. Any deviation from this format is not allowed.\n",
        "  - **Classification**: Pass / Reconsider / Unrelated\n",
        "  - **Rationale**: A clear and concise explanation for your classification.\n",
        "  - **ข้อดี (Strengths)**: A summary of the candidate's strengths.\n",
        "  - **ข้อควรปรับปรุง (Areas for Improvement)**: A summary of areas where the candidate could improve or is lacking.\n",
        "\n",
        "- **Do not** include a detailed analysis of the job description or resume in the output.\n",
        "- The output should **start** with the **Classification** and **not include** resume details or job description.\n",
        "\n",
        "## Example Format for the Output:\n",
        "\n",
        "**Classification**: Pass / Reconsider / Unrelated\n",
        "**Rationale**: Provide a concise explanation, focusing on the candidate's fit, transferable skills, and potential.\n",
        "**ข้อดี (Strengths)**:\n",
        "- List key strengths of the candidate.\n",
        "**ข้อควรปรับปรุง (Areas for Improvement)**:\n",
        "- Summarize areas where the candidate could improve.\n",
        "\n",
        "---\n",
        "\n",
        "## **Job Description** (never copy it):\n",
        "{jobdescribe}\n",
        "\n",
        "## **Resume** (never copy it):\n",
        "{resume}\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **`convert_pdf_to_images`**: Converts a PDF file into high-resolution PNG images using Ghostscript.\n",
        "- **`extract_text_from_image`**: Extracts text from images using easyocr for both Thai and English languages.\n",
        "- **`chunk_text`**: Splits large text into smaller chunks based on a token limit for model processing.\n",
        "- **`tag_and_clean_text`**: Tags and cleans text using a custom NER model and removes unnecessary tags.\n",
        "- **`generate_answer`**: Generates an evaluation (classification and rationale) from a resume and job description.\n",
        "- **`extract_classification`**: Extracts the classification result (Pass, Reconsider, Unrelated) from generated text.\n",
        "- **`process_file`**: Processes a single resume file by extracting text and generating an evaluation.\n",
        "- **`process_multiple_files`**: Processes multiple resume files in batch, applying the evaluation function to each.\n",
        "- **`save_dataframe`**: Saves the processed evaluation results to a CSV file, appending new data.\n",
        "- **`generate_prompt_answer_optimized`**: Optimizes prompt generation and evaluation for batch processing.\n",
        "- **`process_batch`**: Handles batch processing of resumes with threading for efficient evaluation.\n",
        "- **`batch_process`**: Parallelizes the evaluation of resumes using ThreadPoolExecutor for faster batch processing."
      ],
      "metadata": {
        "id": "vetHrWwQ4d30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model parameters\n",
        "model_params = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"repetition_penalty\": 1.0\n",
        "}\n",
        "semaphore = Semaphore(50)\n",
        "\n",
        "def convert_pdf_to_images(pdf_file, output_folder=\"/content/images\", dpi=300):\n",
        "    try:\n",
        "        # Create a unique folder for each PDF\n",
        "        pdf_filename = os.path.splitext(os.path.basename(pdf_file))[0]\n",
        "        unique_output_folder = os.path.join(output_folder, pdf_filename)\n",
        "\n",
        "        if not os.path.exists(unique_output_folder):\n",
        "            os.makedirs(unique_output_folder)\n",
        "\n",
        "        output_format = os.path.join(unique_output_folder, \"page_%03d.png\")\n",
        "        gs_command = [\n",
        "            \"gs\",\n",
        "            \"-sDEVICE=png16m\",\n",
        "            f\"-r{dpi}\",\n",
        "            \"-o\", output_format,\n",
        "            pdf_file\n",
        "        ]\n",
        "        subprocess.run(gs_command, check=True)\n",
        "\n",
        "        # Collect all generated images in a list\n",
        "        image_files = sorted([os.path.join(unique_output_folder, f) for f in os.listdir(unique_output_folder) if f.endswith(\".png\")])\n",
        "        return image_files\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ghostscript error: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_text_from_image(image_path):\n",
        "    reader = easyocr.Reader(['th', 'en'], gpu=True)\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "    result = reader.readtext(image_np)\n",
        "    sorted_data = sorted(result, key=lambda x: x[0][0][1])\n",
        "    plain_text = \"\\n\".join([text for _, text, _ in sorted_data])\n",
        "    return plain_text\n",
        "\n",
        "def chunk_text(text, tokenizer, max_tokens=200):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    total_tokens = len(tokens)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < total_tokens:\n",
        "        end = min(start + max_tokens, total_tokens)\n",
        "        chunk = tokenizer.convert_tokens_to_string(tokens[start:end])\n",
        "        chunks.append(chunk)\n",
        "\n",
        "        start += max_tokens\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def tag_and_clean_text(text, tagger, tokenizer, unwanted_pattern, max_tokens=200):\n",
        "    text_chunks = chunk_text(text, tokenizer, max_tokens=max_tokens)\n",
        "    tagged_text = []\n",
        "    cleaned_text = []\n",
        "\n",
        "    for i, chunk in enumerate(text_chunks):\n",
        "        ner = tagger.get_ner(chunk, tag=True)\n",
        "        if not ner:\n",
        "            ner = chunk\n",
        "\n",
        "        # Clean the tags\n",
        "        pattern = r'<(?!ORGANIZATION|PERCENT|TIME)[^>]+>[^<]*?</[^>]+>'\n",
        "        cleaned_ner = re.sub(pattern, '', ner)\n",
        "        cleaned_ner = re.sub(r'</?(ORGANIZATION|PERCENT|TIME)>', '', cleaned_ner)\n",
        "        cleaned_ner = re.sub(unwanted_pattern, '', cleaned_ner, flags=re.IGNORECASE)\n",
        "        cleaned_ner = re.sub(r'\\bal\\b', 'ai', cleaned_ner, flags=re.IGNORECASE)\n",
        "        # Append the tagged and cleaned text\n",
        "        tagged_text.append(ner)\n",
        "        cleaned_text.append(cleaned_ner)\n",
        "    # Combine results from all chunks\n",
        "    combined_tagged_text = \"\\n\".join(tagged_text).strip()\n",
        "    combined_cleaned_text = \"\\n\".join(cleaned_text).strip()\n",
        "\n",
        "    return combined_tagged_text, combined_cleaned_text\n",
        "\n",
        "\n",
        "# Function to generate an answer using the prompt\n",
        "def generate_answer(resume, job_description):\n",
        "    formatted_prompt = resume_prompt.replace(\"{resume}\", resume).replace(\"{jobdescribe}\", job_description)\n",
        "    truncated_prompt = formatted_prompt[:model_params[\"max_new_tokens\"]]\n",
        "    client = InferenceClient('https://ai-api.manageai.co.th/llm-model-03/')\n",
        "    response = client.text_generation(formatted_prompt, **model_params)\n",
        "    output = \"\".join(response)\n",
        "    return output\n",
        "\n",
        "# Extract classification from the result text\n",
        "def extract_classification(text):\n",
        "    pattern = r'\\*\\*\\s*Classification\\s*\\**:\\s*(?:\\[)?\\s*(Pass|Reconsider|Not Pass|Unrelated)\\s*(?:\\])?'\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if not match:\n",
        "        pattern = r'Classification\\s*:\\s*(?:\\[)?\\s*(Pass|Reconsider|Not Pass|Unrelated)\\s*(?:\\])?'\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return text\n",
        "\n",
        "def process_file(file, job_description, is_pdf=True):\n",
        "    if is_pdf:\n",
        "        images = convert_pdf_to_images(file.name)\n",
        "        raw_text = \"\"\n",
        "        for image_path in images:\n",
        "            raw_text += extract_text_from_image(image_path) + \"\\n\"\n",
        "    else:\n",
        "        raw_text = extract_text_from_image(file.name)\n",
        "\n",
        "    tagger = NamedEntityTagger()\n",
        "    tokenizer = tagger.tokenizer\n",
        "\n",
        "    unwanted_terms = [\n",
        "        'ที่อยู่', 'โทรศัพท์', 'อีเมล', 'linkedin', ':', ',', '-', '|',\n",
        "        'ประวัติส่วนตัว', 'เกี่ยวกับฉัน', 'about me', 'ชื่อ', 'สกุล', 'tell', 'โทร', 'โทรงาน',\n",
        "        'ชื่อเล่น', 'อายุ', 'วันเกิด', 'พุทธ', 'ศาสนา', 'สัญชาติ', 'phone',\n",
        "        'ช่องทางการติดต่อ', '_', 're sume', 'resume', 'resu me', 'birth', 'date',\n",
        "        'address', 'email.', 'ประวัติ'\n",
        "    ]\n",
        "    unwanted_pattern = '|'.join(map(re.escape, unwanted_terms))\n",
        "\n",
        "    tagged_text, cleaned_text = tag_and_clean_text(raw_text, tagger, tokenizer, unwanted_pattern)\n",
        "    evaluation = generate_answer(cleaned_text, job_description)\n",
        "    result = extract_classification(evaluation)\n",
        "\n",
        "    df = pd.DataFrame([{\n",
        "        \"File\": os.path.basename(file.name),\n",
        "        \"Raw_Text\": raw_text,\n",
        "        \"Tagged_Text\": tagged_text,\n",
        "        \"Cleaned_Text\": cleaned_text,\n",
        "        \"Job_Description\": job_description,\n",
        "        \"Evaluation\": evaluation,\n",
        "        \"Result\": result,\n",
        "        \"Images\": images\n",
        "    }])\n",
        "    return df\n",
        "\n",
        "# Function to process multiple files (remains unchanged)\n",
        "def process_multiple_files(files, job_description, is_pdf=True):\n",
        "    all_results = pd.DataFrame()\n",
        "    for file in files:\n",
        "        df = process_file(file, job_description, is_pdf)\n",
        "        all_results = pd.concat([all_results, df], ignore_index=True)\n",
        "    return all_results\n",
        "\n",
        "# Modify the function to append results without loading the existing DataFrame\n",
        "def save_dataframe(df, save_path='/content/output.csv'):\n",
        "    try:\n",
        "        # Append new data directly to the CSV without reloading existing data\n",
        "        df.to_csv(save_path, mode='a', header=not os.path.exists(save_path), index=False, encoding='utf-8-sig')\n",
        "        return save_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving DataFrame: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to process a batch of DataFrame rows\n",
        "def generate_prompt_answer_optimized(row):\n",
        "    resume = row.get('Cleaned_Text', \"\")\n",
        "    job_description = row.get('Job_Description', \"\")\n",
        "    result = generate_answer(resume, job_description)\n",
        "    return result\n",
        "\n",
        "# Function to process a batch of rows\n",
        "def process_batch(batch_df):\n",
        "    return [generate_prompt_answer_optimized(row) for _, row in batch_df.iterrows()]\n",
        "\n",
        "# Batch processing with threading\n",
        "def batch_process(df, batch_size=32):\n",
        "    results = [None] * len(df)\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = {}\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            batch_df = df.iloc[i:i + batch_size]\n",
        "            future = executor.submit(process_batch, batch_df)\n",
        "            futures[future] = (i, i + batch_size)\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            start_idx, end_idx = futures[future]\n",
        "            batch_results = future.result()\n",
        "            results[start_idx:end_idx] = batch_results\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "esoz39MrswdM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **gradio interface**"
      ],
      "metadata": {
        "id": "u9Js0VMV379J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_interface(files, job_description, is_pdf, max_new_tokens, temperature, top_p, repetition_penalty):\n",
        "    try:\n",
        "        # Update model parameters\n",
        "        model_params.update({\n",
        "            \"max_new_tokens\": max_new_tokens,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p,\n",
        "            \"repetition_penalty\": repetition_penalty\n",
        "        })\n",
        "\n",
        "        df = process_multiple_files(files, job_description, is_pdf)\n",
        "        df['Evaluation'] = batch_process(df, batch_size=32)\n",
        "        df['Result'] = df['Evaluation'].apply(extract_classification)\n",
        "\n",
        "        # Ensure the 'Images' column is in the DataFrame\n",
        "        if 'Images' not in df.columns:\n",
        "            raise ValueError(\"The 'Images' column is missing from the DataFrame!\")\n",
        "\n",
        "        csv_path = save_dataframe(df)\n",
        "        df_output = df[[\"File\", \"Result\", \"Evaluation\", \"Images\"]]  # Output all required columns for Gradio\n",
        "        return df_output, csv_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in gradio_interface: {e}\")\n",
        "        return pd.DataFrame(), \"\""
      ],
      "metadata": {
        "id": "IPLUB-V90iqF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Async function to process row selection without unnecessary reloads\n",
        "async def show_evaluation(evt: gr.SelectData):\n",
        "    row_index = evt.index[0]\n",
        "    selected_eval = df.iloc[row_index][\"Evaluation\"]\n",
        "    image_files = df.iloc[row_index][\"Images\"]\n",
        "    first_image = image_files[0] if image_files else None\n",
        "    return str(selected_eval), first_image\n",
        "\n",
        "# Gradio interface creation with three-column layout\n",
        "def create_gradio_interface():\n",
        "    custom_theme = gr.themes.Default()\n",
        "\n",
        "    with gr.Blocks(theme=custom_theme) as demo:\n",
        "        with gr.Row():\n",
        "            # Left Section for Inputs\n",
        "            with gr.Column(scale=1):\n",
        "                file_input = gr.Files(label=\"Select PDF Files\", file_count=\"multiple\")\n",
        "                job_input = gr.Textbox(placeholder=\"Enter job description...\", label=\"Job Description\", lines=5)\n",
        "                submit_btn = gr.Button(\"Process\")\n",
        "                is_pdf_input = gr.Checkbox(label=\"PDF\", value=True)\n",
        "                max_new_tokens_input = gr.Slider(label=\"Max New Tokens\", minimum=50, maximum=1024, value=300, step=50)\n",
        "                temperature_input = gr.Slider(label=\"Temperature\", minimum=0.01, maximum=1.0, value=0.1, step=0.1)\n",
        "                top_p_input = gr.Slider(label=\"Top P\", minimum=0.1, maximum=1.0, value=0.95, step=0.05)\n",
        "                repetition_penalty_input = gr.Slider(label=\"Repetition Penalty\", minimum=0.1, maximum=2.0, value=1.0, step=0.1)\n",
        "\n",
        "            # Center Section for Results\n",
        "            with gr.Column(scale=1):\n",
        "                output_df = gr.DataFrame(\n",
        "                    headers=[\"File\", \"Result\"],\n",
        "                    type=\"pandas\",\n",
        "                    interactive=False,\n",
        "                )\n",
        "                output_csv = gr.DownloadButton(label=\"Download CSV\")\n",
        "\n",
        "            # Right Section for Evaluation and Preview\n",
        "            with gr.Column(scale=1):\n",
        "                eval_text = gr.Textbox(label=\"Evaluation Detail\", interactive=False, max_lines=15)\n",
        "                resume_image = gr.Image(label=\"Resume Preview\", interactive=False)\n",
        "\n",
        "        # Function to process inputs and generate output\n",
        "        def on_submit(files, job_description, is_pdf, max_new_tokens, temperature, top_p, repetition_penalty):\n",
        "            global df\n",
        "            df, csv_path = gradio_interface(files, job_description, is_pdf, max_new_tokens, temperature, top_p, repetition_penalty)\n",
        "            return df[[\"File\", \"Result\"]], csv_path\n",
        "\n",
        "        # Bind submit button to the processing function\n",
        "        submit_btn.click(on_submit,\n",
        "                         inputs=[file_input, job_input, is_pdf_input, max_new_tokens_input, temperature_input, top_p_input, repetition_penalty_input],\n",
        "                         outputs=[output_df, output_csv])\n",
        "\n",
        "        # Bind row selection to evaluation display function\n",
        "        output_df.select(show_evaluation, outputs=[eval_text, resume_image])\n",
        "\n",
        "    return demo"
      ],
      "metadata": {
        "id": "T2BbHjSvNw4R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wVOA6m2-53gT",
        "outputId": "902c9630-e47e-4c2a-ca54-e9af21c680dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://5eb91faf0446cfd25f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5eb91faf0446cfd25f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 510). Running this sequence through the model will result in indexing errors\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 510). Running this sequence through the model will result in indexing errors\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device))\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5eb91faf0446cfd25f.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "app = create_gradio_interface()\n",
        "app.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## software enginner (https://th.jobsdb.com/job/78728644?type=standout&ref=search-standalone#sol=56ea90da2ce55925ca5b5294f7dc6009051ee403)\n",
        "## business analysis (https://th.jobsdb.com/Business-Analysis-jobs?jobId=78724436&type=standout)\n",
        "## AI Engineer (https://th.jobsdb.com/AI-Engineer-jobs?jobId=78686025&type=standout)"
      ],
      "metadata": {
        "id": "oOW4Mg8tzkyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "a = pd.read_csv('/content/output.csv')\n",
        "a"
      ],
      "metadata": {
        "id": "bdPTbleERMtg",
        "outputId": "174b0475-1e45-4e2c-d309-7d8cd905fa8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              File                                           Raw_Text  \\\n",
              "0  resume dev1.pdf  thaaphoom babparn\\n software engineer\\npathum ...   \n",
              "1   resume hr1.pdf  resume\\n ประวัติส่วนตัว\\nadora mondmimi\\nอโดรา...   \n",
              "2   resume ai1.pdf  สมหญิง\\n แก้วกาจญ์\\n วิศวกรปัญญาประดิษฐ์\\nal ท...   \n",
              "3   resume ai3.pdf  re sume\\nประวัติส่วนตัว\\n090-123-4567\\n pimcha...   \n",
              "4   resume ai6.pdf   linkedin:\\nนภัสสร วิวัฒนาวงศ์\\nlinkedin.com i...   \n",
              "5   resume ai7.pdf  ปัญญา วิริยะชัย\\n วิศวกรปัญญาประดิษฐ์\\nประสบกา...   \n",
              "6   Resume ba3.pdf  ธนกร อินทรีย์พงษ์\\n ที่อยู่:\\n456 ถนนพระราม 3,...   \n",
              "\n",
              "                                         Tagged_Text  \\\n",
              "0  <LOCATION>tha</LOCATION><ORGANIZATION>a</ORGAN...   \n",
              "1  resume ประวัติส่วนตัว<PERSON> adora</PERSON><P...   \n",
              "2  <PERSON>ส</PERSON><PERSON>สม</PERSON><PERSON>ห...   \n",
              "3  re sume ประวัติส่วนตัว<PHONE> 09</PHONE><PHONE...   \n",
              "4  <URL>linkedin</URL>:<PERSON> </PERSON><PERSON>...   \n",
              "5  <PERSON>ป</PERSON><PERSON>ปัญญา วิริยะชัย</PER...   \n",
              "6  <PERSON>ธ</PERSON><PERSON>ธน</PERSON><PERSON>ก...   \n",
              "\n",
              "                                        Cleaned_Text  \\\n",
              "0  aparn software engineer accenture application ...   \n",
              "1  ข้อมูลติดต่อ เกียวกับฉัน เล่น        st. 123 a...   \n",
              "2  วิศวกรปัญญาประดิษฐ์ ai ที่มีประสบการณ์ 3 ปีในก...   \n",
              "3  ผู้ เชี่ยวชาญด้าน ai ที่มีประสบการณ์ 4 เขี ในด...   \n",
              "4  in  วิศวกรปัญญาประดิษฐ์ ประสบการณ์การทํางาน วิ...   \n",
              "5  วิศวกรปัญญาประดิษฐ์ ประสบการณ์การฝึกงาน บัณฑิต...   \n",
              "6  เป้าหมายในการทํางาน มุ่งมันที่จะใช้ความรู้และท...   \n",
              "\n",
              "                                     Job_Description  \\\n",
              "0  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "1  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "2  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "3  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "4  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "5  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "6  **Software Engineer (Junior/Senior/Specialist)...   \n",
              "\n",
              "                                          Evaluation      Result  \\\n",
              "0  ---\\n\\n**Classification**: Reconsider\\n**Ratio...  Reconsider   \n",
              "1  ---\\n\\n## **Evaluation**:\\n\\n**Classification*...   Unrelated   \n",
              "2  ---\\n\\n**Classification**: Reconsider\\n**Ratio...  Reconsider   \n",
              "3  ---\\n\\n**Classification**: Unrelated\\n**Ration...   Unrelated   \n",
              "4  ---\\n\\n### **Evaluation**:\\n\\n**Classification...  Reconsider   \n",
              "5  ---\\n\\n### **Evaluation**:\\n\\n**Classification...   Unrelated   \n",
              "6  ---\\n\\n**Classification**: Unrelated\\n**Ration...   Unrelated   \n",
              "\n",
              "                                         Images  \n",
              "0  ['/content/images/resume dev1/page_001.png']  \n",
              "1   ['/content/images/resume hr1/page_001.png']  \n",
              "2   ['/content/images/resume ai1/page_001.png']  \n",
              "3   ['/content/images/resume ai3/page_001.png']  \n",
              "4   ['/content/images/resume ai6/page_001.png']  \n",
              "5   ['/content/images/resume ai7/page_001.png']  \n",
              "6   ['/content/images/Resume ba3/page_001.png']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbc1bc4a-c358-4e6c-ba3c-dff847daba9c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File</th>\n",
              "      <th>Raw_Text</th>\n",
              "      <th>Tagged_Text</th>\n",
              "      <th>Cleaned_Text</th>\n",
              "      <th>Job_Description</th>\n",
              "      <th>Evaluation</th>\n",
              "      <th>Result</th>\n",
              "      <th>Images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>resume dev1.pdf</td>\n",
              "      <td>thaaphoom babparn\\n software engineer\\npathum ...</td>\n",
              "      <td>&lt;LOCATION&gt;tha&lt;/LOCATION&gt;&lt;ORGANIZATION&gt;a&lt;/ORGAN...</td>\n",
              "      <td>aparn software engineer accenture application ...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n**Classification**: Reconsider\\n**Ratio...</td>\n",
              "      <td>Reconsider</td>\n",
              "      <td>['/content/images/resume dev1/page_001.png']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>resume hr1.pdf</td>\n",
              "      <td>resume\\n ประวัติส่วนตัว\\nadora mondmimi\\nอโดรา...</td>\n",
              "      <td>resume ประวัติส่วนตัว&lt;PERSON&gt; adora&lt;/PERSON&gt;&lt;P...</td>\n",
              "      <td>ข้อมูลติดต่อ เกียวกับฉัน เล่น        st. 123 a...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n## **Evaluation**:\\n\\n**Classification*...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>['/content/images/resume hr1/page_001.png']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>resume ai1.pdf</td>\n",
              "      <td>สมหญิง\\n แก้วกาจญ์\\n วิศวกรปัญญาประดิษฐ์\\nal ท...</td>\n",
              "      <td>&lt;PERSON&gt;ส&lt;/PERSON&gt;&lt;PERSON&gt;สม&lt;/PERSON&gt;&lt;PERSON&gt;ห...</td>\n",
              "      <td>วิศวกรปัญญาประดิษฐ์ ai ที่มีประสบการณ์ 3 ปีในก...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n**Classification**: Reconsider\\n**Ratio...</td>\n",
              "      <td>Reconsider</td>\n",
              "      <td>['/content/images/resume ai1/page_001.png']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>resume ai3.pdf</td>\n",
              "      <td>re sume\\nประวัติส่วนตัว\\n090-123-4567\\n pimcha...</td>\n",
              "      <td>re sume ประวัติส่วนตัว&lt;PHONE&gt; 09&lt;/PHONE&gt;&lt;PHONE...</td>\n",
              "      <td>ผู้ เชี่ยวชาญด้าน ai ที่มีประสบการณ์ 4 เขี ในด...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n**Classification**: Unrelated\\n**Ration...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>['/content/images/resume ai3/page_001.png']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>resume ai6.pdf</td>\n",
              "      <td>linkedin:\\nนภัสสร วิวัฒนาวงศ์\\nlinkedin.com i...</td>\n",
              "      <td>&lt;URL&gt;linkedin&lt;/URL&gt;:&lt;PERSON&gt; &lt;/PERSON&gt;&lt;PERSON&gt;...</td>\n",
              "      <td>in  วิศวกรปัญญาประดิษฐ์ ประสบการณ์การทํางาน วิ...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n### **Evaluation**:\\n\\n**Classification...</td>\n",
              "      <td>Reconsider</td>\n",
              "      <td>['/content/images/resume ai6/page_001.png']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>resume ai7.pdf</td>\n",
              "      <td>ปัญญา วิริยะชัย\\n วิศวกรปัญญาประดิษฐ์\\nประสบกา...</td>\n",
              "      <td>&lt;PERSON&gt;ป&lt;/PERSON&gt;&lt;PERSON&gt;ปัญญา วิริยะชัย&lt;/PER...</td>\n",
              "      <td>วิศวกรปัญญาประดิษฐ์ ประสบการณ์การฝึกงาน บัณฑิต...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n### **Evaluation**:\\n\\n**Classification...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>['/content/images/resume ai7/page_001.png']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Resume ba3.pdf</td>\n",
              "      <td>ธนกร อินทรีย์พงษ์\\n ที่อยู่:\\n456 ถนนพระราม 3,...</td>\n",
              "      <td>&lt;PERSON&gt;ธ&lt;/PERSON&gt;&lt;PERSON&gt;ธน&lt;/PERSON&gt;&lt;PERSON&gt;ก...</td>\n",
              "      <td>เป้าหมายในการทํางาน มุ่งมันที่จะใช้ความรู้และท...</td>\n",
              "      <td>**Software Engineer (Junior/Senior/Specialist)...</td>\n",
              "      <td>---\\n\\n**Classification**: Unrelated\\n**Ration...</td>\n",
              "      <td>Unrelated</td>\n",
              "      <td>['/content/images/Resume ba3/page_001.png']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbc1bc4a-c358-4e6c-ba3c-dff847daba9c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbc1bc4a-c358-4e6c-ba3c-dff847daba9c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbc1bc4a-c358-4e6c-ba3c-dff847daba9c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ca12b0f-bf08-4741-a8cd-f911abc90cd7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ca12b0f-bf08-4741-a8cd-f911abc90cd7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ca12b0f-bf08-4741-a8cd-f911abc90cd7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5392099d-17a2-47d2-9350-809f0f2cd3c9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('a')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5392099d-17a2-47d2-9350-809f0f2cd3c9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('a');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "a",
              "summary": "{\n  \"name\": \"a\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"File\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"resume dev1.pdf\",\n          \"resume hr1.pdf\",\n          \"resume ai7.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Raw_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"thaaphoom babparn\\n software engineer\\npathum thani, thailand\\ntp babparn ogmail.com\\n+668-8917-0359\\n github.\\n linkedin .com/ in/ thanaphoom babparn\\n.com marttp\\nprofessional experience\\n accenture, bangtok., thailand\\n january 2021 -]u| 2022\\napplication development senior analyst qjava., spring webflur, mongodb, aws kubernetes, kafka, python., jenkins, vault, redis)\\n initiated and developed deep linkts hiding solutions for repayment, by using ttl key value store, prevent by token scopes\\nitoring\\n recognized\\nstrength in men\\n managed as\\nas the engineer who has\\nand consulting\\nbackend lead in the team, and was\\na\\n technology\\n takeholders,\\n advised, consulted, and collaborated on\\n terms and software architecture with cross functional s\\nsenior engineers, and development managers in the java enterprise-scale banking / fnancial project.\\n suggested to team lead and take action to design., code, and deploy statement digitization process with publish- subscribe\\n pattern with kafka to eliminate synchronous process, cut processing time from 10 seconds to 2 seconds.\\ntraining\\n development team about kubernetes, microservices architecture, and cloud native\\n conducted\\n sessions to the\\n including the enterprise tools with reliability and security practice, and reduced onboarding time by around 40%.\\narchitecture\\n created and maintained spring webflux internal libraries and architect the java microservice templates for enterprise-scale\\n repetition by around 30%.\\n development base practices. as a result, disposing of the duplication of code caused by\\nbased on\\n application development analyst microservice developer, java, spring\\nspring webflus, kubernetes, bash, mongodb, mys0l)\\n boot,\\n creating the bash script\\n migrated kong api gateway confguration from a manual process that takes\\nto 3 minutes by\\nhours\\nfor automated migration working by reading ajson confguration fle and calling the restful confgurations api.\\n client credentials and authorization code methods for the exchange data process\\nusing\\nimplemented oauth 2.0 solution by\\nkong\\napi gateway (ce).\\nfor partner vendors with\\n application by using jpa pagination api.\\n optimized manual pagination logic on restfil api fom java spring boot\\n improve the query time from 3400 milliseconds to 500 milliseconds.\\naware technology solutions, bangkok., thailand\\n may\\n dec 2020\\n2019\\n\\n software engineer 1 (full-stack development, hode.is, kotlin, android., sol, mongodb microservices, docker; kubernetes, gcp)\\n focused on kotlin android fuall stack development and delivered a software project that supports 1k+ telecommunication\\n talling\\n companys technical engineers to collect customer information about inse\\nthe internet related.\\n coached new members of software engineers and instructed technologies to the team for innovative products.\\n researched., designed, and managed to build scalability, and reliable system for work time-attendance solution used more than\\nhundreds of users inside corporate by hode.is microservice architecture to work with the oracle database.\\nassociate software engineer (backend development, javascript., hode.js., postgre$ql, mongodb docker;, linur, azure)\\n \\\"superse\\n quality of software solutions delivered and business growth.\\ntar of the company'\\nawarded as one of\\ndue to\\n coded and implementation a hode.is expense approval system to help support the clients internal approval policy as\\n web\\na\\napplication to support 2k+ employees working with postgre$ol.\\nprojects\\n github.com / marttp/ java tech interviews prep\\n prep\\n[general] qava, guideline)\\n java technical interview\\nresources for software engineers who want to learn and be better in technical knowledge  focusing on java and currently in thai).\\n github.com marttp./ boba-shop traffic\\nboba shop [be] (spring boot, kotlin, mockk, junit5, hode.js, kubernetes, mysql)\\n mocking order traffc for one medium size boba\\n including high -level/ estimation design.\\n shop,\\n github.com marttp./ spring boot kt upload excel file-to mongodb\\nspring boot\\n excel file to mongodb\\n example of use case to upload excel file to spring boot api developed by kotlin.\\n education\\n rajamangala university of technology thanyaburi pathum thani, thaiand\\n march 2019\\n bachelors of engineering in computer engineering\\nshills\\n java/ kotlin / javascript/ pthon/ go\\nsol mongodb/ redis_\\nkafka\\ninfrastructure as code\\n android development\\n cloud native/ serverless architecture\\nmonitoring / troubleshooting/ testing\\n mentoring/ leadership\\n distributed systems / microservices\\nspring boot/ spring webflux\\nawards & actiities\\njibility\\n friendly\\\" kotlin, android, tensorflow).\\nsecond runner up at\\naccessible learning hackathon 2018\\\" with the team\\naccess\\nii\\n welsign project of accenture thailand as\\n collaborating\\n developer & devops role (spring boot., django, go).\\n backend\\nin the\\na\\n\",\n          \"resume\\n \\u0e1b\\u0e23\\u0e30\\u0e27\\u0e31\\u0e15\\u0e34\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e15\\u0e31\\u0e27\\nadora mondmimi\\n\\u0e2d\\u0e42\\u0e14\\u0e23\\u0e32 \\u0e21\\u0e2d\\u0e19\\u0e15\\u0e4c\\u0e21\\u0e34\\u0e19\\u0e35\\n\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e15\\u0e34\\u0e14\\u0e15\\u0e48\\u0e2d\\n\\u0e40\\u0e01\\u0e35\\u0e22\\u0e27\\u0e01\\u0e31\\u0e1a\\u0e09\\u0e31\\u0e19\\n\\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e25\\u0e48\\u0e19\\n\\u0e42\\u0e14\\u0e23\\u0e32\\n:\\n123-456-7890\\n\\u0e27\\u0e31\\u0e19\\u0e40\\u0e01\\u0e34\\u0e14 : 7 \\u0e2a\\u0e34\\u0e07\\u0e2b\\u0e32\\u0e04\\u0e21 2546\\nww\\u0e1e. reallygreatsite. com\\n \\u0e2d\\u0e32\\u0e22\\u0e38 : 20 \\u0e1b\\u0e35\\n hello @reallygreatsite. com\\n\\u0e28\\u0e32\\u0e2a\\u0e19\\u0e32\\n\\u0e1e\\u0e38\\u0e17\\u0e18\\nst.,\\n123 anywhere\\n\\u0e40\\u0e0a\\u0e37\\u0e49\\u0e2d\\u0e0a\\u0e32\\u0e15\\u0e34\\n\\u0e44\\u0e17\\u0e22\\ncity,\\nany\\n$t 12345\\n\\u0e44\\u0e17\\u0e22\\n\\u0e2a\\u0e31\\u0e0d\\u0e0a\\u0e32\\u0e15\\u0e34\\n:\\n \\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e17\\u0e33\\u0e07\\u0e32\\u0e19\\n\\u0e17\\u0e31\\u0e01\\u0e29\\u0e30\\u0e1e\\u0e34\\u0e40\\u0e28\\u0e29\\n \\u0e17\\u0e31\\u0e01\\u0e29\\u0e30\\u0e01\\u0e32\\u0e23\\u0e2a\\u0e37\\u0e48\\u0e2d\\u0e2a\\u0e32\\u0e23\\u0e14\\u0e35\\u0e40\\u0e22\\u0e35\\u0e48\\u0e22\\u0e21\\n\\u0e14\\u0e39\\u0e41\\u0e25\\u0e07\\u0e32\\u0e19\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e43\\u0e2b\\u0e49\\u0e01\\u0e31\\u0e1a\\u0e17\\u0e32\\u0e07\\n2558\\n \\u0e1a\\u0e23\\u0e34\\u0e29\\u0e31\\u0e17\\n\\u0e17\\u0e33\\u0e07\\u0e32\\u0e19\\u0e23\\u0e48\\u0e27\\u0e21\\u0e01\\u0e31\\u0e1a\\u0e17\\u0e35\\u0e21\\u0e44\\u0e14\\u0e49\\u0e14\\u0e35\\n \\u0e2b\\u0e31\\u0e27\\u0e2b\\u0e19\\u0e49\\u0e32\\u0e07\\u0e32\\u0e19\\u0e08\\u0e31\\u0e14\\u0e01\\u0e32\\u0e23\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\n2559\\n \\u0e43\\u0e0a\\u0e49\\u0e07\\u0e32\\u0e19\\u0e42\\u0e1b\\u0e23\\u0e41\\u0e01\\u0e23\\u0e21\\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\n\\u0e17\\u0e33\\u0e07\\u0e32\\u0e19\\u0e01\\u0e31\\u0e1a\\u0e41\\u0e23\\u0e07\\u0e01\\u0e14\\u0e14\\u0e31\\u0e19\\u0e44\\u0e14\\u0e49\\u0e14\\u0e35\\n\\u0e1c\\u0e39\\u0e49\\u0e08\\u0e31\\u0e14\\u0e01\\u0e32\\u0e23\\u0e1d\\u0e32\\u0e22\\u0e01\\u0e32\\u0e23\\u0e15\\u0e25\\u0e32\\u0e14\\n2560\\n\\u0e2a\\u0e32\\u0e21\\u0e32\\u0e23\\u0e16\\u0e43\\u0e0a\\u0e49\\u0e07\\u0e32\\u0e19\\u0e42\\u0e1b\\u0e23\\u0e41\\u0e01\\u0e23\\u0e21\\n2562\\n\\u0e1c\\u0e39\\u0e49\\u0e08\\u0e31\\u0e14\\u0e01\\u0e32\\u0e23\\u0e1d\\u0e48\\u0e32\\u0e22\\u0e1c\\u0e25\\u0e34\\u0e15\\n \\u0e40\\u0e2d\\u0e01\\u0e2a\\u0e32\\u0e23\\u0e44\\u0e14\\u0e49\\n\",\n          \"\\u0e1b\\u0e31\\u0e0d\\u0e0d\\u0e32 \\u0e27\\u0e34\\u0e23\\u0e34\\u0e22\\u0e30\\u0e0a\\u0e31\\u0e22\\n \\u0e27\\u0e34\\u0e28\\u0e27\\u0e01\\u0e23\\u0e1b\\u0e31\\u0e0d\\u0e0d\\u0e32\\u0e1b\\u0e23\\u0e30\\u0e14\\u0e34\\u0e29\\u0e10\\u0e4c\\n\\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e01\\u0e32\\u0e23\\u0e1d\\u0e36\\u0e01\\u0e07\\u0e32\\u0e19\\n\\u0e1a\\u0e31\\u0e13\\u0e11\\u0e34\\u0e15\\u0e08\\u0e1a\\u0e43\\u0e2b\\u0e21\\u0e48\\u0e2a\\u0e32\\u0e02\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e01\\u0e32\\u0e23\\u0e04\\u0e2d\\u0e21\\u0e1e\\u0e34\\u0e27\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c\\u0e17\\u0e35\\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21\\n\\u0e19\\u0e31\\u0e01\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e1d\\u0e36\\u0e01\\u0e2b\\u0e31\\u0e14 al\\n\\u0e2a\\u0e19\\u0e43\\u0e08\\u0e41\\u0e25\\u0e30\\u0e17\\u0e31\\u0e01\\u0e29\\u0e30\\u0e14\\u0e49\\u0e32\\u0e19 al \\u0e41\\u0e25\\u0e30 machine learning \\u0e1c\\u0e48\\u0e32\\u0e19\\n \\u0e1a\\u0e23\\u0e34\\u0e29\\u0e31\\u0e17 \\u0e42\\u0e2d\\u0e17\\u0e35 \\u0e42\\u0e0b\\u0e25\\u0e39\\u0e0a\\u0e31\\u0e19\\u0e2a\\u0e4c \\u0e08\\u0e33\\u0e01\\u0e31\\u0e14\\n\\u0e1e\\u0e24\\u0e29\\u0e20\\u0e32\\u0e04\\u0e21 2023\\n \\u0e2a\\u0e34\\u0e07\\u0e2b\\u0e32\\u0e04\\u0e21 2023\\n\\u0e01\\u0e32\\u0e23\\u0e17\\u0e33\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e17\\u0e31\\u0e49\\u0e07\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e23\\u0e35\\u0e22\\u0e19\\u0e41\\u0e25\\u0e30\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e15\\u0e31\\u0e27 \\u0e21\\u0e35\\n\\n\\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 machine learning\\n\\u0e0a\\u0e48\\u0e27\\u0e22\\u0e17\\u0e35\\u0e21\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 machine learning \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e1e\\u0e22\\u0e32\\u0e01\\u0e23\\u0e13\\u0e4c\\n deep learning \\u0e14\\u0e49\\u0e27\\u0e22 python \\u0e41\\u0e25\\u0e30\\n\\u0e41\\u0e25\\u0e30\\n\\u0e22\\u0e2d\\u0e14\\u0e02\\u0e32\\u0e22\\u0e2a\\u0e34\\u0e19\\u0e04\\u0e49\\u0e32\\ntensorflow \\u0e21\\u0e38\\u0e48\\u0e07\\u0e21\\u0e31\\u0e19\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e17\\u0e31\\u0e01\\u0e29\\u0e30 al \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e2a\\u0e23\\u0e49\\u0e32\\u0e07\\u0e42\\u0e0b\\u0e25\\u0e39\\u0e0a\\u0e31\\u0e19\\n\\u0e17\\u0e33\\u0e01\\u0e32\\u0e23\\u0e17\\u0e14\\u0e2a\\u0e2d\\u0e1a\\u0e41\\u0e25\\u0e30\\u0e1b\\u0e23\\u0e31\\u0e1a\\u0e1b\\u0e23\\u0e38\\u0e07\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25\\u0e14\\u0e49\\u0e27\\u0e22\\u0e40\\u0e17\\u0e04\\u0e19\\u0e34\\u0e04\\n\\u0e17\\u0e35\\u0e48\\u0e21\\u0e35\\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e34\\u0e17\\u0e18\\u0e34\\u0e20\\u0e32\\u0e1e\\n hyperparameter tuning\\n\\u0e40\\u0e23\\u0e35\\u0e22\\u0e19\\u0e23\\u0e39\\u0e49\\u0e41\\u0e25\\u0e30\\u0e43\\u0e0a\\u0e49\\u0e40\\u0e04\\u0e23\\u0e37\\u0e48\\u0e2d\\u0e07\\u0e21\\u0e37\\u0e2d\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e31\\u0e14\\u0e01\\u0e32\\u0e23\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e41\\u0e25\\u0e30\\u0e01\\u0e32\\u0e23\\u0e1d\\u0e36\\u0e01\\n\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 al\\n\\u0e17\\u0e31\\u0e01\\u0e29\\u0e30\\n\\u0e20\\u0e32\\u0e29\\u0e32\\u0e42\\u0e1b\\u0e23\\u0e41\\u0e01\\u0e23\\u0e21: python, c++\\n\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e43\\u0e19\\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31\\u0e22\\nmachine learning: scikit learn,\\n\\u0e01\\u0e32\\u0e23\\u0e27\\u0e34\\u0e40\\u0e04\\u0e23\\u0e32\\u0e30\\u0e2b\\u0e4c\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32\\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e23\\u0e30\\u0e1a\\u0e38\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\ntensorflow, keras\\n\\u0e01\\u0e32\\u0e23\\u0e08\\u0e31\\u0e14\\u0e01\\u0e32\\u0e23\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25: sol, pandas, numpy\\n(emotion recognition)\\n\\u0e40\\u0e04\\u0e23\\u0e37\\u0e48\\u0e2d\\u0e07\\u0e21\\u0e37\\u0e2d\\u0e2d\\u0e37\\u0e48\\u0e19\\u0e46: git, jupyter notebook\\n\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 deep learning \\u0e14\\u0e49\\u0e27\\u0e22 tensorflow \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\n \\u0e08\\u0e33\\u0e41\\u0e19\\u0e01\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\u0e08\\u0e32\\u0e01\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32\\n\\u0e43\\u0e0a\\u0e49\\u0e0a\\u0e38\\u0e14\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 fer2013 \\u0e41\\u0e25\\u0e30\\u0e1d\\u0e36\\u0e01\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 cnn \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21\\n\\u0e0a\\u0e48\\u0e2d\\u0e07\\u0e17\\u0e32\\u0e07\\u0e01\\u0e32\\u0e23\\u0e15\\u0e34\\u0e14\\u0e15\\u0e48\\u0e2d\\n\\u0e04\\u0e27\\u0e32\\u0e21\\u0e41\\u0e21\\u0e48\\u0e19\\u0e22\\u0e33\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e33\\u0e41\\u0e19\\u0e01\\nphone: 080-123-4567\\n\\u0e01\\u0e32\\u0e23\\u0e27\\u0e34\\u0e40\\u0e04\\u0e23\\u0e32\\u0e30\\u0e2b\\u0e4c\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e2b\\u0e47\\u0e19\\u0e1a\\u0e19\\u0e42\\u0e0b\\u0e40\\u0e0a\\u0e35\\u0e22\\u0e25\\u0e21\\u0e35\\u0e40\\u0e14\\u0e35\\u0e22\\nemail: panya@example. com\\n(sentiment analysis)\\n linkedin: linkedin. com in panyaviriyachai\\n github: github.com panyaviriyachai\\n\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 deep learning \\u0e14\\u0e49\\u0e27\\u0e22 tensorflow \\u0e40\\u0e1e\\u0e37\\u0e2d\\n \\u0e08\\u0e33\\u0e41\\u0e19\\u0e01\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\u0e08\\u0e32\\u0e01\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32\\n\\u0e43\\u0e0a\\u0e49\\u0e0a\\u0e38\\u0e14\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 fer2013 \\u0e41\\u0e25\\u0e30\\u0e1d\\u0e36\\u0e01\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 cnn \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21\\n\\u0e04\\u0e27\\u0e32\\u0e21\\u0e41\\u0e21\\u0e48\\u0e19\\u0e22\\u0e33\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e33\\u0e41\\u0e19\\u0e01\\n\\u0e01\\u0e32\\u0e23\\u0e28\\u0e36\\u0e01\\u0e29\\u0e32\\n \\u0e1b\\u0e23\\u0e30\\u0e01\\u0e32\\u0e28\\u0e19\\u0e35\\u0e22\\u0e1a\\u0e31\\u0e15\\u0e23\\n \\u0e1b\\u0e23\\u0e34\\u0e0d\\u0e0d\\u0e32\\u0e15\\u0e23\\u0e35\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c \\u0e2a\\u0e32\\u0e02\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e01\\u0e32\\u0e23\\u0e04\\u0e2d\\u0e21\\u0e1e\\u0e34\\u0e27\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c\\n\\u0e08\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e28\\u0e36\\u0e01\\u0e29\\u0e32: \\u0e1e\\u0e24\\u0e29\\u0e20\\u0e32\\u0e04\\u0e21 2024\\n\\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31\\u0e22\\u0e40\\u0e01\\u0e29\\u0e15\\u0e23\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c\\n \\u0e43\\u0e0a\\u0e49 nlp \\u0e41\\u0e25\\u0e30 machine learning \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e27\\u0e34\\u0e40\\u0e04\\u0e23\\u0e32\\u0e30\\u0e2b\\u0e4c\\u0e04\\u0e27\\u0e32\\u0e21\\u0e04\\u0e34\\u0e14\\n\\u0e40\\u0e2b\\u0e47\\u0e19\\u0e08\\u0e32\\u0e01\\u0e42\\u0e0b\\u0e40\\u0e0a\\u0e35\\u0e22\\u0e25\\u0e21\\u0e35\\u0e40\\u0e14\\u0e35\\u0e22\\n \\u0e40\\u0e01\\u0e23\\u0e14\\u0e40\\u0e09\\u0e25\\u0e35\\u0e22: 3.70\\n \\u0e43\\u0e0a\\u0e49 python, scikit learn \\u0e41\\u0e25\\u0e30 nltk \\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\n\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e27\\u0e34\\u0e08\\u0e31\\u0e22: \\u0e3a\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 deep\\n\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25\\u0e01\\u0e32\\u0e23\\u0e08\\u0e31\\u0e14\\u0e2b\\u0e21\\u0e27\\u0e14\\u0e2b\\u0e21\\u0e39\\u0e48\\u0e04\\u0e27\\u0e32\\u0e21\\u0e04\\u0e34\\u0e14\\u0e40\\u0e2b\\u0e47\\u0e19\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e1a\\u0e27\\u0e01\\u0e2b\\u0e23\\u0e37\\u0e2d\\u0e25\\u0e1a\\n learning \\u0e2a\\u0e33\\u0e2b\\u0e23\\u0e31\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e17\\u0e33\\u0e19\\u0e32\\u0e22\\u0e04\\u0e27\\u0e32\\u0e21\\u0e15\\u0e49\\u0e2d\\u0e07\\u0e01\\u0e32\\u0e23\\u0e02\\u0e2d\\u0e07\\n\\u0e25\\u0e39\\u0e01\\u0e04\\u0e49\\u0e32\\u0e43\\u0e19\\u0e23\\u0e30\\u0e1a\\u0e1a\\u0e2d\\u0e35\\u0e04\\u0e2d\\u0e21\\u0e40\\u0e21\\u0e34\\u0e23\\u0e4c\\u0e0b\\n\\u0e01\\u0e34\\u0e08\\u0e01\\u0e23\\u0e23\\u0e21\\u0e41\\u0e25\\u0e30\\u0e04\\u0e27\\u0e32\\u0e21\\u0e2a\\u0e19\\u0e43\\u0e08\\n\\u0e2a\\u0e21\\u0e32\\u0e0a\\u0e34\\u0e01\\u0e0a\\u0e21\\u0e23\\u0e21\\u0e27\\u0e34\\u0e08\\u0e31\\u0e22\\u0e41\\u0e25\\u0e30\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32 al \\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31\\u0e22\\n \\u0e40\\u0e01\\u0e29\\u0e15\\u0e23\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c\\n\\u0e2a\\u0e19\\u0e43\\u0e08\\u0e01\\u0e32\\u0e23\\u0e1b\\u0e23\\u0e30\\u0e22\\u0e38\\u0e01\\u0e15\\u0e4c\\u0e43\\u0e0a\\u0e49 al \\u0e43\\u0e19\\u0e14\\u0e49\\u0e32\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e22\\u0e32\\u0e01\\u0e23\\u0e13\\u0e4c\\u0e17\\u0e32\\u0e07\\u0e18\\u0e38\\u0e23\\u0e01\\u0e34\\u0e08\\n\\u0e41\\u0e25\\u0e30\\u0e01\\u0e32\\u0e23\\u0e27\\u0e34\\u0e40\\u0e04\\u0e23\\u0e32\\u0e30\\u0e2b\\u0e4c \\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e40\\u0e0a\\u0e34\\u0e07\\u0e25\\u0e36\\u0e01\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tagged_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"<LOCATION>tha</LOCATION><ORGANIZATION>a</ORGANIZATION><LOCATION>pho</LOCATION><LOCATION>om</LOCATION><URL> bab</URL><ORGANIZATION>parn</ORGANIZATION> software<ORGANIZATION> engineer</ORGANIZATION><LOCATION> pat</LOCATION><LOCATION>hum thani</LOCATION>,<LOCATION> thailand</LOCATION><URL> tp bab</URL><EMAIL>parn ogmail.</EMAIL><URL>com</URL><PHONE> +</PHONE><PHONE>668-8917-0359</PHONE><URL> github. linkedin .com/ in/ </URL><URL>thana</URL><EMAIL>pho</EMAIL><EMAIL>om</EMAIL><URL> babparn .com marttp professional experience</URL><ORGANIZATION> accenture</ORGANIZATION>,<LOCATION> bang</LOCATION><LOCATION>tok.</LOCATION>,<LOCATION> thailand</LOCATION><DATE> january 2021 -]u| 2022</DATE> application development senior analyst q<ORGANIZATION>java</ORGANIZATION>\\nbanking / fnancial project. suggested to team lead and take action to design., code, and deploy statement digitization process with publish- subscribe pattern with kafka to eliminate synchronous process, cut processing time from<TIME> 10 seconds</TIME> to<TIME> 2 seconds</TIME>\\nmanual process that takes to<TIME> 3 minutes by</TIME> hours for automated migration working by reading ajson confguration fle and calling the restful confgurations api. client credentials and authorization code methods for the exchange data process using implemented oauth 2.0 solution by kong api gateway (ce). for partner vendors with application by using jpa pagination api. optimized manual pagination logic on restfil api fom java spring boot improve the query time from 3400 milliseconds to 500 milliseconds. aware technology solutions,<LOCATION> bangkok</LOCATION>.,<DATE> thailand</DATE><DATE> may dec 2020 2019</DATE>\\ncoached new members of software engineers and instructed technologies to the team for innovative products. researched., designed, and managed to build scalability, and reliable system for work time-attendance solution used more than hundreds of users inside corporate by hode.is microservice architecture to work with the oracle database. associate software engineer (backend development, javascript., hode<URL>.</URL>js., postgre$ql, mon<ORGANIZATION>god</ORGANIZATION>b docker;, linur, azure) \\\"superse quality of software solutions delivered and business growth. tar of the company' awarded as one of due to coded and implementation a hode.is expense approval system to help support the clients internal approval policy as web a application to support 2k+ employees working with postgre$ol. projects<URL> github.com / marttp</URL>\\nwant to learn and be better in technical knowledge focusing on java and currently in thai).<URL> git</URL><URL>hub.com marttp./ boba-shop</URL> traffic boba<URL> shop</URL> [be] (spring boot, kotlin, mockk, junit5, hode.js, kubernetes, mysql) mocking order traffc for one medium size boba including high -level/ estimation design. shop,<URL> git</URL><URL>hub.com marttp./ spring boot</URL> kt upload excel file-to mongodb spring boot excel file to mongodb example of use case to upload excel file to spring boot api developed by<ORGANIZATION> kot</ORGANIZATION><ORGANIZATION>lin</ORGANIZATION><URL>.</URL><EMAIL> education</EMAIL><LOCATION> raja</LOCATION><LOCATION>mangala</LOCATION><ORGANIZATION> university of</ORGANIZATION><LOCATION> technology</LOCATION><LOCATION> tha</LOCATION><LOCATION>nyaburi</LOCATION><LOCATION> pat</LOCATION><LOCATION>hum thani</LOCATION>,<LOCATION> thaiand march 2019</LOCATION>\\nted systems / microservices spring boot/ spring webflux awards & actiities jibility friendly\\\" kotlin, android, tensorflow). second runner up at accessible learning hackathon 2018\\\" with the team access ii welsign project of accenture thailand as collaborating developer & devops role (spring boot., django, go). backend in the a\",\n          \"resume \\u0e1b\\u0e23\\u0e30\\u0e27\\u0e31\\u0e15\\u0e34\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e15\\u0e31\\u0e27<PERSON> adora</PERSON><PERSON> mond</PERSON><PERSON>m</PERSON><PERSON>imi</PERSON><PERSON> \\u0e2d</PERSON><PERSON>\\u0e42\\u0e14\\u0e23</PERSON><PERSON>\\u0e32 \\u0e21\\u0e2d\\u0e19\\u0e15\\u0e4c\\u0e21\\u0e34\\u0e19\\u0e35</PERSON> \\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e15\\u0e34\\u0e14\\u0e15\\u0e48\\u0e2d \\u0e40\\u0e01\\u0e35\\u0e22\\u0e27\\u0e01\\u0e31\\u0e1a\\u0e09\\u0e31\\u0e19 \\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e25\\u0e48\\u0e19<PERSON> </PERSON><PERSON>\\u0e42\\u0e14\\u0e23</PERSON><PERSON>\\u0e32</PERSON> :<PERSON> 123</PERSON><PHONE>-456-7890</PHONE> \\u0e27\\u0e31\\u0e19\\u0e40\\u0e01\\u0e34\\u0e14 :<DATE> 7 \\u0e2a\\u0e34\\u0e07\\u0e2b\\u0e32\\u0e04\\u0e21 2546</DATE><URL> w</URL><URL>w</URL><URL>\\u0e1e. reallygreatsite. com</URL> \\u0e2d\\u0e32\\u0e22\\u0e38 :<AGO> 20 \\u0e1b\\u0e35</AGO><URL> hello</URL><URL> @</URL><URL>real</URL><URL>lygreatsite. com</URL> \\u0e28\\u0e32\\u0e2a\\u0e19\\u0e32 \\u0e1e\\u0e38\\u0e17\\u0e18 st., 123 anywhere \\u0e40\\u0e0a\\u0e37\\u0e49\\u0e2d\\u0e0a\\u0e32\\u0e15\\u0e34 \\u0e44\\u0e17\\u0e22 city, any $<URL>t</URL> 12345<LOCATION> </LOCATION><LOCATION>\\u0e44\\u0e17\\u0e22</LOCATION>\",\n          \"<PERSON>\\u0e1b</PERSON><PERSON>\\u0e1b\\u0e31\\u0e0d\\u0e0d\\u0e32 \\u0e27\\u0e34\\u0e23\\u0e34\\u0e22\\u0e30\\u0e0a\\u0e31\\u0e22</PERSON> \\u0e27\\u0e34\\u0e28\\u0e27\\u0e01\\u0e23<ORGANIZATION>\\u0e1b\\u0e31\\u0e0d\\u0e0d\\u0e32</ORGANIZATION><ORGANIZATION>\\u0e1b\\u0e23\\u0e30\\u0e14\\u0e34\\u0e29\\u0e10\\u0e4c</ORGANIZATION> \\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e01\\u0e32\\u0e23\\u0e1d\\u0e36\\u0e01\\u0e07\\u0e32\\u0e19 \\u0e1a\\u0e31\\u0e13\\u0e11\\u0e34\\u0e15\\u0e08\\u0e1a\\u0e43\\u0e2b\\u0e21\\u0e48<ORGANIZATION>\\u0e2a\\u0e32\\u0e02\\u0e32</ORGANIZATION><ORGANIZATION>\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e01\\u0e32\\u0e23</ORGANIZATION><ORGANIZATION>\\u0e04</ORGANIZATION><ORGANIZATION>\\u0e2d\\u0e21\\u0e1e\\u0e34\\u0e27\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c</ORGANIZATION>\\u0e17\\u0e35\\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21 \\u0e19\\u0e31\\u0e01\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e1d\\u0e36\\u0e01\\u0e2b\\u0e31\\u0e14 al \\u0e2a\\u0e19\\u0e43\\u0e08\\u0e41\\u0e25\\u0e30\\u0e17\\u0e31\\u0e01\\u0e29\\u0e30\\u0e14\\u0e49\\u0e32\\u0e19 al \\u0e41\\u0e25\\u0e30 machine learning \\u0e1c\\u0e48\\u0e32\\u0e19<ORGANIZATION> \\u0e1a\\u0e23\\u0e34\\u0e29\\u0e31\\u0e17 \\u0e42\\u0e2d\\u0e17\\u0e35 \\u0e42\\u0e0b\\u0e25\\u0e39\\u0e0a\\u0e31\\u0e19\\u0e2a\\u0e4c \\u0e08\\u0e4d\\u0e32\\u0e01\\u0e31\\u0e14</ORGANIZATION><DATE> </DATE><DATE>\\u0e1e\\u0e24\\u0e29\\u0e20\\u0e32\\u0e04\\u0e21 2023 \\u0e2a\\u0e34\\u0e07\\u0e2b\\u0e32\\u0e04\\u0e21 2023</DATE> \\u0e01\\u0e32\\u0e23\\u0e17\\u0e4d\\u0e32\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e17\\u0e31\\u0e49\\u0e07\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e23\\u0e35\\u0e22\\u0e19\\u0e41\\u0e25\\u0e30\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e15\\u0e31\\u0e27 \\u0e21\\u0e35 \\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 machine learning \\u0e0a\\u0e48\\u0e27\\u0e22\\u0e17\\u0e35\\u0e21\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 machine learning \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e1e\\u0e22\\u0e32\\u0e01\\u0e23\\u0e13\\u0e4c deep learning \\u0e14\\u0e49\\u0e27\\u0e22 python \\u0e41\\u0e25\\u0e30 \\u0e41\\u0e25\\u0e30 \\u0e22\\u0e2d\\u0e14\\u0e02\\u0e32\\u0e22\\u0e2a\\u0e34\\u0e19\\u0e04\\u0e49\\u0e32<ORGANIZATION> ten</ORGANIZATION><ORGANIZATION>sor</ORGANIZATION><ORGANIZATION>flow</ORGANIZATION>\\n\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\u0e08\\u0e32\\u0e01\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32 \\u0e43\\u0e0a\\u0e49\\u0e0a\\u0e38\\u0e14\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 fer<DATE>2013</DATE> \\u0e41\\u0e25\\u0e30\\u0e1d\\u0e36\\u0e01\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 cnn \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21 \\u0e0a\\u0e48\\u0e2d\\u0e07\\u0e17\\u0e32\\u0e07\\u0e01\\u0e32\\u0e23\\u0e15\\u0e34\\u0e14\\u0e15\\u0e48\\u0e2d \\u0e04\\u0e27\\u0e32\\u0e21\\u0e41\\u0e21\\u0e48\\u0e19\\u0e22\\u0e4d\\u0e32\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e4d\\u0e32\\u0e41\\u0e19\\u0e01 phone:<PHONE> 08</PHONE><PHONE>0-1</PHONE><PHONE>23-4567</PHONE> \\u0e01\\u0e32\\u0e23\\u0e27\\u0e34\\u0e40\\u0e04\\u0e23\\u0e32\\u0e30\\u0e2b\\u0e4c\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e2b\\u0e47\\u0e19\\u0e1a\\u0e19\\u0e42\\u0e0b\\u0e40\\u0e0a\\u0e35\\u0e22\\u0e25\\u0e21\\u0e35\\u0e40\\u0e14\\u0e35\\u0e22 email:<EMAIL> pa</EMAIL><EMAIL>nya@example. com</EMAIL> (sentiment analysis) linkedin:<URL> linkedin. com in pa</URL><EMAIL>nya</EMAIL><URL>vi</URL><EMAIL>riya</EMAIL><EMAIL>chai</EMAIL><URL> github</URL>:<URL> github.com</URL><PERSON> pa</PERSON><PERSON>nya</PERSON><PERSON>vi</PERSON><PERSON>riya</PERSON><PERSON>chai</PERSON> \\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 deep learning \\u0e14\\u0e49\\u0e27\\u0e22 tensorflow \\u0e40\\u0e1e\\u0e37\\u0e2d \\u0e08\\u0e4d\\u0e32\\u0e41\\u0e19\\u0e01\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\u0e08\\u0e32\\u0e01\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32 \\u0e43\\u0e0a\\u0e49\\u0e0a\\u0e38\\u0e14\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 fer<DATE>2013</DATE> \\u0e41\\u0e25\\u0e30\\u0e1d\\u0e36\\u0e01\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 cnn \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21 \\u0e04\\u0e27\\u0e32\\u0e21\\u0e41\\u0e21\\u0e48\\u0e19\\u0e22\\u0e4d\\u0e32\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e4d\\u0e32\\u0e41\\u0e19\\u0e01 \\u0e01\\u0e32\\u0e23\\u0e28\\u0e36\\u0e01\\u0e29\\u0e32 \\u0e1b\\u0e23\\u0e30\\u0e01\\u0e32\\u0e28\\u0e19\\u0e35\\u0e22\\u0e1a\\u0e31\\u0e15\\u0e23 \\u0e1b\\u0e23\\u0e34\\u0e0d\\u0e0d\\u0e32\\u0e15\\u0e23\\u0e35\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c \\u0e2a\\u0e32\\u0e02\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e01\\u0e32\\u0e23\\u0e04\\u0e2d\\u0e21\\u0e1e\\u0e34\\u0e27\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c \\u0e08\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e28\\u0e36\\u0e01\\u0e29\\u0e32:<DATE> </DATE><DATE>\\u0e1e\\u0e24\\u0e29\\u0e20\\u0e32\\u0e04\\u0e21 2024</DATE><ORGANIZATION> </ORGANIZATION><ORGANIZATION>\\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31</ORGANIZATION><ORGANIZATION>\\u0e22\\u0e40\\u0e01\\u0e29\\u0e15\\u0e23</ORGANIZATION><ORGANIZATION>\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c</ORGANIZATION>\\n\\u0e2a\\u0e21\\u0e32\\u0e0a\\u0e34\\u0e01<ORGANIZATION>\\u0e0a\\u0e21\\u0e23\\u0e21</ORGANIZATION><ORGANIZATION>\\u0e27\\u0e34\\u0e08\\u0e31\\u0e22</ORGANIZATION><ORGANIZATION>\\u0e41\\u0e25\\u0e30\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32 al</ORGANIZATION><ORGANIZATION> </ORGANIZATION><ORGANIZATION>\\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31</ORGANIZATION><ORGANIZATION>\\u0e22 \\u0e40\\u0e01\\u0e29\\u0e15\\u0e23\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c</ORGANIZATION>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"aparn software engineer accenture application development senior analyst qjava\\nbanking / fnancial project. suggested to team lead and take action to design. code and deploy statement digitization process with publish subscribe pattern with kafka to eliminate synchronous process cut processing time from 10 seconds to 2 seconds\\nmanual process that takes to 3 minutes by hours for automated migration working by reading ajson confguration fle and calling the restful confgurations api. client credentials and authorization code methods for the exchange data process using implemented oauth 2.0 solution by kong api gateway (ce). for partner vendors with application by using jpa pagination api. optimized manual pagination logic on restfil api fom java spring boot improve the query time from 3400 milliseconds to 500 milliseconds. aware technology solutions.\\ncoached new members of software engineers and instructed technologies to the team for innovative products. researched. designed and managed to build scalability and reliable system for work timeattendance solution used more than hundreds of users inside corporate by hode.is microservice architecture to work with the oracle database. associate software engineer (backend development javascript. hodejs. postgre$ql mongodb docker; linur azure) \\\"superse quality of software solutions delivered and business growth. tar of the company' awarded as one of due to coded and implementation a hode.is expense approval system to help support the clients internal approval policy as web a application to support 2k+ employees working with postgre$ol. projects\\nwant to learn and be better in technical knowledge focusing on java and currently in thai). traffic boba [be] (spring boot kotlin mockk junit5 hode.js kubernetes mysql) mocking order traffc for one medium size boba including high level/ estimation design. shop kt upload excel fileto mongodb spring boot excel file to mongodb example of use case to upload excel file to spring boot api developed by kotlin university of\\nted systems / microservices spring boot/ spring webflux awards & actiities jibility friendly\\\" kotlin android tensorflow). second runner up at accessible learning hackathon 2018\\\" with the team access ii welsign project of accenture thailand as collaborating developer & devops role (spring boot. django go). backend in the a\",\n          \"\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25\\u0e15\\u0e34\\u0e14\\u0e15\\u0e48\\u0e2d \\u0e40\\u0e01\\u0e35\\u0e22\\u0e27\\u0e01\\u0e31\\u0e1a\\u0e09\\u0e31\\u0e19 \\u0e40\\u0e25\\u0e48\\u0e19        st. 123 anywhere \\u0e40\\u0e0a\\u0e37\\u0e49\\u0e2d\\u0e0a\\u0e32\\u0e15\\u0e34 \\u0e44\\u0e17\\u0e22 city any $ 12345\",\n          \"\\u0e27\\u0e34\\u0e28\\u0e27\\u0e01\\u0e23\\u0e1b\\u0e31\\u0e0d\\u0e0d\\u0e32\\u0e1b\\u0e23\\u0e30\\u0e14\\u0e34\\u0e29\\u0e10\\u0e4c \\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e01\\u0e32\\u0e23\\u0e1d\\u0e36\\u0e01\\u0e07\\u0e32\\u0e19 \\u0e1a\\u0e31\\u0e13\\u0e11\\u0e34\\u0e15\\u0e08\\u0e1a\\u0e43\\u0e2b\\u0e21\\u0e48\\u0e2a\\u0e32\\u0e02\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e01\\u0e32\\u0e23\\u0e04\\u0e2d\\u0e21\\u0e1e\\u0e34\\u0e27\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c\\u0e17\\u0e35\\u0e21\\u0e35\\u0e04\\u0e27\\u0e32\\u0e21 \\u0e19\\u0e31\\u0e01\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e1d\\u0e36\\u0e01\\u0e2b\\u0e31\\u0e14 ai \\u0e2a\\u0e19\\u0e43\\u0e08\\u0e41\\u0e25\\u0e30\\u0e17\\u0e31\\u0e01\\u0e29\\u0e30\\u0e14\\u0e49\\u0e32\\u0e19 ai \\u0e41\\u0e25\\u0e30 machine learning \\u0e1c\\u0e48\\u0e32\\u0e19 \\u0e1a\\u0e23\\u0e34\\u0e29\\u0e31\\u0e17 \\u0e42\\u0e2d\\u0e17\\u0e35 \\u0e42\\u0e0b\\u0e25\\u0e39\\u0e0a\\u0e31\\u0e19\\u0e2a\\u0e4c \\u0e08\\u0e4d\\u0e32\\u0e01\\u0e31\\u0e14 \\u0e01\\u0e32\\u0e23\\u0e17\\u0e4d\\u0e32\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e17\\u0e31\\u0e49\\u0e07\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e40\\u0e23\\u0e35\\u0e22\\u0e19\\u0e41\\u0e25\\u0e30\\u0e42\\u0e1b\\u0e23\\u0e40\\u0e08\\u0e01\\u0e15\\u0e4c\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e15\\u0e31\\u0e27 \\u0e21\\u0e35 \\u0e1b\\u0e23\\u0e30\\u0e2a\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e13\\u0e4c\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 machine learning \\u0e0a\\u0e48\\u0e27\\u0e22\\u0e17\\u0e35\\u0e21\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 machine learning \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e1e\\u0e22\\u0e32\\u0e01\\u0e23\\u0e13\\u0e4c deep learning \\u0e14\\u0e49\\u0e27\\u0e22 python \\u0e41\\u0e25\\u0e30 \\u0e41\\u0e25\\u0e30 \\u0e22\\u0e2d\\u0e14\\u0e02\\u0e32\\u0e22\\u0e2a\\u0e34\\u0e19\\u0e04\\u0e49\\u0e32 tensorflow\\n\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\u0e08\\u0e32\\u0e01\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32 \\u0e43\\u0e0a\\u0e49\\u0e0a\\u0e38\\u0e14\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 fer \\u0e41\\u0e25\\u0e30\\u0e1d\\u0e36\\u0e01\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 cnn \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21  \\u0e04\\u0e27\\u0e32\\u0e21\\u0e41\\u0e21\\u0e48\\u0e19\\u0e22\\u0e4d\\u0e32\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e4d\\u0e32\\u0e41\\u0e19\\u0e01  \\u0e01\\u0e32\\u0e23\\u0e27\\u0e34\\u0e40\\u0e04\\u0e23\\u0e32\\u0e30\\u0e2b\\u0e4c\\u0e04\\u0e27\\u0e32\\u0e21\\u0e40\\u0e2b\\u0e47\\u0e19\\u0e1a\\u0e19\\u0e42\\u0e0b\\u0e40\\u0e0a\\u0e35\\u0e22\\u0e25\\u0e21\\u0e35\\u0e40\\u0e14\\u0e35\\u0e22 email (sentiment analysis)  \\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 deep learning \\u0e14\\u0e49\\u0e27\\u0e22 tensorflow \\u0e40\\u0e1e\\u0e37\\u0e2d \\u0e08\\u0e4d\\u0e32\\u0e41\\u0e19\\u0e01\\u0e2d\\u0e32\\u0e23\\u0e21\\u0e13\\u0e4c\\u0e08\\u0e32\\u0e01\\u0e20\\u0e32\\u0e1e\\u0e43\\u0e1a\\u0e2b\\u0e19\\u0e49\\u0e32 \\u0e43\\u0e0a\\u0e49\\u0e0a\\u0e38\\u0e14\\u0e02\\u0e49\\u0e2d\\u0e21\\u0e39\\u0e25 fer \\u0e41\\u0e25\\u0e30\\u0e1d\\u0e36\\u0e01\\u0e42\\u0e21\\u0e40\\u0e14\\u0e25 cnn \\u0e40\\u0e1e\\u0e37\\u0e48\\u0e2d\\u0e40\\u0e1e\\u0e34\\u0e48\\u0e21 \\u0e04\\u0e27\\u0e32\\u0e21\\u0e41\\u0e21\\u0e48\\u0e19\\u0e22\\u0e4d\\u0e32\\u0e43\\u0e19\\u0e01\\u0e32\\u0e23\\u0e08\\u0e4d\\u0e32\\u0e41\\u0e19\\u0e01 \\u0e01\\u0e32\\u0e23\\u0e28\\u0e36\\u0e01\\u0e29\\u0e32 \\u0e1b\\u0e23\\u0e30\\u0e01\\u0e32\\u0e28\\u0e19\\u0e35\\u0e22\\u0e1a\\u0e31\\u0e15\\u0e23 \\u0e1b\\u0e23\\u0e34\\u0e0d\\u0e0d\\u0e32\\u0e15\\u0e23\\u0e35\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c \\u0e2a\\u0e32\\u0e02\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e01\\u0e32\\u0e23\\u0e04\\u0e2d\\u0e21\\u0e1e\\u0e34\\u0e27\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c \\u0e08\\u0e1a\\u0e01\\u0e32\\u0e23\\u0e28\\u0e36\\u0e01\\u0e29\\u0e32 \\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31\\u0e22\\u0e40\\u0e01\\u0e29\\u0e15\\u0e23\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c\\n\\u0e2a\\u0e21\\u0e32\\u0e0a\\u0e34\\u0e01\\u0e0a\\u0e21\\u0e23\\u0e21\\u0e27\\u0e34\\u0e08\\u0e31\\u0e22\\u0e41\\u0e25\\u0e30\\u0e1e\\u0e31\\u0e12\\u0e19\\u0e32 ai \\u0e21\\u0e2b\\u0e32\\u0e27\\u0e34\\u0e17\\u0e22\\u0e32\\u0e25\\u0e31\\u0e22 \\u0e40\\u0e01\\u0e29\\u0e15\\u0e23\\u0e28\\u0e32\\u0e2a\\u0e15\\u0e23\\u0e4c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Job_Description\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"**Software Engineer (Junior/Senior/Specialist)**\\nKey Responsibilities:\\n\\nDevelop efficient, high-quality Web applications or APIs based on requirements and complete the project within the given timeline.\\nDevelop clear and comprehensive system diagrams (high-level and low-level) to facilitate communication and collaboration across teams.\\nOptimized code performance, reduced infrastructure costs, and researched emerging technologies to improve efficiency and innovation.\\nConducted thorough code reviews, providing actionable feedback to improve code quality and foster knowledge sharing within the team.\\nMinimize the risk of security breaches by maintaining up-to-date software and infrastructure, leading to improved code scanning accuracy and vulnerability detection.\\n\\nRequired Qualifications (What we need) : \\n\\nAt least  2-6 years of hands-on experience in the entire software development lifecycle, from coding and testing to deployment in a production environment.\\nPassionate about software development, meticulously attending to each step from scratch to production.\\nUnderstanding of software design principles, patterns, and architectures end-to-end.\\nStrong knowledge of programming language and the ecosystem (Golang, Typescript, rust, or more).\\nStrong knowledge of Golang, including an understanding of goroutine and experience using Go libraries such as Echo, Fiber, and GORM.\\nStrong knowledge of MongoDB, including sharding and replication configuration. MongoDB certification is a plus.\\nStrong knowledge of Redis, including proficiency in Redis modules such as RedisJSON and RedisSearch. Redis certification is a plus.\\nStrong knowledge of Event-Driven concepts and understanding of the work processes of RabbitMQ or Kafka.\\nStrong knowledge of Web application development using Next.js, with an understanding of the React life cycle.\\nStrong knowledge of designing and developing high-performance software services optimized for handling many concurrent requests per second.\\nStrong knowledge of DevSecOps pipelines, Infrastructure as Code (IaC), and AWS cloud services.\\nFamiliar with automated testing frameworks like Playwright.\\nFamiliar with performance testing frameworks like K6.\\nBe able to communicate in both Thai and English.\\nPossesses a positive attitude and participates in team-building and events\\nComfortable presenting technical information and project updates to both technical and non-technical stakeholders.\\nSkilled in talking with AI to solve complex problems, leading to improved outcomes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Evaluation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"---\\n\\n**Classification**: Reconsider\\n**Rationale**: The candidate has a strong background in software development, particularly in Java and Spring Boot, and has experience with microservices and database optimization. They also have experience with Kafka, which is relevant to the job description. However, there is a lack of direct experience with Golang, Typescript, and other technologies specifically mentioned in the job description. Their experience with MongoDB and DevOps practices is a plus, but they would need to learn and adapt to the specific technologies required for this role.\\n\\n**\\u0e02\\u0e49\\u0e2d\\u0e14\\u0e35 (Strengths)**:\\n- Extensive experience in Java and Spring Boot, including optimization and microservices.\\n- Familiarity with Kafka and experience in designing scalable systems.\\n- Experience with MongoDB and DevOps practices.\\n- Proven track record of coaching and mentoring team members.\\n\\n**\\u0e02\\u0e49\\u0e2d\\u0e04\\u0e27\\u0e23\\u0e1b\\u0e23\\u0e31\\u0e1a\\u0e1b\\u0e23\\u0e38\\u0e07 (Areas for Improvement)**:\\n- Limited experience with Golang, Typescript, and other required technologies.\\n- No direct mention of experience with Next.js, Redis, or AWS cloud services.\\n- Lack of proficiency in the Thai language, which is a requirement for the position.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Result\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Unrelated\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Images\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"['/content/images/resume dev1/page_001.png']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pass**\n",
        "จะตัดสินใจให้ `ผ่าน` ก็ต่อเมื่อผู้สมัครดูมี potential จาก resume ดูจะ applied ไปกับ job description ได้หรือตรงตาม requirement เป็นส่วนใหญ่\n",
        "## **Reconsider**\n",
        "จะตัดสินใจให้ `พิจารณา` ก็ต่อเมื่อผู้สมัคร จาก resume ดูจะมีแนวโน้มที่สามารถ applied ตาม requirement ได้ ควรสัมภาษณ์อีกครั้ง\n",
        "## **Unrelated**\n",
        "จะตัดสินใจให้ `ไม่เกี่ยวข้อง` ก็ต่อเมื่อผู้สมัคร จาก resume ดูจะ ไม่เกี่ยวข้องกับ job description หรือตรงข้ามกับ requirement เป็นส่วนใหญ่"
      ],
      "metadata": {
        "id": "59zHbRS6EoC0"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5634877,
          "sourceId": 9322283,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30762,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}