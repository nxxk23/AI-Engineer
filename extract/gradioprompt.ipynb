{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/extract/gradioprompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eCrTQcC53f5"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr gradio pythainlp langchain langchain_huggingface langchain_community pytesseract transformers\n",
        "!sudo apt-get install ghostscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs7wm9vm53fy"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2ikrvvo53f-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "resume_directory = '/content/drive/MyDrive/AIEngineer/resume/resume_LLM'\n",
        "pdf_files = [os.path.join(resume_directory, f) for f in os.listdir(resume_directory) if f.endswith('.pdf')]\n",
        "\n",
        "# Print the list of PDF files to verify\n",
        "print(pdf_files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDWsn2sE53gD"
      },
      "source": [
        "## **Job Qualification**\n",
        "\n",
        "| **ᴊᴏʙ** | **ᴘᴏꜱɪᴛɪᴏɴ** | **ᴄᴏᴜɴᴛ** |\n",
        "|:---:|:---:|:---:|\n",
        "| 1 | ʙᴜꜱɪɴᴇꜱꜱ ᴀɴᴀʟʏꜱᴛ | 5 |\n",
        "| 2 | ᴀɪ ᴇɴɢɪɴᴇᴇʀ | 7 |\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import easyocr\n",
        "import subprocess\n",
        "from pythainlp.phayathaibert.core import NamedEntityTagger\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import requests\n",
        "from threading import Semaphore\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from huggingface_hub import InferenceClient\n",
        "import pytesseract\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import os\n",
        "import subprocess\n",
        "import uuid"
      ],
      "metadata": {
        "id": "90WztN4zV52X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eExOBevq53gJ"
      },
      "outputs": [],
      "source": [
        "resume_prompt = \"\"\"\n",
        "# Resume Evaluation Prompt\n",
        "\n",
        "**You are a career coach and resume evaluator**, tasked with thoughtfully assessing a candidate's resume based on a specific job description. Your goal is to strike a balance between the candidate’s qualifications and their potential for growth. Keep in mind that real-world hiring involves not only meeting immediate requirements but also identifying long-term potential and adaptability.\n",
        "\n",
        "## Instructions:\n",
        "- **Focus primarily on the job description**, but also consider any unique skills and experience that the candidate offers.\n",
        "- Your evaluation should prioritize candidates who align well with the role but remain open to those who might provide unexpected strengths.\n",
        "- **Don’t rely solely on a perfect match**—instead, take a holistic view of the candidate to assess their overall fit, potential, and growth trajectory.\n",
        "\n",
        "### Evaluation Criteria:\n",
        "\n",
        "1. **Strong Fit (PASS)**:\n",
        "   - The candidate aligns well with the job requirements and demonstrates strong potential to excel, even if some qualifications are missing.\n",
        "   - Consider their **unique strengths**, **relevant experience**, and **transferable skills**.\n",
        "   - If they show adaptability and a strong overall fit, classify them as \"Strong Fit.\"\n",
        "\n",
        "2. **Promising (RECONSIDER)**:\n",
        "   - The candidate aligns with some aspects of the job but has notable gaps.\n",
        "   - However, their experience suggests they could grow into the role.\n",
        "   - Consider them as a candidate with potential, particularly if their overall background suggests they would be worth interviewing or reviewing further.\n",
        "\n",
        "3. **Not a Fit (UNRELATED)**:\n",
        "   - The candidate’s background does not align with the job description and there is no significant potential for the role.\n",
        "   - Their experience, while potentially strong in other areas, is unrelated to the requirements for this position.\n",
        "\n",
        "## Evaluation Process:\n",
        "\n",
        "1. **Step 1**: Carefully review the **job description** and extract the core requirements and preferred qualifications.\n",
        "2. **Step 2**: Compare the **resume** to the job description:\n",
        "   - Identify relevant qualifications and skills.\n",
        "   - Note any **transferable skills** or **unique strengths** that the candidate brings.\n",
        "3. **Step 3**: Consider the candidate's **overall potential**, adaptability, and long-term growth.\n",
        "4. **Step 4**: Classify the resume and provide feedback.\n",
        "\n",
        "## Output Instructions:\n",
        "- Summarize the candidate's resume in two key sections: **ข้อดี (Strengths)** and **ข้อควรปรับปรุง (Areas for Improvement)**.\n",
        "- Then provide the **Classification** (Pass / Reconsider / Unrelated) and a **Concise Rationale**.\n",
        "- Do **not** include a detailed analysis of the job description or resume in the output.\n",
        "\n",
        "### What Not to Do:\n",
        "- **Don’t disqualify candidates** for not meeting every single requirement. Assess their ability to adapt and grow.\n",
        "- **Don’t ignore transferable skills** that could be useful in the role.\n",
        "- **Remain open-minded** to candidates who may bring unique value, even if their experience isn’t a perfect match.\n",
        "\n",
        "## Selection Criteria:\n",
        "\n",
        "- **Relevance to Job Requirements**: Focus on how well the candidate’s experience and skills align with both the required and preferred qualifications of the job description.\n",
        "- **Transferable Skills**: Identify skills and experiences that, while not directly related, could be beneficial in the role.\n",
        "- **Potential**: Look beyond immediate requirements to assess whether the candidate shows promise to grow into the role and contribute long-term.\n",
        "- **Holistic View**: Evaluate the resume with a broader perspective, considering adaptability, cultural fit, and overall value to the team or company.\n",
        "\n",
        "---\n",
        "\n",
        "### **Few-Shot Examples** (for internal reference, never copy them)\n",
        "\n",
        "#### **Job Description**:\n",
        "- Required: 5+ years of experience in software development, proficiency in Python and JavaScript, experience with cloud platforms, and leadership skills. Bachelor's degree in Computer Science or related field.\n",
        "- Preferred: Master's degree, DevOps experience, and familiarity with modern software development practices.\n",
        "\n",
        "#### **Resume**:\n",
        "- Candidate has 6 years of software development experience, proficient in Python and JavaScript, and cloud platform experience. Holds a Master’s degree in Computer Science and has led teams of up to 10 people. Some exposure to DevOps.\n",
        "\n",
        "#### **Evaluation**:\n",
        "\n",
        "**Classification**: Pass\n",
        "**Rationale**: The candidate meets the core requirements and brings valuable experience in leadership and DevOps. They have demonstrated the ability to succeed in a complex environment, making them a strong fit for the role.\n",
        "\n",
        "**ข้อดี (Strengths)**:\n",
        "- Extensive software development experience and proficiency in required programming languages.\n",
        "- Leadership experience and familiarity with cloud platforms.\n",
        "\n",
        "**ข้อควรปรับปรุง (Areas for Improvement)**:\n",
        "- Limited exposure to DevOps, which is a preferred qualification.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Job Description**:\n",
        "- Required: 3+ years of software development experience, proficiency in Python and JavaScript, experience with cloud platforms. Bachelor’s degree required.\n",
        "- Preferred: Experience with DevOps and React.js.\n",
        "\n",
        "#### **Resume**:\n",
        "- The candidate has 3 years of experience in automation and Python development. They have worked on cloud-based projects but have less direct experience with JavaScript or React.js.\n",
        "\n",
        "#### **Evaluation**:\n",
        "\n",
        "**Classification**: Reconsider\n",
        "**Rationale**: The candidate shows strong Python and cloud platform experience but lacks direct JavaScript experience. Given their expertise in automation and cloud projects, they might still be a good fit with some support in JavaScript.\n",
        "\n",
        "**ข้อดี (Strengths)**:\n",
        "- Strong experience with automation and Python.\n",
        "- Familiarity with cloud platforms.\n",
        "\n",
        "**ข้อควรปรับปรุง (Areas for Improvement)**:\n",
        "- Lacks direct experience with JavaScript and React.js, which are mentioned in the job description.\n",
        "---\n",
        "\n",
        "## **Job Description** (never copy it):\n",
        "{jobdescribe}\n",
        "\n",
        "## **Resume** (never copy it):\n",
        "{resume}\n",
        "\n",
        "## **Template for Evaluation**:\n",
        "\n",
        "**Classification**: (Pass / Reconsider / Unrelated)\n",
        "**Rationale**: Provide a clear and concise explanation for your classification. Focus on how well the candidate aligns with the job description, highlight any transferable skills or potential, and explain any significant gaps. Mention both strengths and areas for improvement.\n",
        "\n",
        "**ข้อดี (Strengths)**:\n",
        "- Summarize the key strengths of the candidate based on their resume.\n",
        "\n",
        "**ข้อควรปรับปรุง (Areas for Improvement)**:\n",
        "- Summarize areas where the candidate could improve or is lacking in relation to the job description.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model parameters\n",
        "model_params = {\n",
        "    \"max_new_tokens\": 500,\n",
        "    \"temperature\": 0.1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"repetition_penalty\": 1.0\n",
        "}\n",
        "semaphore = Semaphore(50)\n",
        "\n",
        "def convert_pdf_to_images(pdf_file, output_folder=\"/content/images\", dpi=300):\n",
        "    try:\n",
        "        # Create a unique folder for each PDF\n",
        "        pdf_filename = os.path.splitext(os.path.basename(pdf_file))[0]\n",
        "        unique_output_folder = os.path.join(output_folder, pdf_filename)\n",
        "\n",
        "        if not os.path.exists(unique_output_folder):\n",
        "            os.makedirs(unique_output_folder)\n",
        "\n",
        "        output_format = os.path.join(unique_output_folder, \"page_%03d.png\")\n",
        "        gs_command = [\n",
        "            \"gs\",\n",
        "            \"-sDEVICE=png16m\",\n",
        "            f\"-r{dpi}\",\n",
        "            \"-o\", output_format,\n",
        "            pdf_file\n",
        "        ]\n",
        "        subprocess.run(gs_command, check=True)\n",
        "\n",
        "        # Collect all generated images in a list\n",
        "        image_files = sorted([os.path.join(unique_output_folder, f) for f in os.listdir(unique_output_folder) if f.endswith(\".png\")])\n",
        "        return image_files\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Ghostscript error: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_text_from_image(image_path):\n",
        "    reader = easyocr.Reader(['th', 'en'], gpu=True)\n",
        "    image = Image.open(image_path)\n",
        "    image_np = np.array(image)\n",
        "    result = reader.readtext(image_np)\n",
        "    sorted_data = sorted(result, key=lambda x: x[0][0][1])\n",
        "    plain_text = \"\\n\".join([text for _, text, _ in sorted_data])\n",
        "    return plain_text\n",
        "\n",
        "def chunk_text(text, tokenizer, max_tokens=200):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    total_tokens = len(tokens)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < total_tokens:\n",
        "        end = min(start + max_tokens, total_tokens)\n",
        "        chunk = tokenizer.convert_tokens_to_string(tokens[start:end])\n",
        "        chunks.append(chunk)\n",
        "\n",
        "        start += max_tokens\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def tag_and_clean_text(text, tagger, tokenizer, unwanted_pattern, max_tokens=200):\n",
        "    text_chunks = chunk_text(text, tokenizer, max_tokens=max_tokens)\n",
        "    tagged_text = []\n",
        "    cleaned_text = []\n",
        "\n",
        "    for i, chunk in enumerate(text_chunks):\n",
        "        ner = tagger.get_ner(chunk, tag=True)\n",
        "        if not ner:\n",
        "            ner = chunk\n",
        "\n",
        "        # Clean the tags\n",
        "        pattern = r'<(?!ORGANIZATION|PERCENT|TIME)[^>]+>[^<]*?</[^>]+>'\n",
        "        cleaned_ner = re.sub(pattern, '', ner)\n",
        "        cleaned_ner = re.sub(r'</?(ORGANIZATION|PERCENT|TIME)>', '', cleaned_ner)\n",
        "        cleaned_ner = re.sub(unwanted_pattern, '', cleaned_ner, flags=re.IGNORECASE)\n",
        "        cleaned_ner = re.sub(r'\\bal\\b', 'ai', cleaned_ner, flags=re.IGNORECASE)\n",
        "        # Append the tagged and cleaned text\n",
        "        tagged_text.append(ner)\n",
        "        cleaned_text.append(cleaned_ner)\n",
        "    # Combine results from all chunks\n",
        "    combined_tagged_text = \"\\n\".join(tagged_text).strip()\n",
        "    combined_cleaned_text = \"\\n\".join(cleaned_text).strip()\n",
        "\n",
        "    return combined_tagged_text, combined_cleaned_text\n",
        "\n",
        "\n",
        "# Function to generate an answer using the prompt\n",
        "def generate_answer(resume, job_description):\n",
        "    formatted_prompt = resume_prompt.replace(\"{resume}\", resume).replace(\"{jobdescribe}\", job_description)\n",
        "    truncated_prompt = formatted_prompt[:model_params[\"max_new_tokens\"]]\n",
        "    client = InferenceClient('https://ai-api.manageai.co.th/llm-model-02/')\n",
        "    response = client.text_generation(formatted_prompt, **model_params)\n",
        "    output = \"\".join(response)\n",
        "    return output\n",
        "\n",
        "# Extract classification from the result text\n",
        "def extract_classification(text):\n",
        "    pattern = r'\\*\\*\\s*Classification\\s*\\**:\\s*(?:\\[)?\\s*(Pass|Reconsider|Not Pass|Unrelated)\\s*(?:\\])?'\n",
        "    match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if not match:\n",
        "        pattern = r'Classification\\s*:\\s*(?:\\[)?\\s*(Pass|Reconsider|Not Pass|Unrelated)\\s*(?:\\])?'\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return text\n",
        "\n",
        "def process_file(file, job_description, is_pdf=True):\n",
        "    if is_pdf:\n",
        "        images = convert_pdf_to_images(file.name)\n",
        "        raw_text = \"\"\n",
        "        for image_path in images:\n",
        "            raw_text += extract_text_from_image(image_path) + \"\\n\"\n",
        "    else:\n",
        "        raw_text = extract_text_from_image(file.name)\n",
        "\n",
        "    tagger = NamedEntityTagger()\n",
        "    tokenizer = tagger.tokenizer\n",
        "\n",
        "    unwanted_terms = [\n",
        "        'ที่อยู่', 'โทรศัพท์', 'อีเมล', 'linkedin', ':', ',', '-', '|',\n",
        "        'ประวัติส่วนตัว', 'เกี่ยวกับฉัน', 'about me', 'ชื่อ', 'สกุล', 'tell', 'โทร', 'โทรงาน',\n",
        "        'ชื่อเล่น', 'อายุ', 'วันเกิด', 'พุทธ', 'ศาสนา', 'สัญชาติ', 'phone',\n",
        "        'ช่องทางการติดต่อ', '_', 're sume', 'resume', 'resu me', 'birth', 'date',\n",
        "        'address', 'email.', 'ประวัติ'\n",
        "    ]\n",
        "    unwanted_pattern = '|'.join(map(re.escape, unwanted_terms))\n",
        "\n",
        "    tagged_text, cleaned_text = tag_and_clean_text(raw_text, tagger, tokenizer, unwanted_pattern)\n",
        "    evaluation = generate_answer(cleaned_text, job_description)\n",
        "    result = extract_classification(evaluation)\n",
        "\n",
        "    df = pd.DataFrame([{\n",
        "        \"File\": os.path.basename(file.name),\n",
        "        \"Raw_Text\": raw_text,\n",
        "        \"Tagged_Text\": tagged_text,\n",
        "        \"Cleaned_Text\": cleaned_text,\n",
        "        \"Job_Description\": job_description,\n",
        "        \"Evaluation\": evaluation,\n",
        "        \"Result\": result,\n",
        "        \"Images\": images\n",
        "    }])\n",
        "    return df\n",
        "\n",
        "# Function to process multiple files (remains unchanged)\n",
        "def process_multiple_files(files, job_description, is_pdf=True):\n",
        "    all_results = pd.DataFrame()\n",
        "    for file in files:\n",
        "        df = process_file(file, job_description, is_pdf)\n",
        "        all_results = pd.concat([all_results, df], ignore_index=True)\n",
        "    return all_results\n",
        "\n",
        "# Modify the function to append results without loading the existing DataFrame\n",
        "def save_dataframe(df, save_path='/content/output.csv'):\n",
        "    try:\n",
        "        # Append new data directly to the CSV without reloading existing data\n",
        "        df.to_csv(save_path, mode='a', header=not os.path.exists(save_path), index=False, encoding='utf-8-sig')\n",
        "        return save_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving DataFrame: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to process a batch of DataFrame rows\n",
        "def generate_prompt_answer_optimized(row):\n",
        "    resume = row.get('Cleaned_Text', \"\")\n",
        "    job_description = row.get('Job_Description', \"\")\n",
        "    result = generate_answer(resume, job_description)\n",
        "    return result\n",
        "\n",
        "# Function to process a batch of rows\n",
        "def process_batch(batch_df):\n",
        "    return [generate_prompt_answer_optimized(row) for _, row in batch_df.iterrows()]\n",
        "\n",
        "# Batch processing with threading\n",
        "def batch_process(df, batch_size=32):\n",
        "    results = [None] * len(df)\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = {}\n",
        "        for i in range(0, len(df), batch_size):\n",
        "            batch_df = df.iloc[i:i + batch_size]\n",
        "            future = executor.submit(process_batch, batch_df)\n",
        "            futures[future] = (i, i + batch_size)\n",
        "\n",
        "        for future in as_completed(futures):\n",
        "            start_idx, end_idx = futures[future]\n",
        "            batch_results = future.result()\n",
        "            results[start_idx:end_idx] = batch_results\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "esoz39MrswdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradio_interface(files, job_description, is_pdf, max_new_tokens, temperature, top_p, repetition_penalty):\n",
        "    try:\n",
        "        # Update model parameters\n",
        "        model_params.update({\n",
        "            \"max_new_tokens\": max_new_tokens,\n",
        "            \"temperature\": temperature,\n",
        "            \"top_p\": top_p,\n",
        "            \"repetition_penalty\": repetition_penalty\n",
        "        })\n",
        "\n",
        "        df = process_multiple_files(files, job_description, is_pdf)\n",
        "        df['Evaluation'] = batch_process(df, batch_size=32)\n",
        "        df['Result'] = df['Evaluation'].apply(extract_classification)\n",
        "\n",
        "        # Ensure the 'Images' column is in the DataFrame\n",
        "        if 'Images' not in df.columns:\n",
        "            raise ValueError(\"The 'Images' column is missing from the DataFrame!\")\n",
        "\n",
        "        csv_path = save_dataframe(df)\n",
        "        df_output = df[[\"File\", \"Result\", \"Evaluation\", \"Images\"]]  # Output all required columns for Gradio\n",
        "        return df_output, csv_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in gradio_interface: {e}\")\n",
        "        return pd.DataFrame(), \"\""
      ],
      "metadata": {
        "id": "IPLUB-V90iqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Async function to process row selection without unnecessary reloads\n",
        "async def show_evaluation(evt: gr.SelectData):\n",
        "    row_index = evt.index[0]\n",
        "    selected_eval = df.iloc[row_index][\"Evaluation\"]\n",
        "    image_files = df.iloc[row_index][\"Images\"]\n",
        "    first_image = image_files[0] if image_files else None\n",
        "    return str(selected_eval), first_image\n",
        "\n",
        "# Gradio interface creation with three-column layout\n",
        "def create_gradio_interface():\n",
        "    custom_theme = gr.themes.Default()\n",
        "\n",
        "    with gr.Blocks(theme=custom_theme) as demo:\n",
        "        with gr.Row():\n",
        "            # Left Section for Inputs\n",
        "            with gr.Column(scale=1):\n",
        "                file_input = gr.Files(label=\"Select PDF Files\", file_count=\"multiple\")\n",
        "                job_input = gr.Textbox(placeholder=\"Enter job description...\", label=\"Job Description\", lines=5)\n",
        "                submit_btn = gr.Button(\"Process\")\n",
        "                is_pdf_input = gr.Checkbox(label=\"PDF\", value=True)\n",
        "                max_new_tokens_input = gr.Slider(label=\"Max New Tokens\", minimum=50, maximum=1024, value=300, step=50)\n",
        "                temperature_input = gr.Slider(label=\"Temperature\", minimum=0.01, maximum=1.0, value=0.1, step=0.1)\n",
        "                top_p_input = gr.Slider(label=\"Top P\", minimum=0.1, maximum=1.0, value=0.95, step=0.05)\n",
        "                repetition_penalty_input = gr.Slider(label=\"Repetition Penalty\", minimum=0.1, maximum=2.0, value=1.0, step=0.1)\n",
        "\n",
        "            # Center Section for Results\n",
        "            with gr.Column(scale=1):\n",
        "                output_df = gr.DataFrame(\n",
        "                    headers=[\"File\", \"Result\"],\n",
        "                    type=\"pandas\",\n",
        "                    interactive=False,\n",
        "                )\n",
        "                output_csv = gr.DownloadButton(label=\"Download CSV\")\n",
        "\n",
        "            # Right Section for Evaluation and Preview\n",
        "            with gr.Column(scale=1):\n",
        "                eval_text = gr.Textbox(label=\"Evaluation Detail\", interactive=False)\n",
        "                resume_image = gr.Image(label=\"Resume Preview\", interactive=False)\n",
        "\n",
        "        # Function to process inputs and generate output\n",
        "        def on_submit(files, job_description, is_pdf, max_new_tokens, temperature, top_p, repetition_penalty):\n",
        "            global df\n",
        "            df, csv_path = gradio_interface(files, job_description, is_pdf, max_new_tokens, temperature, top_p, repetition_penalty)\n",
        "            return df[[\"File\", \"Result\"]], csv_path\n",
        "\n",
        "        # Bind submit button to the processing function\n",
        "        submit_btn.click(on_submit,\n",
        "                         inputs=[file_input, job_input, is_pdf_input, max_new_tokens_input, temperature_input, top_p_input, repetition_penalty_input],\n",
        "                         outputs=[output_df, output_csv])\n",
        "\n",
        "        # Bind row selection to evaluation display function\n",
        "        output_df.select(show_evaluation, outputs=[eval_text, resume_image])\n",
        "\n",
        "    return demo"
      ],
      "metadata": {
        "id": "T2BbHjSvNw4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVOA6m2-53gT"
      },
      "outputs": [],
      "source": [
        "app = create_gradio_interface()\n",
        "app.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## software enginner (https://th.jobsdb.com/job/78728644?type=standout&ref=search-standalone#sol=56ea90da2ce55925ca5b5294f7dc6009051ee403)\n",
        "## business analysis (https://th.jobsdb.com/Business-Analysis-jobs?jobId=78724436&type=standout)\n",
        "## AI Engineer (https://th.jobsdb.com/AI-Engineer-jobs?jobId=78686025&type=standout)"
      ],
      "metadata": {
        "id": "oOW4Mg8tzkyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "a = pd.read_csv('/content/output.csv')\n",
        "a"
      ],
      "metadata": {
        "id": "bdPTbleERMtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.to_excel('/content/drive/MyDrive/AIEngineer/resume/JOB/output.xlsx')"
      ],
      "metadata": {
        "id": "7X6VR0LdDt7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a['Result'].value_counts()"
      ],
      "metadata": {
        "id": "7Pps-fl4DQTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pass**\n",
        "จะตัดสินใจให้ `ผ่าน` ก็ต่อเมื่อผู้สมัครดูมี potential จาก resume ดูจะ applied ไปกับ job description ได้หรือตรงตาม requirement เป็นส่วนใหญ่"
      ],
      "metadata": {
        "id": "59zHbRS6EoC0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGsEbt39-wPr"
      },
      "outputs": [],
      "source": [
        "a[a['Result']=='Pass']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reconsider**\n",
        "จะตัดสินใจให้ `พิจารณา` ก็ต่อเมื่อผู้สมัคร จาก resume ดูจะมีแนวโน้มที่สามารถ applied ตาม requirement ได้ ควรสัมภาษณ์อีกครั้ง"
      ],
      "metadata": {
        "id": "dM-pXSklFWxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a[a['Result']=='Reconsider']"
      ],
      "metadata": {
        "id": "s5QEJAUhFm01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Unrelated**\n",
        "จะตัดสินใจให้ `ไม่เกี่ยวข้อง` ก็ต่อเมื่อผู้สมัคร จาก resume ดูจะ ไม่เกี่ยวข้องกับ job description หรือตรงข้ามกับ requirement เป็นส่วนใหญ่"
      ],
      "metadata": {
        "id": "MusbgKa4E9db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a[a['Result']=='Unrelated']"
      ],
      "metadata": {
        "id": "1eySjuOtEnSS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5634877,
          "sourceId": 9322283,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30762,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}