{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi #using GPU is faster","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-05T06:08:55.684270Z","iopub.execute_input":"2024-09-05T06:08:55.684654Z","iopub.status.idle":"2024-09-05T06:08:56.842589Z","shell.execute_reply.started":"2024-09-05T06:08:55.684615Z","shell.execute_reply":"2024-09-05T06:08:56.841523Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Thu Sep  5 06:08:56 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   39C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"!sudo apt-get install ghostscript\n!pip install transformers pythainlp python-crfsuite opencv-python easyocr","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:09:01.135015Z","iopub.execute_input":"2024-09-05T06:09:01.135435Z","iopub.status.idle":"2024-09-05T06:10:30.588423Z","shell.execute_reply.started":"2024-09-05T06:09:01.135382Z","shell.execute_reply":"2024-09-05T06:10:30.587309Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following additional packages will be installed:\n  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 libgs9 libgs9-common\n  libidn12 libijs-0.35 libjbig2dec0 poppler-data\nSuggested packages:\n  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre\n  ghostscript-x poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho\n  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n  fonts-arphic-uming fonts-nanum\nThe following NEW packages will be installed:\n  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript libgs9\n  libgs9-common libidn12 libijs-0.35 libjbig2dec0 poppler-data\n0 upgraded, 10 newly installed, 0 to remove and 39 not upgraded.\nNeed to get 16.7 MB of archives.\nAfter this operation, 63.0 MB of additional disk space will be used.\nDo you want to continue? [Y/n] ^C\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nCollecting pythainlp\n  Downloading pythainlp-5.0.4-py3-none-any.whl.metadata (7.7 kB)\nCollecting python-crfsuite\n  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.10.0.84)\nRequirement already satisfied: easyocr in /opt/conda/lib/python3.10/site-packages (1.7.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from easyocr) (2.4.0)\nRequirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.19.0)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from easyocr) (4.10.0.84)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.14.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from easyocr) (9.5.0)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.23.2)\nRequirement already satisfied: python-bidi in /opt/conda/lib/python3.10/site-packages (from easyocr) (0.6.0)\nRequirement already satisfied: Shapely in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.8.5.post1)\nRequirement already satisfied: pyclipper in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.3.0.post5)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from easyocr) (1.11.1.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (3.3)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (2024.5.22)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->easyocr) (0.4)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (1.13.2)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->easyocr) (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->easyocr) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->easyocr) (1.3.0)\nDownloading pythainlp-5.0.4-py3-none-any.whl (17.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/17.9 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: python-crfsuite, pythainlp\nSuccessfully installed pythainlp-5.0.4 python-crfsuite-0.9.10\n","output_type":"stream"}]},{"cell_type":"code","source":"from pythainlp.phayathaibert.core import NamedEntityTagger\nimport re\nimport pandas as pd\n\ntagger = NamedEntityTagger()","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:10:30.590513Z","iopub.execute_input":"2024-09-05T06:10:30.590830Z","iopub.status.idle":"2024-09-05T06:10:50.815818Z","shell.execute_reply.started":"2024-09-05T06:10:30.590797Z","shell.execute_reply":"2024-09-05T06:10:50.815049Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/527 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abaf95fa0d9749a3bf266ed7ccac6cbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47906fad89aa480396568885f956c6c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/15.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bdd96b2c992432e9bfd800cde49761d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/364 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7068973f1e0c450790de16293e118f65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bec015c526974fc6b73fb3b17621b30e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/144k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec3f3c75c084202b19060973d799cda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.26M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57cf10750d3f4014ad784498a9e93a54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb9dd0fbf3cd4c55bb94ebbecce35b68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/15.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5e707044dbb4549986b46b1d8ea72d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/364 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01efd9c1a3e34f518ff45b19d7239167"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/2.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b391ff16eeb447ccaf8f33176c9fc3d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e1c3176be46436895d2f4517cd02d09"}},"metadata":{}}]},{"cell_type":"markdown","source":"## MULTIPLE PDFs","metadata":{}},{"cell_type":"code","source":"import os\nimport easyocr\nimport pandas as pd\nimport shutil\nfrom pythainlp.phayathaibert.core import NamedEntityTagger\nimport re\nfrom tempfile import TemporaryDirectory\n\n# Define the function to extract text from images\ndef extract_text_from_image(image_path):\n    reader = easyocr.Reader(['th', 'en'])\n    result = reader.readtext(image_path)\n    sorted_data = sorted(result, key=lambda x: x[0][0][1])\n    plain_text = \"\\n\".join([text for _, text, _ in sorted_data])\n    return plain_text\n\n# Convert PDF to images\ndef convert_pdf_to_images(pdf_path, output_dir):\n    pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n    output_pattern = os.path.join(output_dir, f\"{pdf_filename}_%d.png\")\n    os.system(f'gs -dBATCH -dNOPAUSE -sDEVICE=pngalpha -r300 -sOutputFile=\"{output_pattern}\" \"{pdf_path}\"')\n\n# Function to split text into chunks based on token length\ndef chunk_text(text, tokenizer, max_tokens=512):\n    tokens = tokenizer.tokenize(text)\n    chunks = []\n    for i in range(0, len(tokens), max_tokens):\n        chunk = tokenizer.convert_tokens_to_string(tokens[i:i+max_tokens])\n        chunks.append(chunk)\n    return chunks\n\n# Tag and clean text with chunking\ndef tag_and_clean_text(text, tagger, tokenizer, unwanted_pattern):\n    text_chunks = chunk_text(text, tokenizer)\n    \n    tagged_text = \"\"\n    cleaned_text = \"\"\n\n    for chunk in text_chunks:\n        ner = tagger.get_ner(chunk, tag=True)\n        pattern = r'<(?!ORGANIZATION|PERCENT|TIME)[^>]+>[^<]+</[^>]+>'\n        cleaned_ner = re.sub(pattern, '', ner)\n        cleaned_ner = re.sub(r'</?(ORGANIZATION|PERCENT|TIME)>', '', cleaned_ner)\n        cleaned_ner = re.sub(unwanted_pattern, '', cleaned_ner, flags=re.IGNORECASE)\n        cleaned_ner = re.sub(r'\\bal\\b', 'ai', cleaned_ner, flags=re.IGNORECASE)\n        \n        tagged_text += ner + \"\\n\"\n        cleaned_text += cleaned_ner + \"\\n\"\n\n    return tagged_text.strip(), cleaned_text.strip()\n\n# Define the function to process and clean multiple PDFs\ndef process_pdfs_in_directory(pdf_dir):\n    tagger = NamedEntityTagger()\n    tokenizer = tagger.tokenizer\n\n    unwanted_terms = [\n        'ที่อยู่', 'โทรศัพท์', 'อีเมล', 'linkedin', ':', ',', '-', '|',\n        'ประวัติส่วนตัว', 'เกี่ยวกับฉัน', 'about me', 'ชื่อ', 'สกุล', 'tell', 'โทร', 'โทรงาน',\n        'ชื่อเล่น', 'อายุ', 'วันเกิด', 'พุทธ', 'ศาสนา', 'สัญชาติ', 'phone',\n        'ช่องทางการติดต่อ', '_', 're sume', 'resume', 'resu me'\n    ]\n    unwanted_pattern = '|'.join(map(re.escape, unwanted_terms))\n\n    results = []\n    for pdf_file in os.listdir(pdf_dir):\n        if pdf_file.lower().endswith('.pdf'):\n            pdf_path = os.path.join(pdf_dir, pdf_file)\n\n            with TemporaryDirectory() as temp_dir:\n                images_dir = os.path.join(temp_dir, 'images')\n                os.makedirs(images_dir, exist_ok=True)\n\n                # Convert the PDF to images\n                convert_pdf_to_images(pdf_path, images_dir)\n\n                # Extract text from all images related to the PDF file\n                raw_text = \"\"\n                pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n                for img_file in os.listdir(images_dir):\n                    if img_file.startswith(pdf_filename):\n                        img_path = os.path.join(images_dir, img_file)\n                        raw_text += extract_text_from_image(img_path) + \"\\n\"\n\n                # Tag and clean the extracted text using chunking\n                tagged_text, cleaned_text = tag_and_clean_text(raw_text, tagger, tokenizer, unwanted_pattern)\n\n                # Append the result to the list\n                results.append({\n                    \"PDF File\": pdf_file,\n                    \"Raw_Text\": raw_text,\n                    \"Tagged_Text\": tagged_text,\n                    \"Cleaned_Text\": cleaned_text\n                })\n\n    # Create a DataFrame with all results\n    df = pd.DataFrame(results)\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:26:24.591496Z","iopub.execute_input":"2024-09-05T06:26:24.591922Z","iopub.status.idle":"2024-09-05T06:26:24.611764Z","shell.execute_reply.started":"2024-09-05T06:26:24.591885Z","shell.execute_reply":"2024-09-05T06:26:24.610892Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Example usage\npdf_dir = '/kaggle/input/resume'\ndf = process_pdfs_in_directory(pdf_dir)","metadata":{"execution":{"iopub.status.idle":"2024-09-05T06:28:42.695246Z","shell.execute_reply.started":"2024-09-05T06:26:27.259189Z","shell.execute_reply":"2024-09-05T06:28:42.694121Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"},{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:28:42.697242Z","iopub.execute_input":"2024-09-05T06:28:42.697573Z","iopub.status.idle":"2024-09-05T06:28:42.712250Z","shell.execute_reply.started":"2024-09-05T06:28:42.697538Z","shell.execute_reply":"2024-09-05T06:28:42.711124Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"                          PDF File  \\\n0                  Resume BA 2.pdf   \n1   AI-engineer-resume-example.pdf   \n2                  Resume ba 5.pdf   \n3                     resume 6.pdf   \n4                     resume 1.pdf   \n5                     resume 7.pdf   \n6                     resume 4.pdf   \n7                   Resume baa.pdf   \n8                   Resume ba2.pdf   \n9                     resume 3.pdf   \n10                    resume 5.pdf   \n11                    resume 2.pdf   \n12                 Resume BA 3.pdf   \n\n                                             Raw_Text  \\\n0   พิมพ์นารา วัฒนชัย\\nที่อยู่: 789 ถนนรัชดาภิเษก,...   \n1   alexander jones\\nartificial intelligence engin...   \n2   081-456-7890\\nนัทธมน ฺรัตนโชติ\\nnattamon. rado...   \n3    linkedin:\\nนภัสสร วิวัฒนาวงศ์\\nlinkedin.com i...   \n4   สมหญิง\\n แก้วกาจญ์\\nวิศวกรปัญญาประดิษฐ์\\nal ที...   \n5   ปัญญา วิริยะชัย\\n วิศวกรปัญญาประดิษฐ์\\nประสบกา...   \n6    อาทิตย์\\nรัตนวิจิตร\\n วิศวกรปัญญาประดิษฐ์\\nปร...   \n7   ธนกร อินทรีย์พงษ์\\n ที่อยู่:\\n456 ถนนพระราม 3 ...   \n8    ศุภกิจฺ มงคลชัย\\n089-234-5678\\n supakit.m@dom...   \n9   re sume\\n ประวัติส่วนตัว\\n090-123-4567\\npimcha...   \n10  ศิรินทิพย์\\nศรีวัฒนกิจ\\n วิศวกรปัญญาประดิษฐ์\\n...   \n11   วงศ์เจริญ\\nณ็ชพล\\n วิศวกรปัญญาประดิษฐ์\\n ประว...   \n12   จิตรลดา\\n086-234-5678\\n jitlada.s@domain.com\\...   \n\n                                          Tagged_Text  \\\n0   <PERSON>พ</PERSON><PERSON>พิมพ์</PERSON><PERSO...   \n1   alexander jones artificial intelligence engine...   \n2   <PHONE>08</PHONE><PERSON>1-4</PERSON><PERSON>5...   \n3   linkedin:<PERSON> </PERSON><PERSON>น</PERSON><...   \n4   <PERSON>ส</PERSON><PERSON>สม</PERSON><PERSON>ห...   \n5   <PERSON>ป</PERSON><PERSON>ปัญญา วิริยะชัย</PER...   \n6   <PERSON>อ</PERSON><PERSON>อาทิตย์ รัตนวิจิตร</...   \n7   <PERSON>ธ</PERSON><PERSON>ธน</PERSON><PERSON>ก...   \n8   <PERSON>ศ</PERSON><PERSON>ศุภ</PERSON><PERSON>...   \n9   re sume ประวัติส่วนตัว<PHONE> 09</PHONE><PHONE...   \n10  <PERSON>ศ</PERSON><PERSON>ศิริ</PERSON><PERSON...   \n11  <PERSON>วงศ์เจริญ ณ็ชพล</PERSON> วิศวกรปัญญาปร...   \n12  <PERSON>จ</PERSON><PERSON>จิตร</PERSON><PERSON...   \n\n                                         Cleaned_Text  \n0   เป้าหมายในการทํางาน นําความเชี่ยวชาญด้านการวิเ...  \n1   alexander jones artificial inigence engineer i...  \n2   เป้าหมายในการ มุ่งมันในการนําทักษะด้านการจัดกา...  \n3   in วิศวกรปัญญาประดิษฐ์  ประสบการณ์การทํางาน วิ...  \n4   วิศวกรปัญญาประดิษฐ์ ai ที่มีประสบการณ์ 3 ปในกา...  \n5   วิศวกรปัญญาประดิษฐ์ ประสบการณ์การฝึกงาน บัณฑิต...  \n6   วิศวกรปัญญาประดิษฐ์ ประสบการณ์ ทํางาน วิศวกร a...  \n7   เป้าหมายในการทํางาน มุ่งมันที่จะใช้ความรู้และท...  \n8   ประสบการณ์การ เป้าหมายในการทางาน financial ana...  \n9   ที่มีประสบการณ์ 4 ฺdี ผู้ เชี่ยวชาญด้าน ในด้าน...  \n10  วิศวกรปัญญาประดิษฐ์ ประสบการณ์ทํางาน  วิศวกร a...  \n11  วิศวกรปัญญาประดิษฐ์ ประวัติการศึกษา 2016 มหาวิ...  \n12  เสริมs business analyst เป้าหมายในการทํางาน ต้...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PDF File</th>\n      <th>Raw_Text</th>\n      <th>Tagged_Text</th>\n      <th>Cleaned_Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Resume BA 2.pdf</td>\n      <td>พิมพ์นารา วัฒนชัย\\nที่อยู่: 789 ถนนรัชดาภิเษก,...</td>\n      <td>&lt;PERSON&gt;พ&lt;/PERSON&gt;&lt;PERSON&gt;พิมพ์&lt;/PERSON&gt;&lt;PERSO...</td>\n      <td>เป้าหมายในการทํางาน นําความเชี่ยวชาญด้านการวิเ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AI-engineer-resume-example.pdf</td>\n      <td>alexander jones\\nartificial intelligence engin...</td>\n      <td>alexander jones artificial intelligence engine...</td>\n      <td>alexander jones artificial inigence engineer i...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Resume ba 5.pdf</td>\n      <td>081-456-7890\\nนัทธมน ฺรัตนโชติ\\nnattamon. rado...</td>\n      <td>&lt;PHONE&gt;08&lt;/PHONE&gt;&lt;PERSON&gt;1-4&lt;/PERSON&gt;&lt;PERSON&gt;5...</td>\n      <td>เป้าหมายในการ มุ่งมันในการนําทักษะด้านการจัดกา...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>resume 6.pdf</td>\n      <td>linkedin:\\nนภัสสร วิวัฒนาวงศ์\\nlinkedin.com i...</td>\n      <td>linkedin:&lt;PERSON&gt; &lt;/PERSON&gt;&lt;PERSON&gt;น&lt;/PERSON&gt;&lt;...</td>\n      <td>in วิศวกรปัญญาประดิษฐ์  ประสบการณ์การทํางาน วิ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>resume 1.pdf</td>\n      <td>สมหญิง\\n แก้วกาจญ์\\nวิศวกรปัญญาประดิษฐ์\\nal ที...</td>\n      <td>&lt;PERSON&gt;ส&lt;/PERSON&gt;&lt;PERSON&gt;สม&lt;/PERSON&gt;&lt;PERSON&gt;ห...</td>\n      <td>วิศวกรปัญญาประดิษฐ์ ai ที่มีประสบการณ์ 3 ปในกา...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>resume 7.pdf</td>\n      <td>ปัญญา วิริยะชัย\\n วิศวกรปัญญาประดิษฐ์\\nประสบกา...</td>\n      <td>&lt;PERSON&gt;ป&lt;/PERSON&gt;&lt;PERSON&gt;ปัญญา วิริยะชัย&lt;/PER...</td>\n      <td>วิศวกรปัญญาประดิษฐ์ ประสบการณ์การฝึกงาน บัณฑิต...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>resume 4.pdf</td>\n      <td>อาทิตย์\\nรัตนวิจิตร\\n วิศวกรปัญญาประดิษฐ์\\nปร...</td>\n      <td>&lt;PERSON&gt;อ&lt;/PERSON&gt;&lt;PERSON&gt;อาทิตย์ รัตนวิจิตร&lt;/...</td>\n      <td>วิศวกรปัญญาประดิษฐ์ ประสบการณ์ ทํางาน วิศวกร a...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Resume baa.pdf</td>\n      <td>ธนกร อินทรีย์พงษ์\\n ที่อยู่:\\n456 ถนนพระราม 3 ...</td>\n      <td>&lt;PERSON&gt;ธ&lt;/PERSON&gt;&lt;PERSON&gt;ธน&lt;/PERSON&gt;&lt;PERSON&gt;ก...</td>\n      <td>เป้าหมายในการทํางาน มุ่งมันที่จะใช้ความรู้และท...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Resume ba2.pdf</td>\n      <td>ศุภกิจฺ มงคลชัย\\n089-234-5678\\n supakit.m@dom...</td>\n      <td>&lt;PERSON&gt;ศ&lt;/PERSON&gt;&lt;PERSON&gt;ศุภ&lt;/PERSON&gt;&lt;PERSON&gt;...</td>\n      <td>ประสบการณ์การ เป้าหมายในการทางาน financial ana...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>resume 3.pdf</td>\n      <td>re sume\\n ประวัติส่วนตัว\\n090-123-4567\\npimcha...</td>\n      <td>re sume ประวัติส่วนตัว&lt;PHONE&gt; 09&lt;/PHONE&gt;&lt;PHONE...</td>\n      <td>ที่มีประสบการณ์ 4 ฺdี ผู้ เชี่ยวชาญด้าน ในด้าน...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>resume 5.pdf</td>\n      <td>ศิรินทิพย์\\nศรีวัฒนกิจ\\n วิศวกรปัญญาประดิษฐ์\\n...</td>\n      <td>&lt;PERSON&gt;ศ&lt;/PERSON&gt;&lt;PERSON&gt;ศิริ&lt;/PERSON&gt;&lt;PERSON...</td>\n      <td>วิศวกรปัญญาประดิษฐ์ ประสบการณ์ทํางาน  วิศวกร a...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>resume 2.pdf</td>\n      <td>วงศ์เจริญ\\nณ็ชพล\\n วิศวกรปัญญาประดิษฐ์\\n ประว...</td>\n      <td>&lt;PERSON&gt;วงศ์เจริญ ณ็ชพล&lt;/PERSON&gt; วิศวกรปัญญาปร...</td>\n      <td>วิศวกรปัญญาประดิษฐ์ ประวัติการศึกษา 2016 มหาวิ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Resume BA 3.pdf</td>\n      <td>จิตรลดา\\n086-234-5678\\n jitlada.s@domain.com\\...</td>\n      <td>&lt;PERSON&gt;จ&lt;/PERSON&gt;&lt;PERSON&gt;จิตร&lt;/PERSON&gt;&lt;PERSON...</td>\n      <td>เสริมs business analyst เป้าหมายในการทํางาน ต้...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df['Cleaned_Text'].iloc[9])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:29:01.482795Z","iopub.execute_input":"2024-09-05T06:29:01.483678Z","iopub.status.idle":"2024-09-05T06:29:01.488718Z","shell.execute_reply.started":"2024-09-05T06:29:01.483639Z","shell.execute_reply":"2024-09-05T06:29:01.487769Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"ที่มีประสบการณ์ 4 ฺdี ผู้ เชี่ยวชาญด้าน ในด้านการพัฒนาโซลูชันการเรียนรู้ของ วิศวกรปัญญาประดิษฐ์ สําหรับการวิเคราะห์ ข้อมูล เครืองและ ai โดยใช้ scikit learn และ keras มี ธุรกิจ ทักษะ ความสามารถ .. ความสามารถในการจัดการข้อมูลขนาด ใหญ่และสร้างโมเดลที่ช่วยเพิ่ม ภาษา1โปรแกรม python c++ ประสิทธิภาพในการตัดสินใจเชิงธุรกิจ การประมวลผลภาพ opencv pillow การเรียนรู้เชิงลึก tensorflow. keras ประวัติการทํางาน การจัดการข้อมูล sol solite วิศวกร ปัจจุบัน  พัฒนาโมเดล machine learning เพือ ประกาศนียบัตร การพยากรณ์ทางการเงินที่ช่วยให้การ ตัดสินใจเชิงกลยุทธ์มีความแม่นยําขึ้น google cloud professional data engineer 30% ร่วมมือกับทีมวิเคราะห์ ข้อมูลเพือทําการ coursera machine learning by จัดการข้อมูลและสร้างรายงานที่มี stanford ประสิทธิภาพ สําหรับผู้บริหาร ข้อมูลการศึกษา ผู้ ช่วยวิจัย ai ศึกษานารี มัธยมศึกษา   อุดมศึกษา มหาวิทยาลัยธรรมศาสตร์\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## SINGLE PDF","metadata":{}},{"cell_type":"code","source":"import os\nimport easyocr\nimport pandas as pd\nimport shutil\nfrom pythainlp.phayathaibert.core import NamedEntityTagger\nimport re\nfrom tempfile import TemporaryDirectory\n\n# Define the function to extract text from images\ndef extract_text_from_image(image_path):\n    reader = easyocr.Reader(['th', 'en'])\n    result = reader.readtext(image_path)\n    sorted_data = sorted(result, key=lambda x: x[0][0][1])\n    plain_text = \"\\n\".join([text for _, text, _ in sorted_data])\n    return plain_text\n\n# Convert PDF to images\ndef convert_pdf_to_images(pdf_path, output_dir):\n    pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n    output_pattern = os.path.join(output_dir, f\"{pdf_filename}_%d.png\")\n    os.system(f'gs -dBATCH -dNOPAUSE -sDEVICE=pngalpha -r300 -sOutputFile=\"{output_pattern}\" \"{pdf_path}\"')\n\n# Function to split text into chunks based on token length\ndef chunk_text(text, tokenizer, max_tokens=512):\n    tokens = tokenizer.tokenize(text)\n    chunks = []\n    for i in range(0, len(tokens), max_tokens):\n        chunk = tokenizer.convert_tokens_to_string(tokens[i:i+max_tokens])\n        chunks.append(chunk)\n    return chunks\n\n# Modified tag and clean text function with chunking\ndef tag_and_clean_text(text, tagger, tokenizer):\n    text_chunks = chunk_text(text, tokenizer)\n    \n    tagged_text = \"\"\n    cleaned_text = \"\"\n\n    unwanted_terms = [\n        'ที่อยู่', 'โทรศัพท์', 'อีเมล', 'linkedin', ':', ',', '-', '|',\n        'ประวัติส่วนตัว', 'เกี่ยวกับฉัน', 'about me', 'ชื่อ', 'สกุล', 'tell', 'โทร', 'โทรงาน',\n        'ชื่อเล่น', 'อายุ', 'วันเกิด', 'พุทธ', 'ศาสนา', 'สัญชาติ', 'phone',\n        'ช่องทางการติดต่อ', '_', 're sume', 'resume', 'resu me'\n    ]\n    unwanted_pattern = '|'.join(map(re.escape, unwanted_terms))\n\n    for chunk in text_chunks:\n        # Tag each chunk using the model\n        ner = tagger.get_ner(chunk, tag=True)\n        \n        # Clean the tagged text\n        pattern = r'<(?!ORGANIZATION|PERCENT|TIME)[^>]+>[^<]+</[^>]+>'\n        cleaned_ner = re.sub(pattern, '', ner)\n        cleaned_ner = re.sub(r'</?(ORGANIZATION|PERCENT|TIME)>', '', cleaned_ner)\n        cleaned_ner = re.sub(unwanted_pattern, '', cleaned_ner, flags=re.IGNORECASE)\n        cleaned_ner = re.sub(r'\\bal\\b', 'ai', cleaned_ner, flags=re.IGNORECASE)\n        \n        # Append results from the chunk to the overall text\n        tagged_text += ner + \"\\n\"\n        cleaned_text += cleaned_ner + \"\\n\"\n\n    return tagged_text.strip(), cleaned_text.strip()\n\n# Define the function to process and clean a single PDF\ndef process_single_pdf(pdf_path):\n    with TemporaryDirectory() as temp_dir:\n        # Create a temporary directory for images\n        images_dir = os.path.join(temp_dir, 'images')\n        os.makedirs(images_dir, exist_ok=True)\n\n        # Convert the PDF to images in the temporary directory\n        convert_pdf_to_images(pdf_path, images_dir)\n\n        # Initialize the Named Entity Tagger\n        tagger = NamedEntityTagger()\n        tokenizer = tagger.tokenizer\n\n        # Extract text from all images related to the PDF file\n        raw_text = \"\"\n        pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n        for img_file in os.listdir(images_dir):\n            if img_file.startswith(pdf_filename):\n                img_path = os.path.join(images_dir, img_file)\n                raw_text += extract_text_from_image(img_path) + \"\\n\"\n\n        # Tag and clean the extracted text using the chunking approach\n        tagged_text, cleaned_text = tag_and_clean_text(raw_text, tagger, tokenizer)\n\n        # Create a DataFrame with the result\n        data = {\n            \"PDF File\": os.path.basename(pdf_path),\n            \"Raw_Text\": raw_text,\n            \"Tagged_Text\": tagged_text,\n            \"Cleaned_Text\": cleaned_text\n        }\n        df = pd.DataFrame([data])\n\n        return df\n","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:25:30.368124Z","iopub.execute_input":"2024-09-05T06:25:30.368897Z","iopub.status.idle":"2024-09-05T06:25:30.388188Z","shell.execute_reply.started":"2024-09-05T06:25:30.368843Z","shell.execute_reply":"2024-09-05T06:25:30.387373Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Example usage\ntest = '/kaggle/input/resume/AI-engineer-resume-example.pdf'\ntest1 = process_single_pdf(test)","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:25:32.678699Z","iopub.execute_input":"2024-09-05T06:25:32.679302Z","iopub.status.idle":"2024-09-05T06:25:50.482492Z","shell.execute_reply.started":"2024-09-05T06:25:32.679255Z","shell.execute_reply":"2024-09-05T06:25:50.481458Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"GPL Ghostscript 10.03.1 (2024-05-02)\nCopyright (C) 2024 Artifex Software, Inc.  All rights reserved.\nThis software is supplied under the GNU AGPLv3 and comes with NO WARRANTY:\nsee the file COPYING for details.\nProcessing pages 1 through 1.\nPage 1\n","output_type":"stream"},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 510). Running this sequence through the model will result in indexing errors\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\nHardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(test1['Cleaned_Text'].iloc[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-05T06:25:50.484503Z","iopub.execute_input":"2024-09-05T06:25:50.484880Z","iopub.status.idle":"2024-09-05T06:25:50.490423Z","shell.execute_reply.started":"2024-09-05T06:25:50.484845Z","shell.execute_reply":"2024-09-05T06:25:50.489346Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"alexander jones artificial inigence engineer innovative artificial inigence engineer with 12+ years of experience in application design development testing and deployment. highly experienced in writing codes and algorithms as well as building complex neural. networks through various programming languages. possess an unbridled passion for artificial inigence with comprehensive knowledge of machine learning concepts and other related technologies. unmatched abilities to identify. understand and translate program requirements into sustainable javascript python through c# programs for continuous improvement of advanced technical and other solutions c++ ai in work experience areas of expertise artificial inigence engineer ai engineering software prototyping the arts of artificial game tech solutions decision analytics scrum & agile methodologies 05/2017\nbase through galaxy combat mobile game application (2015) artificial inigence and big data analysis and programming languages expertise along leveraged coding contributed innovative ideas to improve the technology in with industry best practices to develop and deploy this mobile lot security resulting in a 28% increase in business revenue with excellent graphics and game application for android user friendly features in the second quarter worked alongside a team of ai personnel to develop test threats and deploy effectively software that detects education learning through inigence artificial and machine applications principles to secure various lot university of massachusetts lowell bachelor ofscience in computer engineering artificial inigence intern ai active reality machines corp. low\n","output_type":"stream"}]}]}