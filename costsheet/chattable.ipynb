{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/costsheet/chattable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUqSEnVta_yf",
        "outputId": "c83308b8-9119-4b77-aec6-d0f8757015f6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.4/447.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install huggingface_hub transformers langchain langchain-community neo4j requests gradio torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from neo4j import GraphDatabase\n",
        "import time\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Z4aTxVQSbGUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import re\n",
        "\n",
        "# Neo4j database connection credentials\n",
        "NEO4J_URI = \"neo4j+s://ba8feaac.databases.neo4j.io\"\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"P5vvwJNewVk42Ey31ynvL9vrRRx98vlmv_5NnmVtshw\"\n",
        "\n",
        "# Define the Neo4j driver connection\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "\n",
        "# Define your LLM API endpoint and key\n",
        "api_url02 = 'https://ai-api.manageai.co.th/llm-model-02/'\n",
        "api_url03 = 'https://ai-api.manageai.co.th/llm-model-03/'\n",
        "api_key = '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'\n"
      ],
      "metadata": {
        "id": "csj0SYxZmsWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Process**"
      ],
      "metadata": {
        "id": "TnPFha86mhDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base_prompt():\n",
        "    return '''\n",
        "    You are an expert Cypher query generator for a graph database with the following nodes and relationships:\n",
        "\n",
        "    - **Nodes:**\n",
        "      - `Seller`: Represents a seller with properties: `id` (string), `name` (string).\n",
        "      - `Customer`: Represents a customer with properties: `id` (string), `name` (string).\n",
        "      - `SaleOrder`: Represents a sales order with properties: `SONumber` (string), `ContractStartDate` (Date), `ContractEndDate` (Date), `Total` (float), `DaysDuration` (integer).\n",
        "      - `CostSheet`: Represents a cost sheet with properties: `CSNumber` (string), `Internal` (float), `External` (float).\n",
        "      - `Service`: Represents a service with properties: `Service` (string), `Original` (string).\n",
        "      - `Platform`: Represents a platform with the property: `Original` (string).\n",
        "\n",
        "    - **Relationships:**\n",
        "      - `HAS_COST_SHEET`: Connects `SaleOrder` to `CostSheet`.\n",
        "      - `PROVIDES_SERVICE`: Connects `SaleOrder` to `Service`.\n",
        "      - `SERVICE_COST`: Connects `CostSheet` to `Service` with properties: `Internal` (float), `External` (float), `Total` (float).\n",
        "      - `DEPLOYED_ON`: Connects `Service` to `Platform`.\n",
        "      - `PLACED_ORDER`: Connects `Customer` to `SaleOrder` with properties: `ContractStartDate` (Date), `ContractEndDate` (Date), `DaysDuration` (integer).\n",
        "      - `HANDLED_ORDER`: Connects `Seller` to `SaleOrder`.\n",
        "\n",
        "    **Important Instructions**:\n",
        "    - Your task is to generate a **single Cypher query** based on the question.\n",
        "    - **Provide only the Cypher query, nothing else**. Do not include explanations, comments, or any additional text.\n",
        "    - Ensure the query is **valid** and uses **correct property and relationship names**.\n",
        "    - Stop after generating the query (end with \";\").\n",
        "    - **Do not use SQL-style subqueries**\n",
        "    - Do not use SQL-style subqueries like 'SELECT MAX'. Instead, sort the results and limit it to get the highest or lowest value.\n",
        "    - To get the record with the maximum value, you must use `ORDER BY` within the main query.\n",
        "\n",
        "    Your task is to generate a **single Cypher query** based on the question.\n",
        "\n",
        "    - **Provide only the Cypher query, nothing else.**\n",
        "    - **Do not provide explanations, markdown syntax, or additional words except the query.**\n",
        "    - Ensure the query is **valid** and uses **correct property and relationship names**.\n",
        "    - Stop after generating the query (end with \";\").\n",
        "\n",
        "    Given the question: {question}\n",
        "    '''"
      ],
      "metadata": {
        "id": "2Eb2eL_RbPtS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**regex**"
      ],
      "metadata": {
        "id": "2qDd0Eo1bIqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract(response):\n",
        "    try:\n",
        "        clean_response = re.sub(r'```cypher|```', '', response)\n",
        "        clean_response = re.sub(r'^\\*/\\s*', '', clean_response, flags=re.MULTILINE)\n",
        "        clean_response = clean_response.replace(\"### Response:\", \"\").strip()\n",
        "        clean_response = re.sub(r'\\bassistant\\b.*$', '', clean_response, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "        response_split = re.split(r'response:', clean_response, flags=re.IGNORECASE)\n",
        "        if len(response_split) > 1:\n",
        "            clean_response = response_split[1].strip()\n",
        "        match_index = clean_response.lower().find(\"match\")\n",
        "        if match_index != -1:\n",
        "            clean_response = clean_response[match_index:].strip()\n",
        "        match = re.search(r'([^;]*;)', clean_response)\n",
        "        if match:\n",
        "            return match.group(0)\n",
        "        cypher_queries = re.split(r'Given the question:', clean_response)\n",
        "        extracted_queries = [query.strip() for query in cypher_queries if query.strip()]\n",
        "\n",
        "        if extracted_queries:\n",
        "            seen_queries = set()\n",
        "            unique_queries = []\n",
        "            for query in extracted_queries:\n",
        "                if query not in seen_queries:\n",
        "                    seen_queries.add(query)\n",
        "                    unique_queries.append(query)\n",
        "            return unique_queries[0] if unique_queries else None\n",
        "        else:\n",
        "            return clean_response.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error during extraction: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "4E8CBjYAbK0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cypher_query(cypher_query):\n",
        "    with driver.session() as session:\n",
        "        result = session.run(cypher_query)\n",
        "        return result.data()  # Return all records as a list of dictionaries\n",
        "\n",
        "def format_result_record(result_record, max_records=10):\n",
        "    if isinstance(result_record, list):\n",
        "        limited_records = result_record[:max_records]\n",
        "        formatted_strings = [\", \".join([f\"{key}: {value}\" for key, value in record.items()]) for record in limited_records]\n",
        "        return \"\\n\".join(formatted_strings)\n",
        "    return str(result_record)"
      ],
      "metadata": {
        "id": "P_95XOkIbQSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **query prompt**"
      ],
      "metadata": {
        "id": "FD7V4cKykwJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt1(question):\n",
        "    try:\n",
        "        baseprompt = get_base_prompt()\n",
        "        formatted_prompt = baseprompt.replace(\"{question}\", question)\n",
        "\n",
        "        # Model parameters\n",
        "        model_params = {\n",
        "            'max_new_tokens': 512,\n",
        "            'temperature': 0.001,\n",
        "            'top_p': 0.95,\n",
        "            'repetition_penalty': 1.0\n",
        "        }\n",
        "\n",
        "        # Send the prompt to the language model for Cypher generation\n",
        "        client = InferenceClient(base_url=api_url02, api_key=api_key)\n",
        "        response = client.text_generation(formatted_prompt, **model_params)\n",
        "\n",
        "        # Extract the Cypher query from the LLM response\n",
        "        clean_cypher_query = extract(response.strip())\n",
        "        return clean_cypher_query\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating query: {str(e)}\")\n",
        "        return f\"Error generating query: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "tPE4OkiUkc0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def chatbot_response(message):\n",
        "    try:\n",
        "        # Get the Cypher query\n",
        "        cypher_query = prompt1(message)\n",
        "        print(f\"Generated Cypher Query: {cypher_query}\")\n",
        "\n",
        "        if cypher_query:\n",
        "            result_record = run_cypher_query(cypher_query)\n",
        "            print(f\"Result Record: {result_record}\")\n",
        "\n",
        "            if result_record and isinstance(result_record, list):\n",
        "                # Return the result_record as a DataFrame-friendly format (list of dictionaries)\n",
        "                return result_record\n",
        "            else:\n",
        "                return \"No relevant data found in the database.\"\n",
        "        else:\n",
        "            return \"Failed to generate a valid Cypher query.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "nNevhDl9kngJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## interface"
      ],
      "metadata": {
        "id": "tcF_6Eer8ZIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define the Gradio theme and layout\n",
        "theme = gr.themes.Default(\n",
        "    text_size=\"sm\",\n",
        "    primary_hue=\"blue\"\n",
        ")\n",
        "\n",
        "# Clear chat history\n",
        "def clear_chat():\n",
        "    return [], \"\", \"\"  # Clear the chatbot history, textbox, and question display\n",
        "\n",
        "# Helper function to format the table-like result into a readable text format\n",
        "def format_table_text(response):\n",
        "    if not response:\n",
        "        return \"No data available.\"\n",
        "\n",
        "    headers = list(response[0].keys())  # Get the table headers\n",
        "    rows = [list(record.values()) for record in response]  # Get the table rows\n",
        "\n",
        "    # Create a formatted string for table-like output\n",
        "    table_str = \"| \" + \" | \".join(headers) + \" |\\n\"\n",
        "    table_str += \"|---\" * len(headers) + \"|\\n\"\n",
        "    for row in rows:\n",
        "        table_str += \"| \" + \" | \".join(map(str, row)) + \" |\\n\"\n",
        "\n",
        "    return table_str\n",
        "\n",
        "with gr.Blocks(theme=theme) as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align: center;'>Sales Assistant Chatbot 💬</h1>\", elem_id=\"title\")\n",
        "\n",
        "    with gr.Column(elem_id=\"chatbot-container\"):\n",
        "        chat_history = gr.Chatbot(label=\"Chat History\", height=500)  # Chatbot to display the conversation history\n",
        "        msg = gr.Textbox(placeholder=\"Ask about orders, services, and more...\", label=\"Type your question here:\", show_label=True)\n",
        "        clear = gr.Button(\"Clear Chat\", elem_id=\"gr-button\")\n",
        "\n",
        "        # Submit message and get response\n",
        "        async def submit_action(message, history):\n",
        "            response = await chatbot_response(message)\n",
        "\n",
        "            # If response is a list (result record)\n",
        "            if isinstance(response, list):\n",
        "                # Convert the response into a text format table\n",
        "                table_text = format_table_text(response)\n",
        "                # Append the question and formatted table to history as strings\n",
        "                history.append((f\"Q: {message}\", f\"Table Result:\\n{table_text}\"))\n",
        "            else:  # If the response is not a table\n",
        "                history.append((f\"Q: {message}\", f\"Error occurred: {str(response)}\"))\n",
        "\n",
        "            return history, \"\"  # Update the chat history and clear the input box\n",
        "\n",
        "        # Set up the message submission to call submit_action\n",
        "        msg.submit(submit_action, [msg, chat_history], [chat_history, msg])\n",
        "\n",
        "        # Clear button functionality - Reset chat UI and textbox\n",
        "        clear.click(clear_chat, None, [chat_history, msg])\n",
        "\n",
        "# Launch the Gradio app\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "id": "m0Eh7cxTnAh8",
        "outputId": "bd565e79-dc56-49d5-d4ee-bf8c7adf4660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:223: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://5594d8f66c99fd96a9.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5594d8f66c99fd96a9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Cypher Query: MATCH (c:Customer)-[:PLACED_ORDER]->(so:SaleOrder)\n",
            "    WITH c, SUM(so.Total) as totalSales\n",
            "    ORDER BY totalSales DESC\n",
            "    RETURN c.name, totalSales\n",
            "    LIMIT 1;\n",
            "Result Record: [{'c.name': 'บัตรกรุงไทย', 'totalSales': 5028824.74}]\n",
            "Generated Cypher Query: MATCH (so:SaleOrder)-[:HAS_COST_SHEET]->(cs:CostSheet)<-[:SERVICE_COST]-(s:Service)\n",
            "    WHERE cs.Total = (SELECT MAX(cs2.Total) FROM (MATCH (so2:SaleOrder)-[:HAS_COST_SHEET]->(cs2:CostSheet) RETURN cs2.Total) AS maxTotal)\n",
            "    RETURN so.SONumber AS SaleOrderNumber, cs.Total AS TotalValue, s.Service AS ServiceName;\n",
            "Generated Cypher Query: MATCH (s:Seller)-[:HANDLED_ORDER]->(so:SaleOrder)\n",
            "     WITH s, SUM(so.Total) as total_sales\n",
            "     RETURN s.name\n",
            "     ORDER BY total_sales DESC\n",
            "     LIMIT 1;\n",
            "Result Record: [{'s.name': 'นางสาวพัชราภรณ์ แนบเนียน'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:1751: UserWarning: A function (clear_chat) returned too many output values (needed: 2, returned: 3). Ignoring extra values.\n",
            "    Output components:\n",
            "        [chatbot, textbox]\n",
            "    Output values returned:\n",
            "        [[], \"\", \"\"]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Cypher Query: MATCH (s:Seller)-[:HANDLED_ORDER]->(so:SaleOrder)\n",
            "     WITH s, SUM(so.Total) as total_sales\n",
            "     RETURN s.name\n",
            "     ORDER BY total_sales DESC\n",
            "     LIMIT 1;\n",
            "Result Record: [{'s.name': 'นางสาวพัชราภรณ์ แนบเนียน'}]\n",
            "Generated Cypher Query: MATCH (s:SaleOrder)-[:PROVIDES_SERVICE]->(service:Service)\n",
            "    WITH service, COUNT(*) as frequency\n",
            "    ORDER BY frequency DESC\n",
            "    LIMIT 5\n",
            "    RETURN service.Service AS Service, frequency AS Frequency;\n",
            "Result Record: [{'Service': 'Cloud-AHV', 'Frequency': 1721}, {'Service': 'Platform-Etax', 'Frequency': 1626}, {'Service': 'Cloud-VMware', 'Frequency': 943}, {'Service': 'Network', 'Frequency': 651}, {'Service': 'Security', 'Frequency': 383}]\n",
            "Generated Cypher Query: MATCH (c:Customer)-[:PLACED_ORDER]->(so:SaleOrder)<-[:HANDLED_ORDER]-(s:Seller)\n",
            "    WITH c, so, s, so.DaysDuration / 365 * 10 AS discount\n",
            "    RETURN c.name AS CustomerName, so.SONumber AS SaleOrderNumber, discount AS Discount\n",
            "    ORDER BY discount DESC\n",
            "    LIMIT 5;\n",
            "Result Record: [{'CustomerName': 'พีทีที ดิจิตอล โซลูชั่น', 'SaleOrderNumber': 'SO01-20230900062', 'Discount': 190}, {'CustomerName': 'พีทีที ดิจิตอล โซลูชั่น', 'SaleOrderNumber': 'SO01-20230900066', 'Discount': 190}, {'CustomerName': 'บัตรกรุงไทย', 'SaleOrderNumber': 'SO01-20220100445', 'Discount': 100}, {'CustomerName': 'เอจีบี นีลเส็น มีเดีย รีเสิร์ช (ประเทศไทย)', 'SaleOrderNumber': 'SO02-20230300657', 'Discount': 100}, {'CustomerName': 'เก็ต ออน เทคโนโลยี', 'SaleOrderNumber': 'SO02-20230400469', 'Discount': 100}]\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://5594d8f66c99fd96a9.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **question**"
      ],
      "metadata": {
        "id": "fLEWX_vsNI05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Which customer has placed the highest total value of sales orders?\n",
        "# 2. Which sale order has the highest total value, and what services are linked to that sale order?\n",
        "# 3. find the sales order with the longest contract duration, including its linked services. Make sure to limit the result to one sales order for efficiency.\n",
        "# 4. Who is the sellers that handling the most valuable orders (based on total sales)?\n",
        "# 5. Top 5 services are deployed on the most platforms?\n",
        "# 6. the top 5 services that are most frequently associated with SaleOrder\n",
        "# 7. the top 5 services that are least frequently associated with SaleOrder\n",
        "# 8. Top 5 customers that have placed the most SaleOrders along with their number of sale orders and summation total value of SaleOrders\n",
        "# 9. Every SaleOrder has cost sheet, every costsheet has service cost, give me the top 5 services generate the highest internal costs for sellers?\n",
        "# 10. Can you provide the top 5 customers along with their sale orders and calculated discounts based on the DaysDuration from the SaleOrder? The discount should be calculated as 10% for every 365 days of the DaysDuration"
      ],
      "metadata": {
        "id": "tmtfjW1nNMKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focus on Key Details:\n",
        "# What is the total sales value for this customer?\n",
        "# How many orders has this customer placed?\n",
        "# What services has this customer used?\n",
        "# Can you list the last three orders placed by this customer?\n",
        "# What are the top two services this customer has used?"
      ],
      "metadata": {
        "id": "8hHDaQPrlviY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ลูกค้า id และ ชื่ออะไร ที่มีมูลค่าการสั่งซื้อรวมสูงสุด?\n",
        "# 2. บอกหมายเลขคำสั่งซื้อ (SONumber) ที่มีมูลค่าสูงสุดและมีบริการใดบ้างที่เชื่อมโยงกับการสั่งซื้อนั้น?\n",
        "# 3. บอกหมายเลขคำสั่งซื้อ (SONumber) หนึ่งรายการที่มีระยะเวลาสัญญายาวนานที่สุดรวมถึงบริการที่เชื่อมโยง\n",
        "# 4. ผู้ขายคนไหนที่รับผิดชอบการสั่งซื้อที่มีมูลค่าสูงสุด (ตามจำนวนออเดอร์การขาย)?\n",
        "# 5. บอก 5 บริการที่ถูกใช้งานบนแพลตฟอร์มมากที่สุด?\n",
        "# 6. บอก 5 บริการที่ถูกกล่าวถึง (PROVIDES SERVICE) กับการสั่งซื้อ (SaleOrder) มากที่สุด\n",
        "# 7. บอก 5 บริการที่ถูกกล่าวถึง (PROVIDES SERVICE) กับการสั่งซื้อ (SaleOrder) น้อยที่สุด\n",
        "# 8. บอก 5 ลูกค้าที่ทำการสั่งซื้อมากที่สุด พร้อมกับจำนวนการสั่งซื้อและยอดรวมมูลค่าของการสั่งซื้อ\n",
        "# 9. ทุกการสั่งซื้อมี cost sheet ทุก cost sheet มีค่าใช้จ่ายในการบริการช่วยบอกบริการ 5 อันดับ ที่สร้างค่าใช้จ่ายภายใน  (Internal cost) สูงสุดสำหรับผู้ขาย?\n",
        "# 10. บอก 5 ลูกค้าที่มีระยะเวลาระหว่างเริ่มต้นสัญญา - สิ้นสุดสัญญา (DaysDuration) ยาวนานที่สุด พร้อมกับบอกหมายเลขคำสั่งซื้อ และการคำนวณส่วนลดตาม DaysDuration จาก SaleOrder ได้ไหม? โดยส่วนลดจะถูกคำนวณเป็น 10% สำหรับทุกๆ 365 วันของ DaysDuration"
      ],
      "metadata": {
        "id": "Cu-eQCRxWnHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Retain and Reference Chat Context**"
      ],
      "metadata": {
        "id": "A3h_d9f7cFgI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TU8VnoMkcLWR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}