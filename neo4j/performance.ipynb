{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/neo4j/performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUqSEnVta_yf",
        "outputId": "f9c82695-7f9f-4c8f-d807-b4e2983999c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m917.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m401.8/401.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install huggingface_hub transformers langchain langchain-community neo4j requests gradio torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from neo4j import GraphDatabase\n",
        "import time\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Z4aTxVQSbGUb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import re\n",
        "\n",
        "# Neo4j database connection credentials\n",
        "NEO4J_URI = \"neo4j+s://ba8feaac.databases.neo4j.io\"\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"P5vvwJNewVk42Ey31ynvL9vrRRx98vlmv_5NnmVtshw\"\n",
        "\n",
        "# Define the Neo4j driver connection\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "\n",
        "# Define your LLM API endpoint and key\n",
        "api_url02 = 'https://ai-api.manageai.co.th/llm-model-02/'\n",
        "api_url03 = 'https://ai-api.manageai.co.th/llm-model-03/'\n",
        "api_key = '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'\n"
      ],
      "metadata": {
        "id": "csj0SYxZmsWS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**run this once**"
      ],
      "metadata": {
        "id": "p0W8G_D1eB79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
        "# def transform_dates_and_floats(tx):\n",
        "#     tx.run(\"\"\"\n",
        "#     MATCH (s:SaleOrder)\n",
        "#     WHERE s.ContractStartDate IS NOT NULL AND s.ContractEndDate IS NOT NULL\n",
        "#     WITH s,\n",
        "#          [item IN split(s.ContractStartDate, \"/\") | toInteger(item)] AS startComponents,\n",
        "#          [item IN split(s.ContractEndDate, \"/\") | toInteger(item)] AS endComponents\n",
        "#     WITH s, startComponents, endComponents,\n",
        "#          startComponents[1] AS startMonth,\n",
        "#          endComponents[1] AS endMonth\n",
        "#     SET s.ContractStartDate =\n",
        "#         CASE\n",
        "#             WHEN startMonth > 12 THEN\n",
        "#                 date({\n",
        "#                     day: startComponents[1],\n",
        "#                     month: startComponents[0],\n",
        "#                     year: startComponents[2]\n",
        "#                 })\n",
        "#             ELSE\n",
        "#                 date({\n",
        "#                     day: startComponents[0],\n",
        "#                     month: startMonth,\n",
        "#                     year: startComponents[2]\n",
        "#                 })\n",
        "#         END,\n",
        "#         s.ContractEndDate =\n",
        "#         CASE\n",
        "#             WHEN endMonth > 12 THEN\n",
        "#                 date({\n",
        "#                     day: endComponents[1],\n",
        "#                     month: endComponents[0],\n",
        "#                     year: endComponents[2]\n",
        "#                 })\n",
        "#             ELSE\n",
        "#                 date({\n",
        "#                     day: endComponents[0],\n",
        "#                     month: endMonth,\n",
        "#                     year: endComponents[2]\n",
        "#                 })\n",
        "#         END;\n",
        "#     \"\"\")\n",
        "\n",
        "# # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô\n",
        "# with driver.session() as session:\n",
        "#     session.write_transaction(transform_dates_and_floats)"
      ],
      "metadata": {
        "id": "ZqprXia6m4Gh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Function to calculate and set DaysDuration on SaleOrder nodes\n",
        "# def update_sale_order_duration(tx):\n",
        "#     tx.run(\"\"\"\n",
        "#     MATCH (so:SaleOrder)\n",
        "#     WHERE so.ContractStartDate IS NOT NULL AND so.ContractEndDate IS NOT NULL\n",
        "#     WITH so, duration.between(so.ContractStartDate, so.ContractEndDate) AS contractDuration\n",
        "#     SET so.DaysDuration = contractDuration.days + (contractDuration.months * 30) + (contractDuration.years * 365)\n",
        "#     RETURN so.SONumber, so.DaysDuration;\n",
        "#     \"\"\")\n",
        "\n",
        "# # Function to update duration for all SaleOrder nodes\n",
        "# def calculate_and_update_duration():\n",
        "#     with driver.session() as session:\n",
        "#         session.write_transaction(update_sale_order_duration)\n",
        "\n",
        "# # Run the update function\n",
        "# calculate_and_update_duration()"
      ],
      "metadata": {
        "id": "Z7Yel9dvoC9k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base_prompt():\n",
        "    return '''\n",
        "    You are an expert Cypher query generator for a graph database with the following nodes and relationships:\n",
        "\n",
        "    - **Nodes:**\n",
        "      - `Seller`: Represents a seller with properties: `id` (string), `name` (string).\n",
        "      - `Customer`: Represents a customer with properties: `id` (string), `name` (string).\n",
        "      - `SaleOrder`: Represents a sales order with properties: `SONumber` (string), `ContractStartDate` (Date), `ContractEndDate` (Date), `Total` (float), `DaysDuration` (integer).\n",
        "      - `CostSheet`: Represents a cost sheet with properties: `CSNumber` (string), `Internal` (float), `External` (float).\n",
        "      - `Service`: Represents a service with properties: `Service` (string), `Original` (string).\n",
        "      - `Platform`: Represents a platform with the property: `Original` (string).\n",
        "\n",
        "    - **Relationships:**\n",
        "      - `HAS_COST_SHEET`: Connects `SaleOrder` to `CostSheet`.\n",
        "      - `PROVIDES_SERVICE`: Connects `SaleOrder` to `Service`.\n",
        "      - `SERVICE_COST`: Connects `CostSheet` to `Service` with properties: `Internal` (float), `External` (float), `Total` (float).\n",
        "      - `DEPLOYED_ON`: Connects `Service` to `Platform`.\n",
        "      - `PLACED_ORDER`: Connects `Customer` to `SaleOrder` with properties: `ContractStartDate` (Date), `ContractEndDate` (Date), `DaysDuration` (integer).\n",
        "      - `HANDLED_ORDER`: Connects `Seller` to `SaleOrder`.\n",
        "\n",
        "    **Important Instructions**:\n",
        "    - Your task is to generate a **single Cypher query** based on the question.\n",
        "    - **Provide only the Cypher query, nothing else**. Do not include explanations, comments, or any additional text.\n",
        "    - Ensure the query is **valid** and uses **correct property and relationship names**.\n",
        "    - Stop after generating the query (end with \";\").\n",
        "    - **Do not use SQL-style subqueries**\n",
        "    - Do not use SQL-style subqueries like 'SELECT MAX'. Instead, sort the results and limit it to get the highest or lowest value.\n",
        "    - To get the record with the maximum value, you must use `ORDER BY` within the main query.\n",
        "\n",
        "    Your task is to generate a **single Cypher query** based on the question.\n",
        "\n",
        "    - **Provide only the Cypher query, nothing else.**\n",
        "    - **Do not provide explanations, markdown syntax, or additional words except the query.**\n",
        "    - Ensure the query is **valid** and uses **correct property and relationship names**.\n",
        "    - Stop after generating the query (end with \";\").\n",
        "\n",
        "    Given the question: {question}\n",
        "    '''\n",
        "\n",
        "def get_answer_prompt():\n",
        "    return '''\n",
        "    Given the question: \"{question}\" and the answer record from the graph database: \"{result_record}\".\n",
        "    You are an expert chatbot designed to provide a confident, clear, concise and human-like response based on the question and query results from a graph database.\n",
        "\n",
        "    ### Important:\n",
        "    - Your response must ONLY contain the essential answer. Do not include any of the instructions, question text, or explanation.\n",
        "\n",
        "    ### Instructions (For the chatbot only, DO NOT include this in the response):\n",
        "    - Respond with a direct, single response that provides the correct and essential information, without repeating or justifying your answer.\n",
        "    - Answer with confidence and **only the essential information**, **without repeating any words or parts of the original question or prompt**.\n",
        "    - The response should be as the same language as the input question (English or Thai).\n",
        "    - Format the currency as \"Bath\" when discussing costs, profits, or discounts. (never copy this instruction).\n",
        "    - If there is **only one record**, respond with a **single, direct sentence**.\n",
        "    - If there are **multiple records**, use **bullet points** to clearly present each entry without repeating or summarizing.\n",
        "\n",
        "    ### WHAT TO DO (For the chatbot only, DO NOT include this in the response):\n",
        "    - Provide the answer with **only the core information** (e.g., customer name, order count) in a single, clear sentence.\n",
        "    - Ensure **no part of the original question or prompt text** appears in the response.\n",
        "    - Keep the response focused and concise, **without any repetition** or unnecessary commentary.\n",
        "    - If there are multiple entries, list each in a **bullet point format** for readability. Ensure that the response is formatted for clarity and precision.\n",
        "\n",
        "    ### WHAT NOT TO DO (For the chatbot only, DO NOT include this in the response):\n",
        "    - DO NOT repeat words or phrases from the original prompt or question.\n",
        "    - DO NOT provide any justifications, corrections, or revisions of the answer.\n",
        "    - DO NOT include any extra formatting, headers, comments, symbols, examples, or explanations.\n",
        "    - DO NOT mention \"assistant\" or phrases like \"based on the query\" or \"according to the data.\"\n",
        "    - DO NOT include any phrases expressing uncertainty, apologies, or attempts to correct previous responses.\n",
        "    '''"
      ],
      "metadata": {
        "id": "2Eb2eL_RbPtS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**regex**"
      ],
      "metadata": {
        "id": "2qDd0Eo1bIqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract(response):\n",
        "    try:\n",
        "        # Step 1: Remove specific unwanted patterns like {}, /* but keep the operation symbols (+, -, *, /) and the comma \",\"\n",
        "        # clean_response = re.sub(r'[\"{}/*]+', '', response)  # Remove \"{\", \"}\", but keep *, +, - and /\n",
        "\n",
        "        # Step 2: Remove code block markers and extra formatting\n",
        "        clean_response = re.sub(r'```cypher|```', '', response)\n",
        "        clean_response = re.sub(r'^\\*/\\s*', '', clean_response, flags=re.MULTILINE)\n",
        "\n",
        "        # Step 3: Remove any instance of \"### Response:\"\n",
        "        clean_response = clean_response.replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "        # Step 4: Remove everything after and including the word 'assistant' in any case\n",
        "        clean_response = re.sub(r'\\bassistant\\b.*$', '', clean_response, flags=re.DOTALL | re.IGNORECASE).strip()\n",
        "\n",
        "        # Step 5: Find the index of the word \"MATCH\" (case-insensitive) and slice the string from that point onwards\n",
        "        match_index = clean_response.lower().find(\"match\")\n",
        "        if match_index != -1:\n",
        "            clean_response = clean_response[match_index:].strip()  # Keep everything from \"MATCH\" onwards\n",
        "\n",
        "        # Step 6: Try to find and return the first semicolon (for Cypher queries)\n",
        "        match = re.search(r'([^;]*;)', clean_response)\n",
        "        if match:\n",
        "            return match.group(0)  # Return the matched query including the semicolon\n",
        "\n",
        "        # Step 7: If no semicolon, split the cleaned response to extract content\n",
        "        cypher_queries = re.split(r'Given the question:', clean_response)\n",
        "        extracted_queries = [query.strip() for query in cypher_queries if query.strip()]\n",
        "\n",
        "        if extracted_queries:\n",
        "            seen_queries = set()\n",
        "            unique_queries = []\n",
        "            for query in extracted_queries:\n",
        "                if query not in seen_queries:\n",
        "                    seen_queries.add(query)\n",
        "                    unique_queries.append(query)\n",
        "            return unique_queries[0] if unique_queries else None\n",
        "        else:\n",
        "            return clean_response.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error during extraction: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "4E8CBjYAbK0m"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cypher_query(cypher_query):\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            # Execute the query without a limit to fetch all records\n",
        "            result = session.run(cypher_query)\n",
        "            return result.data()  # Return all records as a list of dictionaries\n",
        "    except Exception as e:\n",
        "        return f\"Error running Cypher query: {str(e)}\"\n",
        "\n",
        "# Function to format result records into a human-readable string with a limit of 10 records\n",
        "def format_result_record(result_record, max_records=10):\n",
        "    if isinstance(result_record, list):\n",
        "        # Take only the first max_records from the result\n",
        "        limited_records = result_record[:max_records]\n",
        "        # Formatting the records into a more readable format\n",
        "        formatted_strings = []\n",
        "        for record in limited_records:\n",
        "            formatted_strings.append(\", \".join([f\"{key}: {value}\" for key, value in record.items()]))\n",
        "        return \"\\n\".join(formatted_strings)\n",
        "    return str(result_record)\n",
        "\n",
        "# Synchronous call to LLM inference\n",
        "def prompt1(question):\n",
        "    try:\n",
        "        baseprompt = get_base_prompt()\n",
        "        formatted_prompt = baseprompt.replace(\"{question}\", question)\n",
        "        model_params = {\n",
        "            'max_new_tokens': 512,\n",
        "            'temperature': 0.001,\n",
        "            'top_p': 0.95,\n",
        "            'repetition_penalty': 1.0\n",
        "        }\n",
        "\n",
        "        client = InferenceClient(api_url03, api_key)\n",
        "        response = client.text_generation(formatted_prompt, **model_params)\n",
        "        clean_cypher_query = extract(response.strip())\n",
        "        return clean_cypher_query\n",
        "    except Exception as e:\n",
        "        return f\"Error generating query: {str(e)}\"\n",
        "\n",
        "async def prompt2(question, result_record):\n",
        "    try:\n",
        "        answer_prompt = get_answer_prompt()\n",
        "        formatted_result = format_result_record(result_record)  # Limit formatted records to 10\n",
        "        formatted_prompt = answer_prompt.replace(\"{question}\", question).replace(\"{result_record}\", formatted_result)\n",
        "\n",
        "        model_params = {\n",
        "            'max_new_tokens': 512,\n",
        "            'temperature': 0.001,\n",
        "            'top_p': 0.99,\n",
        "            'repetition_penalty': 1.0\n",
        "        }\n",
        "\n",
        "        client = InferenceClient(api_url02, api_key)\n",
        "        response = client.text_generation(formatted_prompt, **model_params)\n",
        "        # print(f\"Raw Response: {response}\")  # Debugging print\n",
        "\n",
        "        # Use both extraction functions\n",
        "        clean_response = extract(response.strip())\n",
        "\n",
        "        if clean_response == \"\":\n",
        "            return f\"No answer generated. Here are the results:\\n{formatted_result}\"\n",
        "\n",
        "        return clean_response\n",
        "    except Exception as e:\n",
        "        return f\"Error generating answer: {str(e)}\"\n",
        "        # print(f\"Response: {clean_response}\")  # Debugging print\n",
        "\n",
        "# Function to handle chatbot response\n",
        "async def chatbot_response(message, chat_history):\n",
        "    try:\n",
        "        cypher_query = prompt1(message)\n",
        "        print(f\"Generated Cypher Query: {cypher_query}\")  # Debugging print\n",
        "\n",
        "        if cypher_query:\n",
        "            result_record = run_cypher_query(cypher_query)\n",
        "            print(f\"Result Record: {result_record}\")  # Debugging print\n",
        "\n",
        "            if result_record and isinstance(result_record, list):\n",
        "                answer = await prompt2(message, result_record)  # Await the async function\n",
        "                chat_history.append((message, answer))\n",
        "            else:\n",
        "                chat_history.append((message, \"No relevant data found in the database.\"))\n",
        "        else:\n",
        "            chat_history.append((message, \"Failed to generate a valid Cypher query.\"))\n",
        "    except Exception as e:\n",
        "        chat_history.append((message, f\"Error: {str(e)}\"))\n",
        "\n",
        "    return \"\", chat_history\n",
        "\n",
        "# # Gradio interface using Blocks\n",
        "# with gr.Blocks() as demo:\n",
        "#     chatbot_ui = gr.Chatbot(label=\"Chatbot\")\n",
        "#     msg = gr.Textbox(placeholder=\"Ask a question about the cost sheet...\")\n",
        "#     clear = gr.ClearButton([msg, chatbot_ui])\n",
        "\n",
        "#     # Submit message and get response\n",
        "#     msg.submit(chatbot_response, [msg, chatbot_ui], [msg, chatbot_ui])\n",
        "\n",
        "# # Launch the Gradio app\n",
        "# demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "P_95XOkIbQSS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## interface"
      ],
      "metadata": {
        "id": "tcF_6Eer8ZIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio theme and layout\n",
        "theme = gr.themes.Default(\n",
        "    text_size=\"sm\",\n",
        "    primary_hue=\"blue\"\n",
        ")\n",
        "\n",
        "with gr.Blocks(theme=theme) as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align: center;'>Sales Assistant Chatbot üí¨</h1>\", elem_id=\"title\")\n",
        "\n",
        "    with gr.Column(elem_id=\"chatbot-container\"):\n",
        "        chatbot_ui = gr.Chatbot(label=\"Chatbot\", elem_id=\"gr-chatbot\")  # Chatbot UI\n",
        "        msg = gr.Textbox(placeholder=\"Ask about orders, services, and more...\", label=\"Type here\", show_label=False)\n",
        "        clear = gr.Button(\"Clear\", elem_id=\"gr-button\")\n",
        "\n",
        "        # Submit and clear functionalities\n",
        "        msg.submit(chatbot_response, [msg, chatbot_ui], [msg, chatbot_ui])\n",
        "        clear.click(lambda: None, None, chatbot_ui)\n",
        "\n",
        "# Launch the Gradio app\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "4wewouuJ1pLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **question**"
      ],
      "metadata": {
        "id": "fLEWX_vsNI05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Which customer has placed the highest total value of sales orders?\n",
        "# 2. Which sale order has the highest total value, and what services are linked to that sale order?\n",
        "# 3. find the sales order with the longest contract duration, including its linked services. Make sure to limit the result to one sales order for efficiency.\n",
        "# 4. Who is the sellers that handling the most valuable orders (based on total sales)?\n",
        "# 5. Top 5 services are deployed on the most platforms?\n",
        "# 6. the top 5 services that are most frequently associated with SaleOrder\n",
        "# 7. the top 5 services that are least frequently associated with SaleOrder\n",
        "# 8. Top 5 customers that have placed the most SaleOrders along with their number of sale orders and summation total value of SaleOrders\n",
        "# 9. Every SaleOrder has cost sheet, every costsheet has service cost, give me the top 5 services generate the highest internal costs for sellers?\n",
        "# 10. Can you provide the top 5 customers along with their sale orders and calculated discounts based on the DaysDuration from the SaleOrder? The discount should be calculated as 10% for every 365 days of the DaysDuration"
      ],
      "metadata": {
        "id": "tmtfjW1nNMKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤ id ‡πÅ‡∏•‡∏∞ ‡∏ä‡∏∑‡πà‡∏≠‡∏≠‡∏∞‡πÑ‡∏£ ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏£‡∏ß‡∏°‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î?\n",
        "# 2. ‡∏ö‡∏≠‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠ (SONumber) ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏ô‡∏±‡πâ‡∏ô?\n",
        "# 3. ‡∏ö‡∏≠‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠ (SONumber) ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏¢‡∏≤‡∏ß‡∏ô‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á\n",
        "# 4. ‡∏ú‡∏π‡πâ‡∏Ç‡∏≤‡∏¢‡∏Ñ‡∏ô‡πÑ‡∏´‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (‡∏ï‡∏≤‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏≠‡∏≠‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢)?\n",
        "# 5. ‡∏ö‡∏≠‡∏Å 5 ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ö‡∏ô‡πÅ‡∏û‡∏•‡∏ï‡∏ü‡∏≠‡∏£‡πå‡∏°‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î?\n",
        "# 6. ‡∏ö‡∏≠‡∏Å 5 ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á (PROVIDES SERVICE) ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠ (SaleOrder) ‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
        "# 7. ‡∏ö‡∏≠‡∏Å 5 ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏Å‡∏•‡πà‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á (PROVIDES SERVICE) ‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠ (SaleOrder) ‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î\n",
        "# 8. ‡∏ö‡∏≠‡∏Å 5 ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÅ‡∏•‡∏∞‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠\n",
        "# 9. ‡∏ó‡∏∏‡∏Å‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏°‡∏µ cost sheet ‡∏ó‡∏∏‡∏Å cost sheet ‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏ä‡πà‡∏ß‡∏¢‡∏ö‡∏≠‡∏Å‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£ 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö ‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏¢‡πÉ‡∏ô  (Internal cost) ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏Ç‡∏≤‡∏¢?\n",
        "# 10. ‡∏ö‡∏≠‡∏Å 5 ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏™‡∏±‡∏ç‡∏ç‡∏≤ - ‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏™‡∏±‡∏ç‡∏ç‡∏≤ (DaysDuration) ‡∏¢‡∏≤‡∏ß‡∏ô‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö‡∏ö‡∏≠‡∏Å‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î‡∏ï‡∏≤‡∏° DaysDuration ‡∏à‡∏≤‡∏Å SaleOrder ‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°? ‡πÇ‡∏î‡∏¢‡∏™‡πà‡∏ß‡∏ô‡∏•‡∏î‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏õ‡πá‡∏ô 10% ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡πÜ 365 ‡∏ß‡∏±‡∏ô‡∏Ç‡∏≠‡∏á DaysDuration"
      ],
      "metadata": {
        "id": "Cu-eQCRxWnHf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}