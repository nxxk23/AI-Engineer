{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhx3kb9FvyXj/ErHp+Veyh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nxxk23/AI-Engineer/blob/main/neo4j/performance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUqSEnVta_yf",
        "outputId": "7cec1af2-73c8-4a02-e81f-8afabb83510f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.6/296.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.2/292.2 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install huggingface_hub transformers langchain langchain-community neo4j requests gradio torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from neo4j import GraphDatabase\n",
        "import time\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "Z4aTxVQSbGUb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_base_prompt():\n",
        "    return '''\n",
        "    You are an expert Cypher query generator for a graph database with the following nodes and relationships:\n",
        "\n",
        "    - Nodes:\n",
        "      - `Seller`: Represents a seller with the following properties: `id` (string), `name` (string).\n",
        "      - `Customer`: Represents a customer with the following properties: `id` (string), `name` (string).\n",
        "      - `SaleOrder`: Represents a sales order with the following properties: `SONumber` (string), `ContractStartDate` (string), `ContractEndDate` (string), `Total` (float).\n",
        "      - `CostSheet`: Represents a cost sheet with the following properties: `CSNumber` (string), `Internal` (float), `External` (float).\n",
        "      - `Service`: Represents a service with the following properties: `Service` (string), `Original` (string).\n",
        "      - `Platform`: Represents a platform or technology with the following property: `Original` (string).\n",
        "\n",
        "    - Relationships:\n",
        "      - `HAS_COST_SHEET`: Connects `SaleOrder` to `CostSheet`.\n",
        "      - `PROVIDES_SERVICE`: Connects `SaleOrder` to `Service`.\n",
        "      - `SERVICE_COST`: Connects `CostSheet` to `Service` with properties: `Internal` (float), `External` (float).\n",
        "      - `DEPLOYED_ON`: Connects `Service` to `Platform`.\n",
        "      - `PLACED_ORDER`: Connects `Customer` to `SaleOrder` with properties: `ContractStartDate` (string), `ContractEndDate` (string), `Total` (float).\n",
        "      - `HANDLED_ORDER`: Connects `Seller` to `SaleOrder`.\n",
        "\n",
        "    Your task is to generate a **single Cypher query** based on the question.\n",
        "\n",
        "    - Provide only the Cypher query, nothing else.\n",
        "    - Do not provide explanations, markdown syntax, or additional queries.\n",
        "    - Return the Cypher query **once**.\n",
        "    - Do not generate any follow-up questions or instructions.\n",
        "    - Stop after generating the query.\n",
        "    - Do not include code block, any additional text symbol, titles, or the word \"assistant\" and \"/\".\n",
        "    - Ensure that **only a single instance** of the Cypher query code is returned.\n",
        "\n",
        "    Given the question: {question}\n",
        "    '''\n",
        "\n",
        "\n",
        "def get_answer_prompt():\n",
        "    return '''\n",
        "    You are an expert designed to provide clear, concise answers based on query results from a graph database.\n",
        "\n",
        "    ### Instructions:\n",
        "    - Understand the question: \"{question}\".\n",
        "    - Review the result data: {result_record}.\n",
        "    - Respond with a brief, clear, and concise answer that directly addresses the question.\n",
        "    - Provide only the essential information, with no extra commentary, thinking process, or step descriptions.\n",
        "\n",
        "    ### Guidelines:\n",
        "    - The answer must be brief, directly addressing the question.\n",
        "    - Only include relevant information (e.g., customer ID and name), formatted cleanly.\n",
        "    - Avoid any additional commentary, repetition, or explanation of the thought process.\n",
        "    - Do not include titles or headers (e.g., \"Step 3\", \"Execute the function\").\n",
        "    - Ensure the output is in a clean sentence or bullet format, depending on the result.\n",
        "    '''"
      ],
      "metadata": {
        "id": "2Eb2eL_RbPtS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **model 02**"
      ],
      "metadata": {
        "id": "3CufsxbwY0Z9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import asyncio\n",
        "import re\n",
        "from huggingface_hub import InferenceClient\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j database connection credentials\n",
        "NEO4J_URI = \"neo4j+s://ba8feaac.databases.neo4j.io\"\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"P5vvwJNewVk42Ey31ynvL9vrRRx98vlmv_5NnmVtshw\"\n",
        "\n",
        "# Define the Neo4j driver connection\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "\n",
        "# Define your LLM API endpoint and key\n",
        "api_url = 'https://ai-api.manageai.co.th/llm-model-02/'\n",
        "api_key = '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'\n"
      ],
      "metadata": {
        "id": "aV8sJ0rBnHkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ฟังก์ชันสำหรับรันคำสั่งแปลงข้อมูล\n",
        "def transform_dates_and_floats(tx):\n",
        "    tx.run(\"\"\"\n",
        "    MATCH (s:SaleOrder)\n",
        "    WHERE s.ContractStartDate IS NOT NULL AND s.ContractEndDate IS NOT NULL\n",
        "    WITH s,\n",
        "         [item IN split(s.ContractStartDate, \"/\") | toInteger(item)] AS startComponents,\n",
        "         [item IN split(s.ContractEndDate, \"/\") | toInteger(item)] AS endComponents\n",
        "    WITH s, startComponents, endComponents,\n",
        "         startComponents[1] AS startMonth,\n",
        "         endComponents[1] AS endMonth\n",
        "    SET s.ContractStartDate =\n",
        "        CASE\n",
        "            WHEN startMonth > 12 THEN\n",
        "                date({\n",
        "                    day: startComponents[1],\n",
        "                    month: startComponents[0],\n",
        "                    year: startComponents[2]\n",
        "                })\n",
        "            ELSE\n",
        "                date({\n",
        "                    day: startComponents[0],\n",
        "                    month: startMonth,\n",
        "                    year: startComponents[2]\n",
        "                })\n",
        "        END,\n",
        "        s.ContractEndDate =\n",
        "        CASE\n",
        "            WHEN endMonth > 12 THEN\n",
        "                date({\n",
        "                    day: endComponents[1],\n",
        "                    month: endComponents[0],\n",
        "                    year: endComponents[2]\n",
        "                })\n",
        "            ELSE\n",
        "                date({\n",
        "                    day: endComponents[0],\n",
        "                    month: endMonth,\n",
        "                    year: endComponents[2]\n",
        "                })\n",
        "        END;\n",
        "    \"\"\")\n",
        "\n",
        "# เรียกใช้งาน\n",
        "with driver.session() as session:\n",
        "    session.write_transaction(transform_dates_and_floats)"
      ],
      "metadata": {
        "id": "ZqprXia6m4Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import asyncio\n",
        "import re\n",
        "from huggingface_hub import InferenceClient\n",
        "from neo4j import GraphDatabase\n",
        "\n",
        "# Neo4j database connection credentials\n",
        "NEO4J_URI = \"neo4j+s://ba8feaac.databases.neo4j.io\"\n",
        "NEO4J_USERNAME = \"neo4j\"\n",
        "NEO4J_PASSWORD = \"P5vvwJNewVk42Ey31ynvL9vrRRx98vlmv_5NnmVtshw\"\n",
        "\n",
        "# Define the Neo4j driver connection\n",
        "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
        "\n",
        "# Define your LLM API endpoint and key\n",
        "api_url = 'https://ai-api.manageai.co.th/llm-model-02/'\n",
        "api_key = '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'\n",
        "\n",
        "# Exception handling during extraction\n",
        "def extract(response):\n",
        "    try:\n",
        "        clean_response = re.sub(r'```cypher|```', '', response)\n",
        "        clean_response = re.sub(r'^\\*/\\s*', '', clean_response, flags=re.MULTILINE)\n",
        "        cypher_queries = re.split(r'Given the question:', clean_response)\n",
        "        extracted_queries = [query.strip() for query in cypher_queries if query.strip()]\n",
        "\n",
        "        if extracted_queries:\n",
        "            seen_queries = set()\n",
        "            unique_queries = []\n",
        "            for query in extracted_queries:\n",
        "                if query not in seen_queries:\n",
        "                    seen_queries.add(query)\n",
        "                    unique_queries.append(query)\n",
        "            return unique_queries[0] if unique_queries else None\n",
        "        else:\n",
        "            return clean_response.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error during extraction: {str(e)}\"\n",
        "\n",
        "def run_cypher_query(cypher_query):\n",
        "    try:\n",
        "        with driver.session() as session:\n",
        "            result = session.run(cypher_query)\n",
        "            return result.data()  # Return paginated records as a list of dictionaries\n",
        "    except Exception as e:\n",
        "        return f\"Error running Cypher query: {str(e)}\"\n",
        "\n",
        "# Function to format result records into a string\n",
        "def format_result_record(result_record):\n",
        "    if isinstance(result_record, list):\n",
        "        return \"\\n\".join([str(record) for record in result_record])\n",
        "    return str(result_record)\n",
        "\n",
        "# Synchronous call to LLM inference\n",
        "def prompt1(question):\n",
        "    try:\n",
        "        baseprompt = get_base_prompt()\n",
        "        formatted_prompt = baseprompt.replace(\"{question}\", question)\n",
        "        model_params = {\n",
        "            'max_new_tokens': 512,\n",
        "            'temperature': 0.01,\n",
        "            'top_p': 0.95,\n",
        "            'repetition_penalty': 1.0\n",
        "        }\n",
        "\n",
        "        client = InferenceClient(api_url, api_key)\n",
        "        response = client.text_generation(formatted_prompt, **model_params)\n",
        "        clean_cypher_query = extract(response.strip())\n",
        "        return clean_cypher_query\n",
        "    except Exception as e:\n",
        "        return f\"Error generating query: {str(e)}\"\n",
        "\n",
        "async def prompt2(question, result_record):\n",
        "    try:\n",
        "        answer_prompt = get_answer_prompt()\n",
        "        formatted_result = format_result_record(result_record)\n",
        "        formatted_prompt = answer_prompt.replace(\"{question}\", question).replace(\"{result_record}\", formatted_result)\n",
        "\n",
        "        model_params = {\n",
        "            'max_new_tokens': 512,\n",
        "            'temperature': 0.001,\n",
        "            'top_p': 0.95,\n",
        "            'repetition_penalty': 1.0\n",
        "        }\n",
        "\n",
        "        client = InferenceClient(api_url, api_key)\n",
        "        response = client.text_generation(formatted_prompt, **model_params)\n",
        "        clean_response = extract(response.strip())\n",
        "        clean_response = clean_response.strip()\n",
        "\n",
        "        # Final check for empty responses\n",
        "        if clean_response == \"\":\n",
        "            return \"No data found.\"\n",
        "\n",
        "        return clean_response\n",
        "    except Exception as e:\n",
        "        return f\"Error generating answer: {str(e)}\"\n",
        "\n",
        "# Function to handle chatbot response\n",
        "async def chatbot_response(message, chat_history):\n",
        "    try:\n",
        "        cypher_query = prompt1(message)\n",
        "        print(f\"Generated Cypher Query: {cypher_query}\")  # Debugging print\n",
        "\n",
        "        if cypher_query:\n",
        "            result_record = run_cypher_query(cypher_query)\n",
        "            print(f\"Result Record: {result_record}\")  # Debugging print\n",
        "\n",
        "            if result_record and isinstance(result_record, list):\n",
        "                answer = await prompt2(message, result_record)  # Await the async function\n",
        "                chat_history.append((message, answer))\n",
        "            else:\n",
        "                chat_history.append((message, \"No relevant data found in the database.\"))\n",
        "        else:\n",
        "            chat_history.append((message, \"Failed to generate a valid Cypher query.\"))\n",
        "    except Exception as e:\n",
        "        chat_history.append((message, f\"Error: {str(e)}\"))\n",
        "\n",
        "    return \"\", chat_history\n",
        "\n",
        "# Gradio interface using Blocks\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot_ui = gr.Chatbot(label=\"Chatbot\")\n",
        "    msg = gr.Textbox(placeholder=\"Ask a question about the cost sheet...\")\n",
        "    clear = gr.ClearButton([msg, chatbot_ui])\n",
        "\n",
        "    # Submit message and get response\n",
        "    msg.submit(chatbot_response, [msg, chatbot_ui], [msg, chatbot_ui])\n",
        "\n",
        "# Launch the Gradio app\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "P_95XOkIbQSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **ground-truth**"
      ],
      "metadata": {
        "id": "ZRopTCiCbqJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Which customer has placed the highest total value of sales orders?\n",
        "- `| \"ไอเน็กซ์ บรอดแบนด์\" | 35175.46000000001 |`\n",
        "  ```\n",
        "  MATCH (c:Customer)-[r:PLACED_ORDER]->(so:SaleOrder)\n",
        "  RETURN c.name, SUM(so.Total) AS totalValue\n",
        "  ORDER BY totalValue DESC\n",
        "  LIMIT 1\n",
        "```\n",
        "\n",
        "2. What services are associated with the sales order that has the highest total value?\n",
        "- `| \"SO13-20240800267\" | [\"Cloud-AHV\"] |`\n",
        "  ```\n",
        "  MATCH (so:SaleOrder)-[:PROVIDES_SERVICE]->(s:Service)\n",
        "  WITH so, s\n",
        "  ORDER BY so.Total DESC\n",
        "  LIMIT 1\n",
        "  RETURN so.SONumber, COLLECT(s.Service) AS services\n",
        "  ```\n",
        "\n",
        "3. Which seller has handled the most sales orders?\n",
        "- `| \"นางสาวพัชราภรณ์ แนบเนียน\" | 495 order |`\n",
        "  ```\n",
        "  MATCH (s:Seller)-[r:HANDLED_ORDER]->(so:SaleOrder)\n",
        "  RETURN s.name, COUNT(so) AS numberOfOrders\n",
        "  ORDER BY numberOfOrders DESC\n",
        "  LIMIT 1\n",
        "  ```\n",
        "\n",
        "4. On which **platform** was the service for sales order number \"SO13-20240800267\" deployed?\n",
        "-\n",
        "\n",
        "5. What is the **internal and external cost** breakdown for the services associated with the cost sheet number \"CS-202408106981\"?\n",
        "\n",
        "6. Which sales order has the longest contract duration, and what services are linked to it?\n",
        "- `| \"SO01-20220800251\" | [\"Project-Lead\"] | P123M25DT0S |`\n",
        "  ```\n",
        "  MATCH (so:SaleOrder)-[:PROVIDES_SERVICE]->(s:Service)\n",
        "  WITH so, s, duration.between(date(so.ContractStartDate), date(so.ContractEndDate)) AS contractDuration\n",
        "  RETURN so.SONumber, COLLECT(s.Service) AS services, contractDuration\n",
        "  ORDER BY contractDuration DESC\n",
        "  LIMIT 1\n",
        "  ```\n",
        "7. What is the **total internal and external cost** for the services provided by cost sheet number \"CS-202408106981\"?\n",
        "- ` `\n",
        "\n",
        "8. What services has customer ID \"23588\" purchased?\n",
        "- `| \"ไอเน็กซ์ บรอดแบนด์\" | [\"IDC1\", \"Network\", ...] |`\n",
        "  ```\n",
        "  MATCH (c:Customer {id: '23588'})-[:PLACED_ORDER]->(so:SaleOrder)-[:PROVIDES_SERVICE]->(s:Service)-[:DEPLOYED_ON]->(p:Platform)\n",
        "  RETURN c.name, COLLECT(DISTINCT s.Service) AS services\n",
        "  ```\n",
        "\n",
        "9.\n",
        "  ```\n",
        "  MATCH (c:Customer {id: '12345'})-[:PLACED_ORDER]->(so:SaleOrder)\n",
        "  RETURN c.name, SUM(so.Total) AS totalValue\n",
        "  ```"
      ],
      "metadata": {
        "id": "l84PyPd0aDmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **question**"
      ],
      "metadata": {
        "id": "23CYyqTdYvys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Which customer has placed the highest total value of sales orders?\n",
        "# What services are associated with the sales order that has the highest total value?\n",
        "# Which seller has handled the most sales orders?\n",
        "# On which platform was the service for sales order number \"SO13-20240800267\" deployed?\n",
        "# What is the internal and external cost breakdown for the services associated with the cost sheet number \"CS-202408106981\"?\n",
        "# Which sales order has the longest contract duration, and what services are linked to it?\n",
        "# What is the total internal and external cost for the services provided by cost sheet number \"CS-202408106981\"?\n",
        "# What services has customer ID \"23588\" purchased, and on which platforms are they deployed?\n",
        "# What is the total value of sales orders placed by customer ID \"23588\" across all sellers?\n",
        "# Which seller handled the sales order with the lowest total value, and what services were provided in that order?"
      ],
      "metadata": {
        "id": "SLhx8t94bSti"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}